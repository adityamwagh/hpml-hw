{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2ikpFeVyPch1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tawUAmpCPch6"
   },
   "outputs": [],
   "source": [
    "class BasicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(32*32*3, 1000)\n",
    "        self.linear2 = nn.Linear(1000, 1000)\n",
    "        self.linear3 = nn.Linear(1000, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class BasicDropoutNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.linear1 = nn.Linear(32*32*3, 1000)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.linear2 = nn.Linear(1000, 1000)\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "        self.linear3 = nn.Linear(1000, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.drop1(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9lqbU-ZIPch8"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 200\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "M0zJEdy4Pch9",
    "outputId": "0771abf0-783d-4dd3-d160-e70367c23afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_data = datasets.CIFAR10(root=\"CIFAR10\", download=True, train=True, transform=transformations)\n",
    "val_data = datasets.CIFAR10(root=\"CIFAR10\", download=True, train=False, transform=transformations)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "J3z99JLyPch_"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, device=\"cpu\"):\n",
    "    \n",
    "    # store loss & accuracy for each epoch\n",
    "    total_loss = 0.0\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        # send stuff to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(images)\n",
    "\n",
    "        # compute loss with L2-regularization\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        l2_lambda = 0.001\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss and accuracy calculations\n",
    "        total_loss += preds.shape[0] * loss.item()\n",
    "        _, predicted = torch.max(preds.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "                \n",
    "    train_loss = total_loss / total\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    print(f\"[Training] Loss: {train_loss}, Accuracy: {train_accuracy}\")\n",
    "    \n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xzCTL1XLPciB"
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader, device=\"cpu\"):\n",
    "    \n",
    "    # store loss & accuracy for each epoch\n",
    "    total_loss = 0.0\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "\n",
    "            # send stuff to device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            preds = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_fn(preds, labels)\n",
    "\n",
    "            # loss and accuracy calculations\n",
    "            total_loss += preds.shape[0] * loss.item()\n",
    "            _, predicted = torch.max(preds.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "                \n",
    "    val_loss = total_loss / total\n",
    "    val_accuracy = correct / total\n",
    "\n",
    "    print(f\"[Validation] Loss: {val_loss}, Accuracy: {val_accuracy}\")\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhElruNIPciD"
   },
   "source": [
    "# AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOSBd4G5PciH"
   },
   "source": [
    "## L2 Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AW3XiGODPciI"
   },
   "outputs": [],
   "source": [
    "adagrad_L2_train_loss = []\n",
    "adagrad_L2_validation_loss = []\n",
    "adagrad_L2_train_accuracy = []\n",
    "adagrad_L2_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ywtrHzdAPciK",
    "outputId": "065451cb-ce07-486e-8598-8b5e88376f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with AdaGrad]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.3125114086914063, Accuracy: 0.35748\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.064680142593384, Accuracy: 0.4042\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.172159332809448, Accuracy: 0.41068\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.048800601196289, Accuracy: 0.4174\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.134578538894653, Accuracy: 0.43142\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.035703549194336, Accuracy: 0.4357\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.112889401626587, Accuracy: 0.44746\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.0284442180633544, Accuracy: 0.4415\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.099012758407593, Accuracy: 0.45662\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.0222469741821287, Accuracy: 0.4494\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.0885195255279543, Accuracy: 0.4662\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.0185894504547117, Accuracy: 0.4522\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.080273957672119, Accuracy: 0.47396\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.0178107933044434, Accuracy: 0.4527\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.073946030731201, Accuracy: 0.48136\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.015365581512451, Accuracy: 0.4552\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.0685988196563723, Accuracy: 0.48504\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.0079929580688476, Accuracy: 0.4659\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.063971772003174, Accuracy: 0.4911\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.0055358528137206, Accuracy: 0.4676\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.0597763179016115, Accuracy: 0.49574\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.003351357841492, Accuracy: 0.4701\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.0562640705108644, Accuracy: 0.49958\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.0016836597442627, Accuracy: 0.4705\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.0529617475891113, Accuracy: 0.50202\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.0023959156036377, Accuracy: 0.4697\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.050360188064575, Accuracy: 0.50582\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 1.998239888381958, Accuracy: 0.4745\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.0477754434204103, Accuracy: 0.50996\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 1.9968857479095459, Accuracy: 0.4769\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.045276145477295, Accuracy: 0.5128\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 1.9956673023223876, Accuracy: 0.4783\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.0430538580322266, Accuracy: 0.51578\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 1.993544722366333, Accuracy: 0.4792\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.0410629810333254, Accuracy: 0.51852\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 1.9916849969863892, Accuracy: 0.4821\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.0388506730651854, Accuracy: 0.52206\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 1.9910870246887207, Accuracy: 0.4834\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.0369158699798584, Accuracy: 0.52482\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 1.991445756149292, Accuracy: 0.4801\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.0352159912872314, Accuracy: 0.5267\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 1.9897761848449707, Accuracy: 0.4852\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.0334649935913087, Accuracy: 0.52964\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 1.988079546546936, Accuracy: 0.4864\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.0317950119781494, Accuracy: 0.53182\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 1.9880772644042968, Accuracy: 0.4844\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.0303923805999755, Accuracy: 0.5342\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 1.9859260250091553, Accuracy: 0.4873\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.028849695854187, Accuracy: 0.53686\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 1.984902674102783, Accuracy: 0.4861\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.027674655761719, Accuracy: 0.5379\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 1.9838074417114258, Accuracy: 0.49\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.0260805808258056, Accuracy: 0.54066\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 1.983675474357605, Accuracy: 0.4898\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.02488856678009, Accuracy: 0.54244\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 1.9820897109985351, Accuracy: 0.4921\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.023683614807129, Accuracy: 0.54448\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 1.98269748210907, Accuracy: 0.4917\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.022421969718933, Accuracy: 0.5471\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 1.9816556158065797, Accuracy: 0.4939\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.021202932281494, Accuracy: 0.54828\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 1.9800120323181152, Accuracy: 0.4941\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.0201587675476076, Accuracy: 0.55018\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 1.9797471141815186, Accuracy: 0.4976\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.019027789955139, Accuracy: 0.55216\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 1.9798255348205567, Accuracy: 0.4959\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.0180957669067383, Accuracy: 0.55306\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 1.978431217765808, Accuracy: 0.4965\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.0170052604675295, Accuracy: 0.55428\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 1.9770751417160035, Accuracy: 0.4982\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.0160549534225463, Accuracy: 0.55702\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 1.9763760795593261, Accuracy: 0.5\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.014905197906494, Accuracy: 0.5589\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 1.9758208972930908, Accuracy: 0.5016\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.014217998046875, Accuracy: 0.5598\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 1.976386886024475, Accuracy: 0.4999\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.013151904067993, Accuracy: 0.56294\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 1.9740406261444092, Accuracy: 0.5031\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.012420157318115, Accuracy: 0.56418\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 1.9735963474273681, Accuracy: 0.5008\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.011511030654907, Accuracy: 0.56444\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 1.9737814722061158, Accuracy: 0.504\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.010595249938965, Accuracy: 0.5657\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 1.9716908517837524, Accuracy: 0.5039\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.0101202577209474, Accuracy: 0.56668\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 1.9730638008117676, Accuracy: 0.5011\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.0091106341934206, Accuracy: 0.56888\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 1.972259806060791, Accuracy: 0.5023\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.0081913177108763, Accuracy: 0.56906\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 1.9708774959564208, Accuracy: 0.5044\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.007543344116211, Accuracy: 0.57104\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 1.971440424346924, Accuracy: 0.5018\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.006841918334961, Accuracy: 0.57254\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 1.9703333320617675, Accuracy: 0.5037\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.0062602498626707, Accuracy: 0.57358\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 1.9690781898498535, Accuracy: 0.5069\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.005386364860535, Accuracy: 0.57506\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 1.9700349227905274, Accuracy: 0.506\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.0047299103164673, Accuracy: 0.5761\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 1.9694236934661866, Accuracy: 0.5062\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.004180034637451, Accuracy: 0.57738\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 1.9684633205413817, Accuracy: 0.5061\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.0034509031677246, Accuracy: 0.57934\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 1.967925270652771, Accuracy: 0.5098\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.0026390607452393, Accuracy: 0.57908\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 1.9678747058868409, Accuracy: 0.5078\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.002040064468384, Accuracy: 0.58166\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 1.968051803970337, Accuracy: 0.5052\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.001495715560913, Accuracy: 0.58372\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 1.9679223625183107, Accuracy: 0.5063\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.001021936035156, Accuracy: 0.58282\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 1.9675159938812257, Accuracy: 0.5081\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.0003418238449098, Accuracy: 0.5844\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 1.9668082847595214, Accuracy: 0.5084\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 1.9996822497558593, Accuracy: 0.58564\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 1.9647625673294067, Accuracy: 0.5099\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 1.999117582397461, Accuracy: 0.58662\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 1.9662791049957276, Accuracy: 0.5079\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 1.9985609384536742, Accuracy: 0.58826\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 1.965151417541504, Accuracy: 0.5109\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 1.997980203552246, Accuracy: 0.58866\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 1.9655013221740723, Accuracy: 0.508\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 1.997412523612976, Accuracy: 0.58928\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 1.9642817028045654, Accuracy: 0.5105\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 1.9968820359039308, Accuracy: 0.59056\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 1.9647059787750245, Accuracy: 0.5096\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 1.9962406391143799, Accuracy: 0.5918\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 1.9644280456542969, Accuracy: 0.5103\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 1.995798858795166, Accuracy: 0.59272\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 1.9633657163619995, Accuracy: 0.5092\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 1.9951894514465331, Accuracy: 0.59436\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 1.9638668739318847, Accuracy: 0.5094\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 1.9946786125946045, Accuracy: 0.5939\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 1.9631395872116089, Accuracy: 0.5124\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 1.9941922008514403, Accuracy: 0.59612\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 1.9627951961517334, Accuracy: 0.511\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 1.9937612760162353, Accuracy: 0.59594\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 1.9633485996246338, Accuracy: 0.5103\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 1.9933781983947754, Accuracy: 0.59782\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 1.962661187171936, Accuracy: 0.51\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 1.9927982253265382, Accuracy: 0.59814\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 1.961304803276062, Accuracy: 0.51\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 1.992258833580017, Accuracy: 0.59938\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 1.9616941884994508, Accuracy: 0.5093\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 1.9918829211425781, Accuracy: 0.59916\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 1.9608117202758788, Accuracy: 0.5123\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 1.9913868501281737, Accuracy: 0.60088\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 1.960928366279602, Accuracy: 0.5106\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 1.990991266708374, Accuracy: 0.60164\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 1.9614829795837403, Accuracy: 0.5106\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 1.990411072769165, Accuracy: 0.60276\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 1.9621762086868286, Accuracy: 0.5133\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 1.9900551391983032, Accuracy: 0.60228\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 1.9595779214859008, Accuracy: 0.5115\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 1.989631951751709, Accuracy: 0.60442\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 1.9595042514801024, Accuracy: 0.512\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 1.9891099365234375, Accuracy: 0.6045\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 1.9602462526321411, Accuracy: 0.5118\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 1.9885995277404784, Accuracy: 0.60588\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 1.9596404346466065, Accuracy: 0.5142\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 1.98827876121521, Accuracy: 0.6068\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 1.9588948581695558, Accuracy: 0.5142\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 1.9878086233901977, Accuracy: 0.60786\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 1.959432787322998, Accuracy: 0.5121\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 1.9874752310943604, Accuracy: 0.60816\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 1.959390949821472, Accuracy: 0.5158\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 1.9869127229309083, Accuracy: 0.60888\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 1.9604614692687987, Accuracy: 0.5131\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 1.9866344171905517, Accuracy: 0.60914\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 1.9590141017913818, Accuracy: 0.5141\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 1.986048974761963, Accuracy: 0.61076\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 1.9586104959487916, Accuracy: 0.5139\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 1.985880969734192, Accuracy: 0.612\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 1.958518397140503, Accuracy: 0.5125\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 1.9853551751327514, Accuracy: 0.61224\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 1.9574487672805787, Accuracy: 0.5138\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 1.985073929862976, Accuracy: 0.6125\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 1.95717746219635, Accuracy: 0.514\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 1.9845427138900757, Accuracy: 0.61406\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 1.9576258220672607, Accuracy: 0.5153\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 1.984324457550049, Accuracy: 0.61326\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 1.9567494861602783, Accuracy: 0.5151\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 1.9838203089523316, Accuracy: 0.6148\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 1.9582168546676635, Accuracy: 0.5137\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 1.9835707049560547, Accuracy: 0.61588\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 1.9571231884002687, Accuracy: 0.5148\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 1.9830742331314086, Accuracy: 0.6162\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 1.9567168300628661, Accuracy: 0.5163\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 1.9828251184463501, Accuracy: 0.61714\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 1.9568865255355834, Accuracy: 0.5134\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 1.9824320538330078, Accuracy: 0.61784\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 1.9560188777923584, Accuracy: 0.5145\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 1.9821584931945802, Accuracy: 0.6187\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 1.9563345743179321, Accuracy: 0.516\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 1.981769621925354, Accuracy: 0.61896\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 1.9561701635360718, Accuracy: 0.5148\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 1.981270484085083, Accuracy: 0.6194\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 1.955594584274292, Accuracy: 0.5176\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 1.9811806869125366, Accuracy: 0.62086\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 1.9548104877471923, Accuracy: 0.519\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 1.9807093830871583, Accuracy: 0.62032\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 1.955213187599182, Accuracy: 0.5152\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 1.9803211059188843, Accuracy: 0.6216\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 1.95545318775177, Accuracy: 0.5169\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 1.9799888842773437, Accuracy: 0.62276\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 1.9553279216766357, Accuracy: 0.516\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 1.9797102628707886, Accuracy: 0.62232\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 1.9545640029907227, Accuracy: 0.5171\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 1.9793618070602417, Accuracy: 0.62304\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 1.9543428764343262, Accuracy: 0.5188\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 1.9791197539901733, Accuracy: 0.624\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 1.9542083137512207, Accuracy: 0.5189\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 1.9786621242904663, Accuracy: 0.62496\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 1.9541999914169312, Accuracy: 0.5169\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 1.978383596725464, Accuracy: 0.62524\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 1.9544452709198, Accuracy: 0.5195\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 1.9781124737548827, Accuracy: 0.62574\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 1.9538538932800293, Accuracy: 0.5206\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 1.9777013324356079, Accuracy: 0.62676\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 1.953740648651123, Accuracy: 0.5204\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 1.9774873343658448, Accuracy: 0.62736\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 1.95373099193573, Accuracy: 0.5163\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 1.9772471883010865, Accuracy: 0.62706\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 1.9532185607910155, Accuracy: 0.5184\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 1.9768795889282227, Accuracy: 0.629\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 1.9531564516067506, Accuracy: 0.5199\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 1.9766298285675048, Accuracy: 0.63008\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 1.9533384983062745, Accuracy: 0.5192\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 1.9763838990020752, Accuracy: 0.63014\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 1.9526602191925049, Accuracy: 0.5186\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 1.9758473840332031, Accuracy: 0.63074\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 1.9526310905456543, Accuracy: 0.5189\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 1.9756622262573242, Accuracy: 0.63046\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 1.9525173784255982, Accuracy: 0.5197\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 1.9753967067718505, Accuracy: 0.63106\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 1.952193215751648, Accuracy: 0.5201\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 1.974995042114258, Accuracy: 0.63188\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 1.9527555994033814, Accuracy: 0.518\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 1.974759251976013, Accuracy: 0.63308\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 1.9519851642608643, Accuracy: 0.5184\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 1.9744528337860108, Accuracy: 0.6333\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 1.9522888223648072, Accuracy: 0.5209\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 1.9742190867614746, Accuracy: 0.63378\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 1.952332237815857, Accuracy: 0.52\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 1.9739545343017577, Accuracy: 0.6341\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 1.9525210109710693, Accuracy: 0.5199\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 1.9737462494659423, Accuracy: 0.63488\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 1.9513588111877442, Accuracy: 0.5232\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 1.9734800802612305, Accuracy: 0.63578\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 1.9514312147140502, Accuracy: 0.5207\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 1.9731027560424805, Accuracy: 0.63596\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 1.9514551750183105, Accuracy: 0.5209\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 1.9728307511138916, Accuracy: 0.63604\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 1.9511633958816528, Accuracy: 0.523\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 1.9726489008331298, Accuracy: 0.63692\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 1.950879832839966, Accuracy: 0.5232\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 1.972292127532959, Accuracy: 0.63864\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 1.9514338256835937, Accuracy: 0.5219\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 1.9719873162841797, Accuracy: 0.63854\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 1.950839475250244, Accuracy: 0.5226\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 1.9717458405303956, Accuracy: 0.63878\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 1.951102058029175, Accuracy: 0.5219\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 1.9714711783599854, Accuracy: 0.63998\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 1.95157676486969, Accuracy: 0.5213\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 1.9712188524627685, Accuracy: 0.63944\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 1.9504164098739625, Accuracy: 0.5215\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 1.9709004335403442, Accuracy: 0.64058\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 1.9500143268585206, Accuracy: 0.5215\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 1.970550567817688, Accuracy: 0.64028\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 1.951091831588745, Accuracy: 0.5192\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 1.9705406728363037, Accuracy: 0.6406\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 1.9497548822402955, Accuracy: 0.5211\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 1.9701111472320556, Accuracy: 0.64168\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 1.9498841527938844, Accuracy: 0.524\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 1.9699503130722047, Accuracy: 0.64288\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 1.949930556678772, Accuracy: 0.5218\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 1.969657918663025, Accuracy: 0.64258\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 1.9498046976089478, Accuracy: 0.5246\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 1.9694266679763794, Accuracy: 0.6435\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 1.949695761871338, Accuracy: 0.5251\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 1.9691863326263428, Accuracy: 0.6436\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 1.9495446361541748, Accuracy: 0.5234\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 1.9689012321472168, Accuracy: 0.6446\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 1.9492409130096435, Accuracy: 0.5247\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 1.9686915234375, Accuracy: 0.64582\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 1.9490830286026002, Accuracy: 0.5269\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 1.9684089374160767, Accuracy: 0.64534\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 1.9483355148315429, Accuracy: 0.5247\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 1.9681408491897583, Accuracy: 0.64656\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 1.9489462671279907, Accuracy: 0.5236\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 1.9677652555084229, Accuracy: 0.64702\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 1.949085747528076, Accuracy: 0.5225\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 1.967637452468872, Accuracy: 0.64734\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 1.9494329336166383, Accuracy: 0.5243\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 1.967360545387268, Accuracy: 0.6478\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 1.948325556755066, Accuracy: 0.5243\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 1.9671661983108522, Accuracy: 0.64828\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 1.9487183982849121, Accuracy: 0.5248\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 1.9669921648406983, Accuracy: 0.64888\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 1.9484347200393677, Accuracy: 0.5254\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 1.9665724794769288, Accuracy: 0.64914\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 1.947892378807068, Accuracy: 0.5252\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 1.9664502613830566, Accuracy: 0.6499\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 1.9486137027740478, Accuracy: 0.5225\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 1.9661537089157104, Accuracy: 0.65082\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 1.9481551509857178, Accuracy: 0.5266\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 1.9659293207550048, Accuracy: 0.64986\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 1.948299333190918, Accuracy: 0.5268\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 1.965774075126648, Accuracy: 0.65126\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 1.9480572052001952, Accuracy: 0.5247\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 1.9654279442596436, Accuracy: 0.65222\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 1.9476623443603516, Accuracy: 0.5251\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 1.9651471844482422, Accuracy: 0.65252\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 1.9487187921524047, Accuracy: 0.5247\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 1.96496124710083, Accuracy: 0.65274\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 1.9479018878936767, Accuracy: 0.5264\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 1.9648627794265747, Accuracy: 0.65328\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 1.9478496828079224, Accuracy: 0.5257\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 1.9645398070526123, Accuracy: 0.6538\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 1.9471939880371094, Accuracy: 0.5257\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 1.9642894215393067, Accuracy: 0.65452\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 1.946667269897461, Accuracy: 0.5265\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 1.9640120962524414, Accuracy: 0.65512\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 1.947123397064209, Accuracy: 0.526\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 1.9638069324874878, Accuracy: 0.65532\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 1.9470067825317383, Accuracy: 0.5265\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 1.9637661191558837, Accuracy: 0.65564\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 1.9469875999450683, Accuracy: 0.5254\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 1.9633262992858886, Accuracy: 0.65632\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 1.9463864418029786, Accuracy: 0.5286\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 1.9632335723495484, Accuracy: 0.65702\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 1.947848087310791, Accuracy: 0.5247\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 1.9629892057037353, Accuracy: 0.65678\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 1.9462721160888672, Accuracy: 0.5263\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 1.9628126388931275, Accuracy: 0.65692\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 1.9468453330993651, Accuracy: 0.5256\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 1.9626282898712157, Accuracy: 0.65752\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 1.946584659576416, Accuracy: 0.5272\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 1.9623513938140869, Accuracy: 0.65792\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 1.9466213474273681, Accuracy: 0.5262\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 1.9620840671157838, Accuracy: 0.65894\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 1.945958388710022, Accuracy: 0.5275\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 1.9619315686416625, Accuracy: 0.65966\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 1.9462795347213746, Accuracy: 0.5271\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 1.9617790385437013, Accuracy: 0.65918\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 1.9457532064437866, Accuracy: 0.5263\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 1.9615501597595215, Accuracy: 0.65952\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 1.9455529724121094, Accuracy: 0.5287\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 1.9612120258712769, Accuracy: 0.65994\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 1.945901054573059, Accuracy: 0.5259\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 1.9611273529815674, Accuracy: 0.66064\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 1.9463513082504273, Accuracy: 0.5243\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 1.9609102215576173, Accuracy: 0.66094\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 1.9455186210632325, Accuracy: 0.5274\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 1.9606501011276245, Accuracy: 0.66148\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 1.9456757316589355, Accuracy: 0.5287\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 1.9604809712982179, Accuracy: 0.66132\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 1.9456355461120605, Accuracy: 0.5282\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 1.9602340733718873, Accuracy: 0.66252\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 1.9454057718276978, Accuracy: 0.5281\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 1.9600688037872314, Accuracy: 0.66276\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 1.945753783607483, Accuracy: 0.527\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 1.959910227203369, Accuracy: 0.66302\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 1.9451611087799072, Accuracy: 0.5285\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 1.9596786275482179, Accuracy: 0.66438\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 1.945532529449463, Accuracy: 0.5276\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 1.959390584564209, Accuracy: 0.66384\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 1.9456235889434814, Accuracy: 0.5304\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 1.9591127389144898, Accuracy: 0.66446\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 1.9449316785812378, Accuracy: 0.5289\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 1.959141815071106, Accuracy: 0.66492\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 1.944343822479248, Accuracy: 0.5294\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 1.9588295973205567, Accuracy: 0.66522\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 1.9448539850234985, Accuracy: 0.5298\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 1.9587380700683594, Accuracy: 0.66568\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 1.9452797613143922, Accuracy: 0.5277\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 1.95841362575531, Accuracy: 0.66592\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 1.94556882686615, Accuracy: 0.5299\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 1.9583168454742432, Accuracy: 0.66658\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 1.944247152709961, Accuracy: 0.5296\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 1.9580787543487548, Accuracy: 0.66696\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 1.9443143669128418, Accuracy: 0.528\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 1.9578532666015624, Accuracy: 0.66748\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 1.9442488918304444, Accuracy: 0.5304\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 1.957700419998169, Accuracy: 0.6677\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 1.9442967777252198, Accuracy: 0.5289\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 1.9574231909561157, Accuracy: 0.66792\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 1.944241026687622, Accuracy: 0.5298\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 1.9572600564956666, Accuracy: 0.6691\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 1.9440050346374511, Accuracy: 0.5287\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 1.9570850922393799, Accuracy: 0.66856\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 1.9443811225891112, Accuracy: 0.5292\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 1.9569427129745482, Accuracy: 0.66916\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 1.9440724178314208, Accuracy: 0.5294\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 1.9567718980407716, Accuracy: 0.6694\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 1.9438099899291992, Accuracy: 0.5283\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 1.9566570714569091, Accuracy: 0.66996\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 1.9430276538848876, Accuracy: 0.5308\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 1.9562037578964233, Accuracy: 0.67106\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 1.9436695955276488, Accuracy: 0.5285\n",
      "[Finished Training with AdaGrad]\n",
      "\n",
      "Total Training Time: 938.8822618611157\n"
     ]
    }
   ],
   "source": [
    "model = BasicNet().to(device)\n",
    "adagrad_optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with AdaGrad]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, adagrad_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "\n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    adagrad_L2_train_loss.append(train_loss)\n",
    "    adagrad_L2_validation_loss.append(val_loss)\n",
    "    adagrad_L2_train_accuracy.append(train_acc)\n",
    "    adagrad_L2_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with AdaGrad]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9TtdcZuPciM"
   },
   "source": [
    "## L2 + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "brFUO6I9PciM"
   },
   "outputs": [],
   "source": [
    "adagrad_L2D_train_loss = []\n",
    "adagrad_L2D_validation_loss = []\n",
    "adagrad_L2D_train_accuracy = []\n",
    "adagrad_L2D_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "P_ZbzlPnPciN",
    "outputId": "479740ae-3da9-4e2e-ca96-732f3a9e4ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with AdaGrad]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.4200131285095217, Accuracy: 0.31236\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.110218046569824, Accuracy: 0.353\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.2762511544036865, Accuracy: 0.3554\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.085474835586548, Accuracy: 0.3837\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.222351790084839, Accuracy: 0.38308\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.067485859680176, Accuracy: 0.4001\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.192630316696167, Accuracy: 0.39534\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.0593214973449707, Accuracy: 0.408\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.172971717376709, Accuracy: 0.4054\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.0529550342559815, Accuracy: 0.4155\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.1604838121032715, Accuracy: 0.41104\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.050139772796631, Accuracy: 0.4163\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.1501320083618163, Accuracy: 0.41414\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.0473262172698976, Accuracy: 0.4174\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.1415550998687745, Accuracy: 0.4193\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.0448681087493896, Accuracy: 0.4225\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.1349772203063964, Accuracy: 0.4233\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.041216808128357, Accuracy: 0.4235\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.1298460428619386, Accuracy: 0.42462\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.039307152557373, Accuracy: 0.4268\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.124987740478516, Accuracy: 0.42742\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.0375948947906495, Accuracy: 0.4305\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.1199178567504884, Accuracy: 0.43054\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.036366218185425, Accuracy: 0.4331\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.11617314163208, Accuracy: 0.4325\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.0348714263916015, Accuracy: 0.4338\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.1120829972839354, Accuracy: 0.43566\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.032504927825928, Accuracy: 0.4368\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.10827776473999, Accuracy: 0.43846\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.0314223320007323, Accuracy: 0.4369\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.1053973834228517, Accuracy: 0.4414\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.030108553695679, Accuracy: 0.4389\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.1023262436676027, Accuracy: 0.44272\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.027475127029419, Accuracy: 0.4394\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.1004671185302732, Accuracy: 0.44536\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.0270853483200075, Accuracy: 0.4413\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.0985950467681884, Accuracy: 0.44624\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.0257791988372804, Accuracy: 0.4402\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.0955284809875487, Accuracy: 0.44892\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.023774905014038, Accuracy: 0.4444\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.093535143432617, Accuracy: 0.45088\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.0237153560638426, Accuracy: 0.4449\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.090658522644043, Accuracy: 0.45258\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.021126788520813, Accuracy: 0.4467\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.0896785846710206, Accuracy: 0.45368\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.019609592437744, Accuracy: 0.4486\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.0891034861755373, Accuracy: 0.45354\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.0184730972290037, Accuracy: 0.4496\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.0860104579925536, Accuracy: 0.45612\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.0177014759063723, Accuracy: 0.45\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.0851567182159423, Accuracy: 0.45614\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.0160195220947266, Accuracy: 0.4533\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.0836424559020994, Accuracy: 0.45992\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.0142317729949952, Accuracy: 0.4522\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.0817411461639406, Accuracy: 0.4619\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.0136033069610595, Accuracy: 0.4574\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.079278235397339, Accuracy: 0.4655\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.0118308219909666, Accuracy: 0.4589\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.079137428512573, Accuracy: 0.4643\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.011202151489258, Accuracy: 0.4618\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.0775008864593505, Accuracy: 0.4679\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.0093298248291016, Accuracy: 0.4621\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.075838516998291, Accuracy: 0.46852\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.0090087371826173, Accuracy: 0.4627\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.0748088889312744, Accuracy: 0.46856\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.008291933822632, Accuracy: 0.4641\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.0730589756774904, Accuracy: 0.47394\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.006716181564331, Accuracy: 0.4665\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.071907432022095, Accuracy: 0.47364\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 2.0058991830825805, Accuracy: 0.465\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.0706669930267334, Accuracy: 0.47522\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.00499901638031, Accuracy: 0.4673\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.070335839691162, Accuracy: 0.47516\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 2.0031793788909913, Accuracy: 0.4671\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.06859729347229, Accuracy: 0.47858\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.0033815280914307, Accuracy: 0.4694\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.067274941329956, Accuracy: 0.47884\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.0029272499084474, Accuracy: 0.4694\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.0661938593292235, Accuracy: 0.47974\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.001251424789429, Accuracy: 0.4742\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.066279397277832, Accuracy: 0.47994\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.0005232097625734, Accuracy: 0.4734\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.0638900242233276, Accuracy: 0.48308\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 1.9997899272918702, Accuracy: 0.472\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.063890658493042, Accuracy: 0.48386\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 1.9994898206710816, Accuracy: 0.4753\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.0630920509338377, Accuracy: 0.48436\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 1.9987539943695067, Accuracy: 0.4776\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.063290352630615, Accuracy: 0.4835\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 1.9972181758880616, Accuracy: 0.4787\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.061362388305664, Accuracy: 0.4856\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 1.9964853471755981, Accuracy: 0.4791\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.0616635303497315, Accuracy: 0.48566\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 1.9967936298370361, Accuracy: 0.4804\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.059810239486694, Accuracy: 0.48872\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 1.9955927768707276, Accuracy: 0.4797\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.0602276542663573, Accuracy: 0.48868\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 1.9954079088211059, Accuracy: 0.4802\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.0588330792999265, Accuracy: 0.49084\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 1.994472981071472, Accuracy: 0.4817\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.0582234922790525, Accuracy: 0.48996\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 1.993934831237793, Accuracy: 0.482\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.0579182847595217, Accuracy: 0.49038\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 1.9941314893722535, Accuracy: 0.4818\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.0577732198333742, Accuracy: 0.49048\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 1.9928840114593507, Accuracy: 0.4823\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.0564205460357665, Accuracy: 0.4928\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 1.9928512435913086, Accuracy: 0.4821\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.0564451998901365, Accuracy: 0.49198\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 1.9920203874588012, Accuracy: 0.4826\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.054981515197754, Accuracy: 0.49416\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 1.9917114225387573, Accuracy: 0.4841\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.0539755516815186, Accuracy: 0.49646\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 1.9909903715133668, Accuracy: 0.4843\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.0538693758392332, Accuracy: 0.49634\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 1.9905673831939696, Accuracy: 0.4848\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.053383946685791, Accuracy: 0.4966\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 1.9906667446136475, Accuracy: 0.4848\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.0529411627960203, Accuracy: 0.49672\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 1.9898107780456542, Accuracy: 0.4853\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.052386578979492, Accuracy: 0.4979\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 1.989783541870117, Accuracy: 0.4878\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.051389988937378, Accuracy: 0.49968\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 1.9893558584213258, Accuracy: 0.4884\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.0524975035095214, Accuracy: 0.49822\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 1.9888540378570556, Accuracy: 0.4885\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.050952240447998, Accuracy: 0.49978\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 1.9877548383712769, Accuracy: 0.4903\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.0507856010437013, Accuracy: 0.49986\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 1.9874520502090454, Accuracy: 0.49\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.0502259852600098, Accuracy: 0.50018\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 1.9872940128326415, Accuracy: 0.4918\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.0487100435638426, Accuracy: 0.50262\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 1.987614591026306, Accuracy: 0.4888\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.0486808410644533, Accuracy: 0.50482\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 1.9870120836257934, Accuracy: 0.4882\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.0481744326782225, Accuracy: 0.5027\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 1.9861136604309082, Accuracy: 0.4912\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.049221629180908, Accuracy: 0.50134\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 1.986274080657959, Accuracy: 0.4899\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.0484040084838866, Accuracy: 0.50282\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 1.9855525630950928, Accuracy: 0.4927\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.0488530987548828, Accuracy: 0.50162\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 1.985523936843872, Accuracy: 0.4914\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.047415249786377, Accuracy: 0.5042\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 1.9849063009262085, Accuracy: 0.4916\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.0470268534851073, Accuracy: 0.50402\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 1.9848794246673584, Accuracy: 0.4931\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.0470997457885742, Accuracy: 0.50472\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 1.9846234592437744, Accuracy: 0.4928\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.046715050048828, Accuracy: 0.50564\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 1.9844459270477295, Accuracy: 0.4921\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.0456124292755127, Accuracy: 0.50718\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 1.9840616662979127, Accuracy: 0.4905\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.0451226470947264, Accuracy: 0.50824\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 1.983456884765625, Accuracy: 0.4939\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.046114999847412, Accuracy: 0.50554\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 1.9833176599502564, Accuracy: 0.493\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.0441776292419434, Accuracy: 0.50828\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 1.9825910987854003, Accuracy: 0.4938\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.044091122589111, Accuracy: 0.51054\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 1.9826785940170288, Accuracy: 0.4957\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.0443821018218995, Accuracy: 0.5098\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 1.982387720489502, Accuracy: 0.4953\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.043515312347412, Accuracy: 0.51016\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 1.9816429927825927, Accuracy: 0.4955\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.0436928118515016, Accuracy: 0.51012\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 1.9815377937316894, Accuracy: 0.4966\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.043670332260132, Accuracy: 0.50916\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 1.9817604984283448, Accuracy: 0.4966\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.0427720066070556, Accuracy: 0.51082\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 1.982066785812378, Accuracy: 0.4962\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.0422631437683108, Accuracy: 0.51048\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 1.9814937854766845, Accuracy: 0.4958\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.042286613235474, Accuracy: 0.5121\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 1.9818190830230713, Accuracy: 0.4947\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.0414698217010496, Accuracy: 0.51292\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 1.9803661956787109, Accuracy: 0.4972\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.0424835861968993, Accuracy: 0.5102\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 1.9803003553390504, Accuracy: 0.4964\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.041349749298096, Accuracy: 0.51368\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 1.9804378726959229, Accuracy: 0.4976\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.0413204066467285, Accuracy: 0.51248\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 1.979897671508789, Accuracy: 0.4964\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.0409103937530517, Accuracy: 0.51354\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 1.9796741579055785, Accuracy: 0.4969\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.0405002323913575, Accuracy: 0.5139\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 1.9793005807876587, Accuracy: 0.4974\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.039684568634033, Accuracy: 0.51656\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 1.9788143268585205, Accuracy: 0.4988\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.03844550819397, Accuracy: 0.51666\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 1.9789105396270752, Accuracy: 0.4989\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.0393556633758543, Accuracy: 0.5161\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 1.9782655429840088, Accuracy: 0.501\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.039949553527832, Accuracy: 0.51548\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 1.978022673034668, Accuracy: 0.5003\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.039615835723877, Accuracy: 0.51526\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 1.9780331987380981, Accuracy: 0.4983\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.0388055955505373, Accuracy: 0.51786\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 1.9782645778656005, Accuracy: 0.499\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.0387858574676514, Accuracy: 0.51662\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 1.9778609226226807, Accuracy: 0.5008\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.038278893585205, Accuracy: 0.51742\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 1.9777893478393556, Accuracy: 0.5005\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.037642088317871, Accuracy: 0.51898\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 1.977769441795349, Accuracy: 0.5003\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.038723033981323, Accuracy: 0.51696\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 1.9771813123703004, Accuracy: 0.4995\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.0374459897613524, Accuracy: 0.5201\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 1.9777405908584595, Accuracy: 0.5012\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.0373731394958496, Accuracy: 0.51976\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 1.9766386722564697, Accuracy: 0.5021\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.0366742114257814, Accuracy: 0.5209\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 1.9766435209274291, Accuracy: 0.4991\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.0369531018066405, Accuracy: 0.52116\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 1.9765567846298218, Accuracy: 0.5007\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.0363295655059814, Accuracy: 0.52098\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 1.9757931903839112, Accuracy: 0.5014\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.0354116091156005, Accuracy: 0.52122\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 1.9763469745635986, Accuracy: 0.5004\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.0362683170318605, Accuracy: 0.52076\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 1.9760627410888671, Accuracy: 0.5019\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.037103680801392, Accuracy: 0.51912\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 1.9753312507629395, Accuracy: 0.5006\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.0357670024108887, Accuracy: 0.52228\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 1.9753122058868409, Accuracy: 0.5023\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.035183604812622, Accuracy: 0.52168\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 1.9750956478118897, Accuracy: 0.5016\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.0358991844177248, Accuracy: 0.5198\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 1.9751115497589111, Accuracy: 0.5024\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.035264906463623, Accuracy: 0.5217\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 1.9742938545227051, Accuracy: 0.5038\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.035816477584839, Accuracy: 0.52292\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 1.9748017436981202, Accuracy: 0.5014\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.0357883115386963, Accuracy: 0.51954\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 1.9744697698593139, Accuracy: 0.5014\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.0349278481674196, Accuracy: 0.52306\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 1.9740950761795044, Accuracy: 0.5025\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.0347716276550294, Accuracy: 0.52438\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 1.9746246543884278, Accuracy: 0.5041\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.034693645095825, Accuracy: 0.52358\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 1.9741017795562743, Accuracy: 0.5034\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.0350159666442873, Accuracy: 0.52486\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 1.973737170791626, Accuracy: 0.5038\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.034623599014282, Accuracy: 0.52354\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 1.973580244064331, Accuracy: 0.503\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.0343078590393064, Accuracy: 0.52462\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 1.9731739498138428, Accuracy: 0.502\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.032735071258545, Accuracy: 0.52652\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 1.9729934507369995, Accuracy: 0.5028\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.0328740181732177, Accuracy: 0.52624\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 1.9731510932922363, Accuracy: 0.5036\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.033617451171875, Accuracy: 0.5245\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 1.9732218135833741, Accuracy: 0.5037\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.0334380619812014, Accuracy: 0.52618\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 1.9725101551055908, Accuracy: 0.5044\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.0327086931610108, Accuracy: 0.52592\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 1.972878151321411, Accuracy: 0.5031\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.032408182601929, Accuracy: 0.52564\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 1.9729839475631714, Accuracy: 0.5021\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.0316365378570556, Accuracy: 0.52872\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 1.9722035568237304, Accuracy: 0.5032\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.032818325576782, Accuracy: 0.52698\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 1.9720081451416016, Accuracy: 0.5051\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.0316262482070924, Accuracy: 0.52624\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 1.972142314338684, Accuracy: 0.5031\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.0329173564529417, Accuracy: 0.5267\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 1.9720339744567872, Accuracy: 0.5043\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.0320036779022215, Accuracy: 0.52854\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 1.9714411079406737, Accuracy: 0.5072\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.031859539642334, Accuracy: 0.52814\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 1.9717690460205077, Accuracy: 0.5049\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.0318884980773926, Accuracy: 0.52678\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 1.9715647260665894, Accuracy: 0.5066\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.031719782180786, Accuracy: 0.52888\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 1.9712080972671508, Accuracy: 0.5071\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.0317122029113768, Accuracy: 0.5282\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 1.970816480255127, Accuracy: 0.5055\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.0312101903533937, Accuracy: 0.52938\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 1.9708632133483888, Accuracy: 0.5064\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.030770359954834, Accuracy: 0.5294\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 1.9710620811462403, Accuracy: 0.5081\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.0314669300079347, Accuracy: 0.53062\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 1.970645468711853, Accuracy: 0.5045\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.031057764968872, Accuracy: 0.53034\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 1.970585563468933, Accuracy: 0.5045\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.0296250009155274, Accuracy: 0.53094\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 1.9700555206298829, Accuracy: 0.5067\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.0306860414886474, Accuracy: 0.53044\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 1.9702096775054931, Accuracy: 0.5051\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.0300992401123046, Accuracy: 0.53104\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 1.9699333080291748, Accuracy: 0.5091\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.0290207263183593, Accuracy: 0.53214\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 1.9700786972045898, Accuracy: 0.5072\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.029303271179199, Accuracy: 0.5315\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 1.9696624572753907, Accuracy: 0.5081\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.0295056311035156, Accuracy: 0.53282\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 1.9699874597549438, Accuracy: 0.5051\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.0299340716934204, Accuracy: 0.53144\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 1.969871856689453, Accuracy: 0.509\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.028887485809326, Accuracy: 0.53224\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 1.96914651222229, Accuracy: 0.5102\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.0289469173431396, Accuracy: 0.53316\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 1.9694434406280517, Accuracy: 0.5073\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.0301326168060303, Accuracy: 0.53192\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 1.9692810398101808, Accuracy: 0.5078\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.0286126946258545, Accuracy: 0.53176\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 1.9689032341003418, Accuracy: 0.5096\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.028619661331177, Accuracy: 0.53282\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 1.9695880958557128, Accuracy: 0.5064\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.0285004656219483, Accuracy: 0.53144\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 1.9689474313735962, Accuracy: 0.5091\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.0285904946899413, Accuracy: 0.53258\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 1.968956559562683, Accuracy: 0.5085\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.028314071655273, Accuracy: 0.53394\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 1.9681625770568847, Accuracy: 0.5087\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.0275224410629273, Accuracy: 0.53584\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 1.9683229251861571, Accuracy: 0.5097\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.0274296716308595, Accuracy: 0.53498\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 1.9682839904785157, Accuracy: 0.5106\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.0284588123703005, Accuracy: 0.53514\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 1.9686517503738403, Accuracy: 0.5096\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.0278053133392335, Accuracy: 0.53484\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 1.968152500152588, Accuracy: 0.5112\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.027179897079468, Accuracy: 0.53676\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 1.9679982717514037, Accuracy: 0.509\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.0284895599365234, Accuracy: 0.53418\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 1.9679505981445313, Accuracy: 0.5092\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.0273299993896483, Accuracy: 0.5364\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 1.9676972087860107, Accuracy: 0.509\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.0278514226531983, Accuracy: 0.5354\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 1.9675657823562622, Accuracy: 0.5103\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.0264807524871826, Accuracy: 0.5376\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 1.9674542251586915, Accuracy: 0.5107\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.0279434101867677, Accuracy: 0.5343\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 1.9672362339019775, Accuracy: 0.5105\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.0275817767333986, Accuracy: 0.53322\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 1.967220096206665, Accuracy: 0.5085\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.0278453200531006, Accuracy: 0.536\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 1.9670812328338623, Accuracy: 0.5107\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.027573780288696, Accuracy: 0.53452\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 1.9664787252426148, Accuracy: 0.5119\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.026844262161255, Accuracy: 0.53714\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 1.9667207540512084, Accuracy: 0.5108\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.0267644969177248, Accuracy: 0.53594\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 1.966476627922058, Accuracy: 0.5121\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.026972962188721, Accuracy: 0.53644\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 1.9667181751251221, Accuracy: 0.51\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.026327973327637, Accuracy: 0.53688\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 1.9668333518981933, Accuracy: 0.5104\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.026534366378784, Accuracy: 0.53752\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 1.9663328952789307, Accuracy: 0.5124\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.0266980425262453, Accuracy: 0.53628\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 1.966036785697937, Accuracy: 0.511\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.025622008972168, Accuracy: 0.53886\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 1.9660936912536622, Accuracy: 0.511\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.0256736154937744, Accuracy: 0.53878\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 1.9661005950927735, Accuracy: 0.5112\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.025258658065796, Accuracy: 0.53946\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 1.9661052110671997, Accuracy: 0.5093\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.0259601690673827, Accuracy: 0.53724\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 1.9661759845733642, Accuracy: 0.5105\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.0257653630065917, Accuracy: 0.53944\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 1.9654400331497193, Accuracy: 0.5114\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.0258656224823, Accuracy: 0.53816\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 1.9655849685668945, Accuracy: 0.5108\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.025642182159424, Accuracy: 0.53922\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 1.9656053136825562, Accuracy: 0.5099\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.0249193804931642, Accuracy: 0.53938\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 1.9655535530090331, Accuracy: 0.5124\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.0262768547821044, Accuracy: 0.539\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 1.9651730567932129, Accuracy: 0.5124\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.0254430155944823, Accuracy: 0.5382\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 1.965023892021179, Accuracy: 0.5133\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.0250618881225586, Accuracy: 0.54072\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 1.9651852684020996, Accuracy: 0.5134\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.0243490935516357, Accuracy: 0.5406\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 1.9647587800979613, Accuracy: 0.5136\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.0251819923400878, Accuracy: 0.53862\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 1.9648252159118653, Accuracy: 0.513\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.0238710427856446, Accuracy: 0.54148\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 1.9651325733184815, Accuracy: 0.5131\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.0238194522857667, Accuracy: 0.54132\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 1.9646812660217285, Accuracy: 0.5122\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.025648315887451, Accuracy: 0.53908\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 1.9645821722030639, Accuracy: 0.5134\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.0249070182800293, Accuracy: 0.5407\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 1.9642486953735352, Accuracy: 0.5125\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.0236040066528322, Accuracy: 0.54208\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 1.9642508499145508, Accuracy: 0.5126\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.022712616882324, Accuracy: 0.54348\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 1.9641769245147704, Accuracy: 0.5125\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.0243136545944216, Accuracy: 0.54166\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 1.9638196865081787, Accuracy: 0.5138\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.024621810455322, Accuracy: 0.54198\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 1.964183288192749, Accuracy: 0.5137\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.0248302734375, Accuracy: 0.54088\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 1.9638125602722167, Accuracy: 0.5138\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.0239348629379275, Accuracy: 0.54094\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 1.9640806898117065, Accuracy: 0.5153\n",
      "[Finished Training with AdaGrad]\n",
      "\n",
      "Total Training Time: 928.891880008392\n"
     ]
    }
   ],
   "source": [
    "model = BasicDropoutNet().to(device)\n",
    "adagrad_optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with AdaGrad]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, adagrad_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "\n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    adagrad_L2D_train_loss.append(train_loss)\n",
    "    adagrad_L2D_validation_loss.append(val_loss)\n",
    "    adagrad_L2D_train_accuracy.append(train_acc)\n",
    "    adagrad_L2D_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with AdaGrad]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD9ltveDPciN"
   },
   "source": [
    "# RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AnfrojBtPciO"
   },
   "outputs": [],
   "source": [
    "rmsprop_L2_train_loss = []\n",
    "rmsprop_L2_validation_loss = []\n",
    "rmsprop_L2_train_accuracy = []\n",
    "rmsprop_L2_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Bo4PPHTPPciO",
    "outputId": "3107d540-f300-471a-aa63-b8f9071821a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with RMSProp]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.25217757850647, Accuracy: 0.26482\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.1157267024993898, Accuracy: 0.3353\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.175664299850464, Accuracy: 0.3445\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.1596078517913817, Accuracy: 0.2925\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.163349464569092, Accuracy: 0.36374\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.066226304626465, Accuracy: 0.3916\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.157805859298706, Accuracy: 0.37206\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.0673573749542236, Accuracy: 0.3895\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.1499687523651123, Accuracy: 0.383\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.077146003341675, Accuracy: 0.3812\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.1434662441253662, Accuracy: 0.39098\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.0996210342407227, Accuracy: 0.3557\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.1390383824157713, Accuracy: 0.3975\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.0570446660995483, Accuracy: 0.3979\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.1350741672515867, Accuracy: 0.40058\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.0654333782196046, Accuracy: 0.3924\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.1304984509277345, Accuracy: 0.40478\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.061630054092407, Accuracy: 0.3912\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.1306115976715088, Accuracy: 0.40788\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.0508304622650146, Accuracy: 0.4076\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.125399150238037, Accuracy: 0.41202\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.0499943645477297, Accuracy: 0.4072\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.1240006297302245, Accuracy: 0.41382\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.033261191368103, Accuracy: 0.4271\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.121642942352295, Accuracy: 0.41872\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.079653712081909, Accuracy: 0.3764\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.121668271331787, Accuracy: 0.42028\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.0576164661407472, Accuracy: 0.3982\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.119033138504028, Accuracy: 0.4225\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.04830304107666, Accuracy: 0.4079\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.1174164902496337, Accuracy: 0.42484\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.0498617362976073, Accuracy: 0.4054\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.1162356732177736, Accuracy: 0.42632\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.043837210083008, Accuracy: 0.4146\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.1143115229797362, Accuracy: 0.4282\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.0388717861175536, Accuracy: 0.4182\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.113244646606445, Accuracy: 0.43114\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.0367763874053955, Accuracy: 0.4214\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.1097278234100343, Accuracy: 0.4346\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.041405668258667, Accuracy: 0.4143\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.1107953463745117, Accuracy: 0.4354\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.047828769302368, Accuracy: 0.4095\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.1103685210418703, Accuracy: 0.43414\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.042979919052124, Accuracy: 0.4173\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.1074635277557374, Accuracy: 0.43856\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.0388177993774415, Accuracy: 0.4204\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.108494041595459, Accuracy: 0.43864\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.0494936851501464, Accuracy: 0.4072\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.1087753438568115, Accuracy: 0.43712\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.027096855545044, Accuracy: 0.4332\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.109833921966553, Accuracy: 0.43538\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.022028392410278, Accuracy: 0.4358\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.104737985610962, Accuracy: 0.44208\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.03156978225708, Accuracy: 0.4265\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.103968597412109, Accuracy: 0.44266\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.0541079265594484, Accuracy: 0.4039\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.1067592777252195, Accuracy: 0.43866\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.04081791343689, Accuracy: 0.4181\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.105604684753418, Accuracy: 0.4403\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.061393702697754, Accuracy: 0.3941\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.1033982852935793, Accuracy: 0.44328\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.047693280410767, Accuracy: 0.4109\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.103100325164795, Accuracy: 0.44374\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.0303390577316285, Accuracy: 0.4277\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.100845527267456, Accuracy: 0.4466\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.0341821041107178, Accuracy: 0.4246\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.102724991912842, Accuracy: 0.44452\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.0949374252319335, Accuracy: 0.3632\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.101887886657715, Accuracy: 0.44222\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 2.0340815034866333, Accuracy: 0.4248\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.1008450494384765, Accuracy: 0.44648\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.0329002014160156, Accuracy: 0.4255\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.1005421530914306, Accuracy: 0.44574\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 2.027075576400757, Accuracy: 0.4325\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.0999290522003173, Accuracy: 0.446\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.017443162727356, Accuracy: 0.4409\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.1001185962677003, Accuracy: 0.44652\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.0688852210998534, Accuracy: 0.3896\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.0990221574401855, Accuracy: 0.44942\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.0252609897613527, Accuracy: 0.4339\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.099279190750122, Accuracy: 0.4476\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.0321703857421873, Accuracy: 0.4263\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.100080849609375, Accuracy: 0.44782\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 2.032297511291504, Accuracy: 0.4264\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.0992791134643554, Accuracy: 0.44946\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 2.014728119277954, Accuracy: 0.4449\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.097749298706055, Accuracy: 0.45036\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 2.0376437637329103, Accuracy: 0.4209\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.0985393759155273, Accuracy: 0.44932\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 2.0149165241241453, Accuracy: 0.4441\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.09844639251709, Accuracy: 0.449\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 2.0307039791107178, Accuracy: 0.4257\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.099089206161499, Accuracy: 0.446\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 2.0167435081481933, Accuracy: 0.4448\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.097505463027954, Accuracy: 0.44844\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 2.0276614070892336, Accuracy: 0.4306\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.097168721847534, Accuracy: 0.45034\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 2.0404948806762695, Accuracy: 0.4181\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.0974541815948484, Accuracy: 0.44906\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 2.0221335641860962, Accuracy: 0.4376\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.0978600273132324, Accuracy: 0.4499\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 2.015551052474976, Accuracy: 0.4451\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.096441072540283, Accuracy: 0.45196\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 2.017510673522949, Accuracy: 0.4425\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.0959690926361083, Accuracy: 0.4525\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 2.0218512502670287, Accuracy: 0.4379\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.095507815170288, Accuracy: 0.45166\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 2.016469569015503, Accuracy: 0.441\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.0977393550872803, Accuracy: 0.45096\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 2.013791930580139, Accuracy: 0.4494\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.0954010816192628, Accuracy: 0.45164\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 2.0222128700256348, Accuracy: 0.4387\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.0957033959198, Accuracy: 0.4514\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 2.0256023262023928, Accuracy: 0.4342\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.094616422729492, Accuracy: 0.4529\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 2.0211797737121584, Accuracy: 0.4386\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.0957017472076416, Accuracy: 0.45262\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 2.0241777198791504, Accuracy: 0.4354\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.095428578910828, Accuracy: 0.452\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 2.0195345169067385, Accuracy: 0.4402\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.0960685485076906, Accuracy: 0.4521\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 2.024213306427002, Accuracy: 0.4361\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.092847985839844, Accuracy: 0.45442\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 2.028789569091797, Accuracy: 0.4329\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.094465275115967, Accuracy: 0.45364\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 2.0265862716674805, Accuracy: 0.4342\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.0953769082641602, Accuracy: 0.45242\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 2.043234368133545, Accuracy: 0.4134\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.0935887728118896, Accuracy: 0.45282\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 2.0065689630508423, Accuracy: 0.4535\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.0917979598999024, Accuracy: 0.45454\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 2.014395744895935, Accuracy: 0.4492\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.09520400428772, Accuracy: 0.4533\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 2.0140769241333007, Accuracy: 0.4457\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.092804797897339, Accuracy: 0.45584\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 2.020622434997559, Accuracy: 0.4392\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.0932698942565917, Accuracy: 0.45358\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 2.0214217882156373, Accuracy: 0.4381\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.0929272885894776, Accuracy: 0.45406\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 2.019359010696411, Accuracy: 0.4411\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.0922829028320313, Accuracy: 0.45564\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 2.0157140779495237, Accuracy: 0.4436\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.093786472167969, Accuracy: 0.4532\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 2.027802137565613, Accuracy: 0.4315\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.0933745806121826, Accuracy: 0.45286\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 2.0354975757598877, Accuracy: 0.4211\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.0937648361968995, Accuracy: 0.45492\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 2.016701229476929, Accuracy: 0.4459\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.092265082550049, Accuracy: 0.4572\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 2.015610098648071, Accuracy: 0.4464\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.093302166595459, Accuracy: 0.45466\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 2.0166325572967527, Accuracy: 0.4416\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.092233392562866, Accuracy: 0.45484\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 2.026326127243042, Accuracy: 0.4318\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.0928228691101074, Accuracy: 0.45506\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 2.0409720039367674, Accuracy: 0.4173\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.092573355636597, Accuracy: 0.45536\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 2.0091947353363038, Accuracy: 0.4505\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.0925524129486086, Accuracy: 0.4554\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 2.035402564239502, Accuracy: 0.4233\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.093647596664429, Accuracy: 0.45378\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 2.028346927642822, Accuracy: 0.4319\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.0914425302886963, Accuracy: 0.45642\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 2.0067417503356935, Accuracy: 0.4538\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.0919424574279786, Accuracy: 0.4572\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 2.0112864351272584, Accuracy: 0.449\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.0937810569763182, Accuracy: 0.45324\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 2.021794135093689, Accuracy: 0.4379\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.0913151558685303, Accuracy: 0.4571\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 2.0118704879760743, Accuracy: 0.4506\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.092201930770874, Accuracy: 0.457\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 2.0133052570343017, Accuracy: 0.4473\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.093061881790161, Accuracy: 0.4552\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 2.014886524581909, Accuracy: 0.4467\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.0928800025177003, Accuracy: 0.45566\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 2.032436699295044, Accuracy: 0.4273\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.0925648796844483, Accuracy: 0.45416\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 2.032999528503418, Accuracy: 0.4259\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.0938546585083007, Accuracy: 0.4545\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 2.050816876411438, Accuracy: 0.4035\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.0930937576293944, Accuracy: 0.45362\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 2.0065772594451903, Accuracy: 0.4563\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.0916763720703124, Accuracy: 0.45774\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 2.0235839389801025, Accuracy: 0.4372\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.093633751602173, Accuracy: 0.45356\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 2.031312024307251, Accuracy: 0.4257\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.092525661468506, Accuracy: 0.45544\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 2.0280862071990966, Accuracy: 0.4333\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.091723179473877, Accuracy: 0.4549\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 2.016806436538696, Accuracy: 0.4436\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.0920877951049803, Accuracy: 0.45642\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 2.0139098911285402, Accuracy: 0.4476\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.0909859201812746, Accuracy: 0.457\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 2.0135742706298827, Accuracy: 0.4449\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.091850591583252, Accuracy: 0.45534\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 2.0139733989715576, Accuracy: 0.4485\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.0914894997406006, Accuracy: 0.4567\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 2.017138000488281, Accuracy: 0.4457\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.091545715560913, Accuracy: 0.45586\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 2.0166153846740724, Accuracy: 0.4464\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.0925020597839357, Accuracy: 0.45386\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 2.0166283782958985, Accuracy: 0.443\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.091021242980957, Accuracy: 0.4571\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 2.0128239433288573, Accuracy: 0.445\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.0911987060546875, Accuracy: 0.45552\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 2.027075015640259, Accuracy: 0.4327\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.0908081681060793, Accuracy: 0.45616\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 2.050801420593262, Accuracy: 0.4065\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.0912883082580564, Accuracy: 0.45512\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 2.045096830368042, Accuracy: 0.4124\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.089980573272705, Accuracy: 0.45754\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 2.016688787460327, Accuracy: 0.4453\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.0908180280303954, Accuracy: 0.45646\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 2.0176556972503663, Accuracy: 0.4391\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.090964630584717, Accuracy: 0.456\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 2.0328385681152343, Accuracy: 0.4239\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.090682794799805, Accuracy: 0.45738\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 2.0052791929244993, Accuracy: 0.4575\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.0906105103302, Accuracy: 0.45726\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 2.0199780559539793, Accuracy: 0.4412\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.0908158636474607, Accuracy: 0.45754\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 2.0173572490692138, Accuracy: 0.4445\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.090426590423584, Accuracy: 0.4577\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 2.0138337251663208, Accuracy: 0.4488\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.090492640762329, Accuracy: 0.45818\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 2.022290585708618, Accuracy: 0.4353\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.0911963068389894, Accuracy: 0.45596\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 2.0469216650009154, Accuracy: 0.4065\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.0892112035369874, Accuracy: 0.45832\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 2.0151103139877318, Accuracy: 0.4456\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.090252373199463, Accuracy: 0.45822\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 2.0108071880340574, Accuracy: 0.4496\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.0891444775390626, Accuracy: 0.4595\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 2.0433983505249023, Accuracy: 0.4118\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.0909194351196287, Accuracy: 0.45732\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 2.025594507598877, Accuracy: 0.4333\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.091413122711182, Accuracy: 0.45448\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 2.019272926902771, Accuracy: 0.4402\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.0906398316192627, Accuracy: 0.45726\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 2.010719013595581, Accuracy: 0.4485\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.0901229922485354, Accuracy: 0.45718\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 2.026973279762268, Accuracy: 0.432\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.0911576306915283, Accuracy: 0.45602\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 2.0195962379455565, Accuracy: 0.4408\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.0891518266296387, Accuracy: 0.45704\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 2.0376438480377197, Accuracy: 0.4155\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.090566654663086, Accuracy: 0.45614\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 2.026931066894531, Accuracy: 0.4314\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.090535017166138, Accuracy: 0.4567\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 2.0087635334014893, Accuracy: 0.4505\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.090289256362915, Accuracy: 0.45632\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 2.0231981283187865, Accuracy: 0.4374\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.0904751160430908, Accuracy: 0.4561\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 2.0263984603881835, Accuracy: 0.436\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.0888733225250244, Accuracy: 0.45732\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 2.029296692657471, Accuracy: 0.4317\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.0898097257232666, Accuracy: 0.45676\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 2.019770475387573, Accuracy: 0.4416\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.091791059799194, Accuracy: 0.4554\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 2.049732386779785, Accuracy: 0.4112\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.0897502475738525, Accuracy: 0.4559\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 2.014436449432373, Accuracy: 0.4495\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.0885124940490725, Accuracy: 0.45918\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 2.0471824306488036, Accuracy: 0.4121\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.0895849465942384, Accuracy: 0.45828\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 2.0438520137786864, Accuracy: 0.4153\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.0895134884643554, Accuracy: 0.45818\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 2.035473650550842, Accuracy: 0.4256\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.090336689376831, Accuracy: 0.45746\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 2.0166919044494627, Accuracy: 0.4444\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.0885285083770753, Accuracy: 0.45934\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 2.013563726425171, Accuracy: 0.4455\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.08911724357605, Accuracy: 0.4573\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 2.030871345901489, Accuracy: 0.4295\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.088446755142212, Accuracy: 0.45872\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 2.032367713356018, Accuracy: 0.4256\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.0892448781585693, Accuracy: 0.45724\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 2.009802642250061, Accuracy: 0.4538\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.089919490890503, Accuracy: 0.45698\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 2.028837805557251, Accuracy: 0.4301\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.087662174072266, Accuracy: 0.45834\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 2.015055864143372, Accuracy: 0.4439\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.0908515673828125, Accuracy: 0.45726\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 2.042687975692749, Accuracy: 0.4148\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.0899081570434572, Accuracy: 0.45836\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 2.0267658929824828, Accuracy: 0.4309\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.088871106185913, Accuracy: 0.45724\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 2.034967067337036, Accuracy: 0.4226\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.08887475730896, Accuracy: 0.45676\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 2.0224723468780517, Accuracy: 0.4345\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.087664266319275, Accuracy: 0.45828\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 2.0479674251556395, Accuracy: 0.4108\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.0893888719177247, Accuracy: 0.45722\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 2.0149140224456787, Accuracy: 0.4445\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.0891868073272706, Accuracy: 0.45718\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 2.0223522624969483, Accuracy: 0.4384\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.091258803024292, Accuracy: 0.45522\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 2.0092833766937255, Accuracy: 0.4532\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.088825703048706, Accuracy: 0.45886\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 2.0317552080154417, Accuracy: 0.4263\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.088991431350708, Accuracy: 0.4583\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 2.0217510021209715, Accuracy: 0.4355\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.0876139785766603, Accuracy: 0.45998\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 2.02618464679718, Accuracy: 0.4331\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.0892995030975343, Accuracy: 0.45824\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 2.0625862131118775, Accuracy: 0.395\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.0890866387939453, Accuracy: 0.45738\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 2.01324951133728, Accuracy: 0.4511\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.0872223414611817, Accuracy: 0.45958\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 2.0170979721069338, Accuracy: 0.4436\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.088985647277832, Accuracy: 0.45772\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 2.0514021106719973, Accuracy: 0.4061\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.0896433813476563, Accuracy: 0.45794\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 2.0136469081878663, Accuracy: 0.4453\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.0891824389648437, Accuracy: 0.45868\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 2.04374090385437, Accuracy: 0.4132\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.089622371444702, Accuracy: 0.45638\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 2.0097960021972656, Accuracy: 0.4495\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.0875619431304933, Accuracy: 0.4591\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 2.051895029449463, Accuracy: 0.4086\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.089740877532959, Accuracy: 0.4576\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 2.013418852996826, Accuracy: 0.4463\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.087395064163208, Accuracy: 0.45968\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 2.009405333328247, Accuracy: 0.455\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.088631432952881, Accuracy: 0.45734\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 2.0635064044952394, Accuracy: 0.3915\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.088724793548584, Accuracy: 0.45862\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 2.023113820266724, Accuracy: 0.4369\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.0880898404693604, Accuracy: 0.45936\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 2.047755863571167, Accuracy: 0.4081\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.0886437031555176, Accuracy: 0.45736\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 2.0181204105377195, Accuracy: 0.444\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.086601840209961, Accuracy: 0.4595\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 2.009454606246948, Accuracy: 0.4526\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.08588041267395, Accuracy: 0.46094\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 2.010006439590454, Accuracy: 0.4506\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.087442451248169, Accuracy: 0.46046\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 2.0207854595184327, Accuracy: 0.4419\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.0870500350189207, Accuracy: 0.46176\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 2.012198480606079, Accuracy: 0.4462\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.088128667678833, Accuracy: 0.45864\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 2.0170823514938356, Accuracy: 0.4391\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.087582847061157, Accuracy: 0.46018\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 2.0149821897506714, Accuracy: 0.4466\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.0876616432189943, Accuracy: 0.45896\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 2.015982014465332, Accuracy: 0.4436\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.0871111944580076, Accuracy: 0.45752\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 2.0076278755187986, Accuracy: 0.4549\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.087535809402466, Accuracy: 0.4601\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 2.022640471458435, Accuracy: 0.4406\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.0866298201751707, Accuracy: 0.46104\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 2.0156526529312133, Accuracy: 0.4446\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.0873991498565676, Accuracy: 0.46044\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 2.0405656562805174, Accuracy: 0.4169\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.0867232608795168, Accuracy: 0.46086\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 2.008223770904541, Accuracy: 0.4513\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.088128391571045, Accuracy: 0.4586\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 2.018915672492981, Accuracy: 0.44\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.086419012756348, Accuracy: 0.46084\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 2.0532862318038942, Accuracy: 0.403\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.0886616745758055, Accuracy: 0.45836\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 2.0118935791015624, Accuracy: 0.4503\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.0870202643585207, Accuracy: 0.45956\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 2.016432108306885, Accuracy: 0.4449\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.087413153076172, Accuracy: 0.4604\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 2.0086977958679197, Accuracy: 0.4533\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.087734269371033, Accuracy: 0.46024\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 2.0135916927337645, Accuracy: 0.4483\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.0875235424804686, Accuracy: 0.45946\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 2.047835784912109, Accuracy: 0.4119\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.0884868968200685, Accuracy: 0.45764\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 2.019277989578247, Accuracy: 0.4411\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.0860930780792235, Accuracy: 0.46106\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 2.0195181585311888, Accuracy: 0.4414\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.088323059310913, Accuracy: 0.45972\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 2.0111359943389893, Accuracy: 0.4496\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.0868004277801515, Accuracy: 0.4596\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 2.0401918561935424, Accuracy: 0.4165\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.087685213165283, Accuracy: 0.45986\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 2.0261698192596436, Accuracy: 0.4353\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.087533644104004, Accuracy: 0.45956\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 2.024980118179321, Accuracy: 0.4313\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.0873468991088866, Accuracy: 0.45924\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 2.0256838623046876, Accuracy: 0.4322\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.0881152587127687, Accuracy: 0.45868\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 2.032878328704834, Accuracy: 0.4271\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.088485036468506, Accuracy: 0.45664\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 2.033031190109253, Accuracy: 0.4263\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.0858638175201416, Accuracy: 0.46062\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 2.0373981277465822, Accuracy: 0.4194\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.08765045211792, Accuracy: 0.45852\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 2.0096832118988037, Accuracy: 0.4526\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.08781114944458, Accuracy: 0.45878\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 2.033731558609009, Accuracy: 0.4251\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.0877873724365235, Accuracy: 0.45876\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 2.0118207748413086, Accuracy: 0.4479\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.0871312282562258, Accuracy: 0.4599\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 2.0131951272964477, Accuracy: 0.4445\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.0866715892791747, Accuracy: 0.46038\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 2.019736529159546, Accuracy: 0.4379\n",
      "[Finished Training with RMSProp]\n",
      "\n",
      "Total Training Time: 921.0949673959985\n"
     ]
    }
   ],
   "source": [
    "model = BasicNet().to(device)\n",
    "rmsp_optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with RMSProp]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, rmsp_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "    \n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    rmsprop_L2_train_loss.append(train_loss)\n",
    "    rmsprop_L2_validation_loss.append(val_loss)\n",
    "    rmsprop_L2_train_accuracy.append(train_acc)\n",
    "    rmsprop_L2_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with RMSProp]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7l4SLMdAPciO"
   },
   "outputs": [],
   "source": [
    "rmsprop_L2D_train_loss = []\n",
    "rmsprop_L2D_validation_loss = []\n",
    "rmsprop_L2D_train_accuracy = []\n",
    "rmsprop_L2D_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-okllazWPciP",
    "outputId": "93617e42-497d-485d-9617-bf46cc3e2aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with RMSProp]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.356487551727295, Accuracy: 0.2454\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.1508689041137696, Accuracy: 0.3019\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.306620450897217, Accuracy: 0.30266\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.1215370151519775, Accuracy: 0.3294\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.3003574145507812, Accuracy: 0.31052\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.118266834259033, Accuracy: 0.3375\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.301130038986206, Accuracy: 0.31414\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.122756209564209, Accuracy: 0.3307\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.3087850171661377, Accuracy: 0.3134\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.165757556152344, Accuracy: 0.2902\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.308614891204834, Accuracy: 0.31254\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.127174494171143, Accuracy: 0.3254\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.306433290634155, Accuracy: 0.31328\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.106305244445801, Accuracy: 0.3458\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.296382357711792, Accuracy: 0.31666\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.131311295700073, Accuracy: 0.3184\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.299042773284912, Accuracy: 0.31304\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.0908156410217287, Accuracy: 0.3631\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.2990426873016356, Accuracy: 0.31656\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.1159325435638427, Accuracy: 0.336\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.300063398361206, Accuracy: 0.31312\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.101554716873169, Accuracy: 0.3521\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.2992367026519775, Accuracy: 0.31448\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.119949164581299, Accuracy: 0.334\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.2951054522705077, Accuracy: 0.31598\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.141081177139282, Accuracy: 0.3101\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.2947216864013673, Accuracy: 0.31714\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.1115611488342285, Accuracy: 0.3397\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.2958314404296876, Accuracy: 0.31652\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.1098332210540773, Accuracy: 0.3436\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.2965667570495607, Accuracy: 0.31828\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.096144464492798, Accuracy: 0.3565\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.2928631941223143, Accuracy: 0.3183\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.1260275810241698, Accuracy: 0.3263\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.291817459869385, Accuracy: 0.31884\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.1137793739318846, Accuracy: 0.339\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.2922644017791747, Accuracy: 0.3206\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.1220460620880126, Accuracy: 0.3295\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.2901879546356203, Accuracy: 0.31842\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.1315463611602783, Accuracy: 0.322\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.293545377731323, Accuracy: 0.31744\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.1070825080871582, Accuracy: 0.3469\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.2911698173522947, Accuracy: 0.32004\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.11568703918457, Accuracy: 0.3381\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.2912946176910403, Accuracy: 0.31982\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.1031180892944334, Accuracy: 0.35\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.2879895111083983, Accuracy: 0.31944\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.108301377105713, Accuracy: 0.3452\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.2916098906707765, Accuracy: 0.31858\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.1053166366577147, Accuracy: 0.347\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.2915679094696046, Accuracy: 0.32314\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.1013743801116944, Accuracy: 0.3515\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.2857292402648928, Accuracy: 0.32584\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.1294649101257326, Accuracy: 0.3221\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.2889041410827637, Accuracy: 0.31968\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.134099360656738, Accuracy: 0.3185\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.284809579620361, Accuracy: 0.3223\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.1094502840042115, Accuracy: 0.3446\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.2856690419769286, Accuracy: 0.32302\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.1098436183929445, Accuracy: 0.3427\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.285973066558838, Accuracy: 0.32256\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.102368147277832, Accuracy: 0.3506\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.285724237442017, Accuracy: 0.32172\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.1225345737457277, Accuracy: 0.3302\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.2871114595794677, Accuracy: 0.32126\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.1138867156982424, Accuracy: 0.3388\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.2861512350463866, Accuracy: 0.32238\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.1089338386535643, Accuracy: 0.3434\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.290349252166748, Accuracy: 0.3211\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 2.1097293128967287, Accuracy: 0.3428\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.283925119781494, Accuracy: 0.32026\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.142062858581543, Accuracy: 0.3072\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.285261510620117, Accuracy: 0.32208\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 2.121874578475952, Accuracy: 0.3293\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.282284356536865, Accuracy: 0.32374\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.11445177192688, Accuracy: 0.3384\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.2840027896118165, Accuracy: 0.32448\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.103499324798584, Accuracy: 0.3514\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.286917368545532, Accuracy: 0.32146\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.1036159389495848, Accuracy: 0.3469\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.280920669326782, Accuracy: 0.3257\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.1056442184448243, Accuracy: 0.3471\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.2836326907348634, Accuracy: 0.32256\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 2.112297518157959, Accuracy: 0.3417\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.2813929205322268, Accuracy: 0.32454\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 2.126729710006714, Accuracy: 0.3289\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.2830243885040282, Accuracy: 0.3215\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 2.0943079849243165, Accuracy: 0.3588\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.2788310847473143, Accuracy: 0.32204\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 2.1130504035949706, Accuracy: 0.3397\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.284748440093994, Accuracy: 0.32226\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 2.1212643047332764, Accuracy: 0.3339\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.2865901135253908, Accuracy: 0.3218\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 2.155692275619507, Accuracy: 0.2983\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.2797585580444335, Accuracy: 0.32504\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 2.1073385158538818, Accuracy: 0.3431\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.2782526708221433, Accuracy: 0.32498\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 2.10858973236084, Accuracy: 0.3438\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.279351502304077, Accuracy: 0.32366\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 2.1098565349578857, Accuracy: 0.3451\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.281798175354004, Accuracy: 0.32138\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 2.120558568572998, Accuracy: 0.3331\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.2771600399780274, Accuracy: 0.32818\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 2.1119873817443846, Accuracy: 0.338\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.277464705734253, Accuracy: 0.32568\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 2.121920225906372, Accuracy: 0.331\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.2792512969970704, Accuracy: 0.32552\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 2.119632424926758, Accuracy: 0.3331\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.278361446533203, Accuracy: 0.32626\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 2.1124894958496094, Accuracy: 0.3407\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.2823214118957518, Accuracy: 0.32354\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 2.0840931953430175, Accuracy: 0.3697\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.284464105834961, Accuracy: 0.3219\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 2.1107186244964597, Accuracy: 0.3418\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.27775130569458, Accuracy: 0.32478\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 2.1066878498077393, Accuracy: 0.3448\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.277731887893677, Accuracy: 0.32426\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 2.0961603771209716, Accuracy: 0.3551\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.2767681162261963, Accuracy: 0.32794\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 2.119197403717041, Accuracy: 0.3343\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.2733440113830565, Accuracy: 0.32608\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 2.1172630615234374, Accuracy: 0.3335\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.2759893856048583, Accuracy: 0.324\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 2.1177724628448487, Accuracy: 0.3362\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.276241252975464, Accuracy: 0.32612\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 2.0950404922485353, Accuracy: 0.3579\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.273363567199707, Accuracy: 0.32534\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 2.0910214733123778, Accuracy: 0.3631\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.2742118144226073, Accuracy: 0.32686\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 2.1229685722351075, Accuracy: 0.33\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.272647709121704, Accuracy: 0.32504\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 2.0891281017303465, Accuracy: 0.3646\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.2758883657073974, Accuracy: 0.3217\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 2.113513134384155, Accuracy: 0.3422\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.275325765686035, Accuracy: 0.32212\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 2.1122474285125734, Accuracy: 0.3426\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.2700485882568358, Accuracy: 0.32896\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 2.1208531288146975, Accuracy: 0.3302\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.2757083900451662, Accuracy: 0.32284\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 2.1306222423553467, Accuracy: 0.3194\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.2736136562347413, Accuracy: 0.32754\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 2.1012535270690917, Accuracy: 0.353\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.2748295069122313, Accuracy: 0.3258\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 2.113657633972168, Accuracy: 0.3397\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.271894959716797, Accuracy: 0.3235\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 2.1036231956481934, Accuracy: 0.35\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.275650164642334, Accuracy: 0.32714\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 2.143456986999512, Accuracy: 0.3114\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.2754159239959715, Accuracy: 0.32562\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 2.1005835681915284, Accuracy: 0.3545\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.2768068255615233, Accuracy: 0.32834\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 2.1051650985717774, Accuracy: 0.3504\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.2699814514160157, Accuracy: 0.32546\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 2.127185825920105, Accuracy: 0.3266\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.2727203997039793, Accuracy: 0.32748\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 2.0925512477874757, Accuracy: 0.362\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.2725612284088137, Accuracy: 0.32802\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 2.096321499633789, Accuracy: 0.358\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.2741904322052, Accuracy: 0.3255\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 2.0874477748870848, Accuracy: 0.3687\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.2772505123901365, Accuracy: 0.3242\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 2.1144795669555663, Accuracy: 0.3378\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.2704985754394533, Accuracy: 0.32662\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 2.1002911071777346, Accuracy: 0.3522\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.2755256494140625, Accuracy: 0.32814\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 2.119833670425415, Accuracy: 0.3336\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.2692830081176756, Accuracy: 0.3291\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 2.1002934328079226, Accuracy: 0.3546\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.270088464279175, Accuracy: 0.3306\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 2.0967232566833496, Accuracy: 0.3571\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.275024467391968, Accuracy: 0.3233\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 2.1013670528411867, Accuracy: 0.3508\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.270814269943237, Accuracy: 0.32842\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 2.1105357261657716, Accuracy: 0.3375\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.2722368977355956, Accuracy: 0.3249\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 2.1394419830322264, Accuracy: 0.3133\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.2694755476379393, Accuracy: 0.32548\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 2.121492714309692, Accuracy: 0.3299\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.269296968765259, Accuracy: 0.32736\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 2.1354081588745117, Accuracy: 0.3165\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.2717629808044433, Accuracy: 0.32712\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 2.0929311210632324, Accuracy: 0.3602\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.2698421752929687, Accuracy: 0.3299\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 2.1129765911102294, Accuracy: 0.3407\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.268084600753784, Accuracy: 0.33096\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 2.094628031730652, Accuracy: 0.3595\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.2660006771850587, Accuracy: 0.32916\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 2.120725608444214, Accuracy: 0.3322\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.265920607757568, Accuracy: 0.329\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 2.121590133666992, Accuracy: 0.3319\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.2733736097717285, Accuracy: 0.32528\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 2.0981821506500244, Accuracy: 0.3544\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.268578036880493, Accuracy: 0.32828\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 2.0940425178527833, Accuracy: 0.3587\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.270202605133057, Accuracy: 0.32672\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 2.0955398544311525, Accuracy: 0.3592\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.2715504040527343, Accuracy: 0.32894\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 2.117516869354248, Accuracy: 0.3376\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.270622261276245, Accuracy: 0.3265\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 2.101141881942749, Accuracy: 0.3512\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.271566225128174, Accuracy: 0.32878\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 2.1008383029937745, Accuracy: 0.3519\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.2662608883666993, Accuracy: 0.32922\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 2.112671531677246, Accuracy: 0.3419\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.2698629667663575, Accuracy: 0.32792\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 2.1145289794921873, Accuracy: 0.3373\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.272276042327881, Accuracy: 0.32632\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 2.122679905319214, Accuracy: 0.33\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.2694033235931395, Accuracy: 0.32888\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 2.1196339023590087, Accuracy: 0.3307\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.2677880821990968, Accuracy: 0.32726\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 2.1043434783935546, Accuracy: 0.3499\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.267639758605957, Accuracy: 0.33026\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 2.087918807220459, Accuracy: 0.3695\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.2689412034606935, Accuracy: 0.32878\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 2.1059719581604, Accuracy: 0.3467\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.2707374781036376, Accuracy: 0.32544\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 2.1017585727691652, Accuracy: 0.3526\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.269697491607666, Accuracy: 0.32816\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 2.11692488861084, Accuracy: 0.3313\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.267760937271118, Accuracy: 0.32926\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 2.100873720932007, Accuracy: 0.3542\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.2653285716247558, Accuracy: 0.32404\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 2.1398139389038087, Accuracy: 0.3124\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.268320075454712, Accuracy: 0.32636\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 2.1172453643798828, Accuracy: 0.3375\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.2676971791839597, Accuracy: 0.32796\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 2.095741244316101, Accuracy: 0.3604\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.267379446105957, Accuracy: 0.32968\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 2.126832139968872, Accuracy: 0.3296\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.267592234954834, Accuracy: 0.32672\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 2.1064436668395996, Accuracy: 0.3479\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.2636080278015136, Accuracy: 0.32988\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 2.124702428817749, Accuracy: 0.3277\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.2682065171051025, Accuracy: 0.32932\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 2.11555378074646, Accuracy: 0.3379\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.269133743972778, Accuracy: 0.325\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 2.1190458587646486, Accuracy: 0.3341\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.2652263191223145, Accuracy: 0.3265\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 2.1295321014404296, Accuracy: 0.3243\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.2641486892700193, Accuracy: 0.3284\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 2.1095216133117676, Accuracy: 0.3439\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.263865918884277, Accuracy: 0.3299\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 2.092537384033203, Accuracy: 0.3616\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.2643818560028075, Accuracy: 0.3282\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 2.109254707336426, Accuracy: 0.3445\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.26708367729187, Accuracy: 0.32684\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 2.110401047515869, Accuracy: 0.3415\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.2635340755462647, Accuracy: 0.32812\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 2.0863801345825195, Accuracy: 0.3693\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.2637013442230223, Accuracy: 0.32786\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 2.0914701137542724, Accuracy: 0.3646\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.263879354248047, Accuracy: 0.3301\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 2.0908741912841795, Accuracy: 0.3637\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.265186840133667, Accuracy: 0.33082\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 2.1126156829833986, Accuracy: 0.3403\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.2630705850219726, Accuracy: 0.33038\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 2.114010573196411, Accuracy: 0.3379\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.2646904820251463, Accuracy: 0.32664\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 2.1172923053741455, Accuracy: 0.3332\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.2613226895141603, Accuracy: 0.3329\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 2.092275875091553, Accuracy: 0.3605\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.266259689941406, Accuracy: 0.32358\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 2.1040985774993897, Accuracy: 0.3502\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.266027981414795, Accuracy: 0.32638\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 2.1013073627471925, Accuracy: 0.3542\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.2679993018341063, Accuracy: 0.3283\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 2.1102941680908205, Accuracy: 0.3433\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.2616364012908936, Accuracy: 0.33186\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 2.103758253479004, Accuracy: 0.3514\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.267851979446411, Accuracy: 0.32856\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 2.1044797178268433, Accuracy: 0.3495\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.265568486480713, Accuracy: 0.32908\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 2.097664429855347, Accuracy: 0.3556\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.266240377807617, Accuracy: 0.32856\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 2.103689057159424, Accuracy: 0.3505\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.263513614883423, Accuracy: 0.32848\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 2.1035321464538574, Accuracy: 0.3493\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.2640610541534425, Accuracy: 0.32982\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 2.108448697280884, Accuracy: 0.3429\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.26409277305603, Accuracy: 0.32978\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 2.142961362838745, Accuracy: 0.3093\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.262839306793213, Accuracy: 0.32952\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 2.127314677429199, Accuracy: 0.3233\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.265864906158447, Accuracy: 0.32816\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 2.099027448272705, Accuracy: 0.3529\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.2613309832000734, Accuracy: 0.32898\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 2.09995767288208, Accuracy: 0.3529\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.2643556878662108, Accuracy: 0.32846\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 2.099545523452759, Accuracy: 0.3558\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.268111202087402, Accuracy: 0.33102\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 2.1101142227172853, Accuracy: 0.3425\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.2651557695007325, Accuracy: 0.3287\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 2.107978356552124, Accuracy: 0.3437\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.2646065675354006, Accuracy: 0.33098\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 2.1175986362457278, Accuracy: 0.3367\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.263699732208252, Accuracy: 0.33012\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 2.1571166221618654, Accuracy: 0.2912\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.26535696937561, Accuracy: 0.33016\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 2.1146100574493407, Accuracy: 0.3412\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.265441639556885, Accuracy: 0.32886\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 2.114787289047241, Accuracy: 0.3404\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.262140183563232, Accuracy: 0.33328\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 2.0990679767608644, Accuracy: 0.3539\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.264768110961914, Accuracy: 0.33052\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 2.1061266944885255, Accuracy: 0.348\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.264591922302246, Accuracy: 0.32548\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 2.106732766342163, Accuracy: 0.3461\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.2619876132965087, Accuracy: 0.33016\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 2.1115548522949217, Accuracy: 0.3456\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.2614403495788573, Accuracy: 0.3296\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 2.1063124961853026, Accuracy: 0.3469\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.264133285827637, Accuracy: 0.3299\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 2.1017934646606444, Accuracy: 0.3527\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.2625255520629883, Accuracy: 0.3305\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 2.09563940448761, Accuracy: 0.3569\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.261635315322876, Accuracy: 0.33076\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 2.1069738037109373, Accuracy: 0.3454\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.2621859033966065, Accuracy: 0.33134\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 2.1219308853149412, Accuracy: 0.3326\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.2654142194366456, Accuracy: 0.32734\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 2.1031540576934815, Accuracy: 0.3518\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.2624717626190187, Accuracy: 0.32804\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 2.1003461837768556, Accuracy: 0.3515\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.2602082579040528, Accuracy: 0.32806\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 2.108398178100586, Accuracy: 0.3457\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.2605818270874023, Accuracy: 0.33048\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 2.0933728679656984, Accuracy: 0.3614\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.263339109725952, Accuracy: 0.32928\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 2.111869355392456, Accuracy: 0.3404\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.2637404274749757, Accuracy: 0.32694\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 2.110307062149048, Accuracy: 0.3423\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.259572107925415, Accuracy: 0.33094\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 2.1242910469055176, Accuracy: 0.3274\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.2647004627227783, Accuracy: 0.33166\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 2.0981630073547364, Accuracy: 0.3563\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.2666528730773927, Accuracy: 0.33042\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 2.1140825925827027, Accuracy: 0.3403\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.262548048629761, Accuracy: 0.33376\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 2.122220001602173, Accuracy: 0.3307\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.262946731796265, Accuracy: 0.33204\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 2.132374270629883, Accuracy: 0.3198\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.2616824402618407, Accuracy: 0.32968\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 2.1198891445159913, Accuracy: 0.3342\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.2596319456481933, Accuracy: 0.33012\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 2.097253593444824, Accuracy: 0.3538\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.2597262071990967, Accuracy: 0.33176\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 2.0957826164245605, Accuracy: 0.3574\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.2615266188812257, Accuracy: 0.329\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 2.1135975067138673, Accuracy: 0.3371\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.26342936088562, Accuracy: 0.32828\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 2.1272716835021974, Accuracy: 0.3222\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.2648806954193117, Accuracy: 0.32934\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 2.098902721786499, Accuracy: 0.3543\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.260352807235718, Accuracy: 0.32984\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 2.088213357543945, Accuracy: 0.366\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.2609861476135253, Accuracy: 0.32992\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 2.106461742401123, Accuracy: 0.3462\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.2616146979522704, Accuracy: 0.32818\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 2.1416122428894044, Accuracy: 0.3096\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.261656933135986, Accuracy: 0.32946\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 2.0901821125030517, Accuracy: 0.3654\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.2638846933746337, Accuracy: 0.32864\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 2.1038830596923828, Accuracy: 0.3523\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.264475643157959, Accuracy: 0.3313\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 2.121105478096008, Accuracy: 0.3317\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.262625351257324, Accuracy: 0.33326\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 2.0851721027374266, Accuracy: 0.3692\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.261651850204468, Accuracy: 0.3315\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 2.104042988586426, Accuracy: 0.3499\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.2633287336730956, Accuracy: 0.33054\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 2.111533749771118, Accuracy: 0.3397\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.261978664627075, Accuracy: 0.3292\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 2.1331388328552245, Accuracy: 0.3223\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.2618290338897706, Accuracy: 0.32974\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 2.1170321662902833, Accuracy: 0.3373\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.2594108740997316, Accuracy: 0.33152\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 2.0984638641357423, Accuracy: 0.3562\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.257358975753784, Accuracy: 0.33342\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 2.104745550918579, Accuracy: 0.3493\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.2639401528930665, Accuracy: 0.32832\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 2.10110594291687, Accuracy: 0.3515\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.263354614944458, Accuracy: 0.32774\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 2.1224911237716673, Accuracy: 0.3297\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.262900685882568, Accuracy: 0.32984\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 2.098200017929077, Accuracy: 0.3536\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.2607738204956056, Accuracy: 0.32982\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 2.1173328620910645, Accuracy: 0.3359\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.260995795669556, Accuracy: 0.32896\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 2.1167757278442383, Accuracy: 0.339\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.260719042816162, Accuracy: 0.33036\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 2.1463234699249267, Accuracy: 0.306\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.263812317047119, Accuracy: 0.33\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 2.1132010795593263, Accuracy: 0.3409\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.259929720993042, Accuracy: 0.33276\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 2.1082799745559693, Accuracy: 0.3463\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.2582814418029784, Accuracy: 0.33266\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 2.109627095031738, Accuracy: 0.3437\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.2609848069763183, Accuracy: 0.33046\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 2.1277997482299806, Accuracy: 0.3248\n",
      "[Finished Training with RMSProp]\n",
      "\n",
      "Total Training Time: 920.1396476849914\n"
     ]
    }
   ],
   "source": [
    "model = BasicDropoutNet().to(device)\n",
    "rmsp_optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with RMSProp]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, rmsp_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "\n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    rmsprop_L2D_train_loss.append(train_loss)\n",
    "    rmsprop_L2D_validation_loss.append(val_loss)\n",
    "    rmsprop_L2D_train_accuracy.append(train_acc)\n",
    "    rmsprop_L2D_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with RMSProp]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjQ_ZMFEPciP"
   },
   "source": [
    "# Adam+Nesterov instead of RMSProp+Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "58rJxpZQPciP"
   },
   "outputs": [],
   "source": [
    "nadam_L2_train_loss = []\n",
    "nadam_L2_validation_loss = []\n",
    "nadam_L2_train_accuracy = []\n",
    "nadam_L2_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "L4Kun6ohPciQ",
    "outputId": "85c26ecd-8ffc-4c17-8579-5f444e75efd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with Adam+Nesterov]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.231214747543335, Accuracy: 0.31454\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.1005032814025877, Accuracy: 0.3556\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.1683457498168943, Accuracy: 0.3595\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.088645698547363, Accuracy: 0.3668\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.1537037731170656, Accuracy: 0.37878\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.0734183879852295, Accuracy: 0.3831\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.146759256515503, Accuracy: 0.39238\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.068698451042175, Accuracy: 0.3883\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.1406165554046632, Accuracy: 0.39902\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.0803059066772462, Accuracy: 0.3751\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.1319981730651856, Accuracy: 0.40974\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.073604839706421, Accuracy: 0.382\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.126322992324829, Accuracy: 0.4176\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.0667667835235597, Accuracy: 0.388\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.1190816357421873, Accuracy: 0.42486\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.0345703983306884, Accuracy: 0.4251\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.116138255004883, Accuracy: 0.42876\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.0545590686798096, Accuracy: 0.3989\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.1099038396453857, Accuracy: 0.43452\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.0270916244506836, Accuracy: 0.4348\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.11102913734436, Accuracy: 0.4355\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.0400108097076415, Accuracy: 0.4181\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.1058610013580323, Accuracy: 0.44174\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.01878024559021, Accuracy: 0.443\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.107615763244629, Accuracy: 0.44306\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.0214345405578613, Accuracy: 0.4355\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.1043319316101075, Accuracy: 0.44638\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.0167970603942873, Accuracy: 0.4459\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.1015915666198732, Accuracy: 0.4504\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.040615118598938, Accuracy: 0.4206\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.10130948425293, Accuracy: 0.45128\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.0181010177612304, Accuracy: 0.4384\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.096189291305542, Accuracy: 0.45434\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.015783582687378, Accuracy: 0.4473\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.0955646967315675, Accuracy: 0.4564\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.015276131820679, Accuracy: 0.4463\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.0957393155670165, Accuracy: 0.45922\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.0079386098861693, Accuracy: 0.4541\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.0947433879089354, Accuracy: 0.45942\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.0041677585601807, Accuracy: 0.4581\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.092918911743164, Accuracy: 0.4621\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.016833759689331, Accuracy: 0.4435\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.0942033756256104, Accuracy: 0.46228\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.0144183223724363, Accuracy: 0.4448\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.095214493103027, Accuracy: 0.46146\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.039627248764038, Accuracy: 0.4204\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.0896840085983275, Accuracy: 0.4659\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.0175765354156496, Accuracy: 0.442\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.090644449005127, Accuracy: 0.46472\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.0067000822067262, Accuracy: 0.4566\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.0926713874053955, Accuracy: 0.46408\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.004897017288208, Accuracy: 0.4554\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.090975807800293, Accuracy: 0.46458\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.0118682765960694, Accuracy: 0.449\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.089464652481079, Accuracy: 0.46806\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.0015513452529907, Accuracy: 0.4622\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.0880681610107423, Accuracy: 0.46796\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.0052761728286743, Accuracy: 0.4578\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.090374129333496, Accuracy: 0.46744\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.0213512660980224, Accuracy: 0.4377\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.0885929610443115, Accuracy: 0.46728\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.0078635124206543, Accuracy: 0.4521\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.088138318862915, Accuracy: 0.46922\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.0078363893508913, Accuracy: 0.4523\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.0882251223754884, Accuracy: 0.4696\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.017352959060669, Accuracy: 0.4456\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.088970733337402, Accuracy: 0.47014\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.0131138776779176, Accuracy: 0.4448\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.0851732275390624, Accuracy: 0.47192\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 1.99967857170105, Accuracy: 0.4634\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.0850789348602294, Accuracy: 0.47068\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.009126345062256, Accuracy: 0.4538\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.0889954147338865, Accuracy: 0.4689\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 1.999310433959961, Accuracy: 0.4669\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.087232657623291, Accuracy: 0.47088\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.01009037361145, Accuracy: 0.4506\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.0866701902770997, Accuracy: 0.47182\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.011846837234497, Accuracy: 0.4493\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.086250325241089, Accuracy: 0.4722\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.0008857763290404, Accuracy: 0.4615\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.0837521782684325, Accuracy: 0.4732\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.0094073608398437, Accuracy: 0.4509\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.0859376837921144, Accuracy: 0.47198\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 2.008944052886963, Accuracy: 0.4515\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.087645280761719, Accuracy: 0.47138\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 1.9999459770202637, Accuracy: 0.4623\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.0878346563720704, Accuracy: 0.47196\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 2.0012833896636963, Accuracy: 0.4589\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.0877887377166746, Accuracy: 0.47198\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 2.008347050476074, Accuracy: 0.4538\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.0866357495117187, Accuracy: 0.47156\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 2.0131322170257566, Accuracy: 0.4477\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.0850695126342775, Accuracy: 0.4728\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 2.005097830963135, Accuracy: 0.4572\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.086767622680664, Accuracy: 0.4709\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 2.0044612384796143, Accuracy: 0.4562\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.084408916015625, Accuracy: 0.4739\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 2.007513272857666, Accuracy: 0.4538\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.0846088426208498, Accuracy: 0.47434\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 2.0065779651641846, Accuracy: 0.4571\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.083634594116211, Accuracy: 0.47562\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 2.0003798400878905, Accuracy: 0.4628\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.0882665798950195, Accuracy: 0.47288\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 2.0105275779724123, Accuracy: 0.4493\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.084541143417358, Accuracy: 0.47414\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 2.0009155784606936, Accuracy: 0.4611\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.082589724807739, Accuracy: 0.47472\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 1.9916758190155028, Accuracy: 0.4721\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.083626304397583, Accuracy: 0.47554\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 2.0040033039093017, Accuracy: 0.4561\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.084749787902832, Accuracy: 0.47488\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 2.0164336902618407, Accuracy: 0.4433\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.0858891646575928, Accuracy: 0.47386\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 2.004796995544434, Accuracy: 0.4585\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.083131519088745, Accuracy: 0.47384\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 2.002832602882385, Accuracy: 0.4603\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.082849454193115, Accuracy: 0.47592\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 2.0014208423614503, Accuracy: 0.4588\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.0842565965270996, Accuracy: 0.47422\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 2.005139534378052, Accuracy: 0.458\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.0829330466461182, Accuracy: 0.47456\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 2.012718446350098, Accuracy: 0.4474\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.0816887922668457, Accuracy: 0.47518\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 2.0025244564056397, Accuracy: 0.4619\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.0864831282043457, Accuracy: 0.47408\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 1.9970439310073853, Accuracy: 0.4671\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.0821073714447023, Accuracy: 0.47722\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 2.0061472047805786, Accuracy: 0.4551\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.08319915473938, Accuracy: 0.47478\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 2.019428077697754, Accuracy: 0.438\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.0847587662506104, Accuracy: 0.4739\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 2.008564942932129, Accuracy: 0.4511\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.084250978851318, Accuracy: 0.4739\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 2.0008687852859497, Accuracy: 0.4619\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.0819291045379638, Accuracy: 0.477\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 2.0062604064941407, Accuracy: 0.4528\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.0836848781585693, Accuracy: 0.47436\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 2.007496061325073, Accuracy: 0.4545\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.081356810913086, Accuracy: 0.47812\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 2.0147600532531738, Accuracy: 0.4454\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.081721802444458, Accuracy: 0.47662\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 2.000142311668396, Accuracy: 0.4604\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.081989162750244, Accuracy: 0.47382\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 1.9958386720657348, Accuracy: 0.4629\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.0807374877929687, Accuracy: 0.4762\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 2.0107104274749754, Accuracy: 0.4501\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.0799001878356935, Accuracy: 0.47868\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 2.0080528503417967, Accuracy: 0.4539\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.0830662664794923, Accuracy: 0.47862\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 2.004007767486572, Accuracy: 0.4583\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.083799797897339, Accuracy: 0.47546\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 2.0078775619506835, Accuracy: 0.452\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.084997591590881, Accuracy: 0.47486\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 1.9979882484436036, Accuracy: 0.463\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.0820842580413816, Accuracy: 0.47782\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 2.0018689067840576, Accuracy: 0.4606\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.082613414306641, Accuracy: 0.47698\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 2.0091293979644775, Accuracy: 0.4527\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.076475147781372, Accuracy: 0.47958\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 2.003050185775757, Accuracy: 0.4579\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.0825936014556885, Accuracy: 0.47686\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 2.0129387466430666, Accuracy: 0.4486\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.080827458267212, Accuracy: 0.47862\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 2.0045652294158938, Accuracy: 0.4572\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.0821646406555177, Accuracy: 0.47744\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 2.0067421714782716, Accuracy: 0.4519\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.0787966187286377, Accuracy: 0.4791\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 2.000627116394043, Accuracy: 0.4607\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.079038982925415, Accuracy: 0.47886\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 1.9943750144958496, Accuracy: 0.4666\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.0805455294036865, Accuracy: 0.47848\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 2.015684366607666, Accuracy: 0.4405\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.0826595391082763, Accuracy: 0.47758\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 2.0009194561004637, Accuracy: 0.4595\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.082558805847168, Accuracy: 0.47744\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 2.008855330657959, Accuracy: 0.4508\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.0795348389434816, Accuracy: 0.47684\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 2.0057257837295532, Accuracy: 0.4575\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.0797114422607423, Accuracy: 0.47796\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 2.005569953727722, Accuracy: 0.4575\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.0803643700408934, Accuracy: 0.47896\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 2.01419761428833, Accuracy: 0.4461\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.08015952003479, Accuracy: 0.47924\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 2.0123826930999758, Accuracy: 0.4475\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.080987011566162, Accuracy: 0.47774\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 2.0071821506500243, Accuracy: 0.4539\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.0812979788208006, Accuracy: 0.47818\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 2.0060995067596434, Accuracy: 0.4547\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.079597004470825, Accuracy: 0.47792\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 2.0020983224868774, Accuracy: 0.4602\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.0789965159606933, Accuracy: 0.47946\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 2.0178695917129517, Accuracy: 0.4434\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.081283885421753, Accuracy: 0.47722\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 2.000153031730652, Accuracy: 0.4639\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.081481788787842, Accuracy: 0.4763\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 1.9969413314819335, Accuracy: 0.4636\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.0796637701416016, Accuracy: 0.47932\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 2.017259181213379, Accuracy: 0.4432\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.077392552947998, Accuracy: 0.4804\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 1.9986575119018555, Accuracy: 0.462\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.07865950920105, Accuracy: 0.48086\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 2.002776678466797, Accuracy: 0.459\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.080791665878296, Accuracy: 0.47828\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 2.008967830467224, Accuracy: 0.4495\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.0789380799102783, Accuracy: 0.4814\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 2.0109137607574463, Accuracy: 0.4488\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.078871222000122, Accuracy: 0.47952\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 1.9993986881256103, Accuracy: 0.463\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.0770554943084716, Accuracy: 0.47988\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 2.000105361175537, Accuracy: 0.4625\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.0788886978149415, Accuracy: 0.48004\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 1.9967293437957763, Accuracy: 0.4652\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.081176295776367, Accuracy: 0.47662\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 2.0043906753540037, Accuracy: 0.4573\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.0819334051513674, Accuracy: 0.47832\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 2.005104326248169, Accuracy: 0.4577\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.0799996180725095, Accuracy: 0.4788\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 1.9950513862609864, Accuracy: 0.4655\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.0791643550109864, Accuracy: 0.4787\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 2.007749855422974, Accuracy: 0.4517\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.0797093674468994, Accuracy: 0.4776\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 2.010290334892273, Accuracy: 0.4491\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.0807386724090575, Accuracy: 0.47814\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 2.0007439449310302, Accuracy: 0.4615\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.077450069961548, Accuracy: 0.4813\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 2.0075252670288086, Accuracy: 0.4522\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.080843751678467, Accuracy: 0.4781\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 1.9968602029800415, Accuracy: 0.467\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.076025144958496, Accuracy: 0.48234\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 1.999974984741211, Accuracy: 0.463\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.0770213229370116, Accuracy: 0.48024\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 2.002749016571045, Accuracy: 0.4596\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.0793605685424805, Accuracy: 0.47934\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 2.001241239929199, Accuracy: 0.4589\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.078933174133301, Accuracy: 0.47998\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 2.000705662727356, Accuracy: 0.4633\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.07605377243042, Accuracy: 0.48042\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 2.0044730367660524, Accuracy: 0.4586\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.0830461572265624, Accuracy: 0.47836\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 1.9953614532470703, Accuracy: 0.4688\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.0763493242645263, Accuracy: 0.48144\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 1.9951855892181396, Accuracy: 0.467\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.0797903357696534, Accuracy: 0.47868\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 1.999945518875122, Accuracy: 0.4624\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.079634432144165, Accuracy: 0.48088\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 1.9974132932662965, Accuracy: 0.4673\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.0773594214248656, Accuracy: 0.4818\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 1.9945532047271728, Accuracy: 0.4711\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.0761232402038576, Accuracy: 0.4818\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 2.006983361816406, Accuracy: 0.4544\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.0774763748931884, Accuracy: 0.4799\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 2.0081196880340575, Accuracy: 0.4534\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.076305431060791, Accuracy: 0.4829\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 1.9988308471679688, Accuracy: 0.463\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.0762472891235353, Accuracy: 0.48244\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 1.9971756900787354, Accuracy: 0.4627\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.0769381131744384, Accuracy: 0.48114\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 1.9971945446014405, Accuracy: 0.4673\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.0796055841827394, Accuracy: 0.48028\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 2.0000103118896484, Accuracy: 0.4604\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.0782733251953127, Accuracy: 0.48198\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 1.9922255546569825, Accuracy: 0.4695\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.0758349468231203, Accuracy: 0.48332\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 1.9949301822662353, Accuracy: 0.4676\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.0775625415802, Accuracy: 0.4805\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 1.9975222270965576, Accuracy: 0.4617\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.076865829925537, Accuracy: 0.48144\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 2.0070851608276365, Accuracy: 0.4516\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.0770767557525636, Accuracy: 0.48074\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 2.0080199855804444, Accuracy: 0.4531\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.077398148651123, Accuracy: 0.48032\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 2.0071792037963867, Accuracy: 0.4545\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.0770015392303467, Accuracy: 0.48088\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 1.99587163105011, Accuracy: 0.4654\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.075683796234131, Accuracy: 0.48164\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 2.0080564331054687, Accuracy: 0.4537\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.0778614097595214, Accuracy: 0.48074\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 1.9963295478820802, Accuracy: 0.4637\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.076982628479004, Accuracy: 0.48118\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 1.991833563041687, Accuracy: 0.4714\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.076477869300842, Accuracy: 0.48252\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 1.9934375701904297, Accuracy: 0.4671\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.0766675943756105, Accuracy: 0.48452\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 1.9950355094909669, Accuracy: 0.4648\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.0749541037750245, Accuracy: 0.48222\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 2.0011172519683837, Accuracy: 0.4623\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.078744396743774, Accuracy: 0.48088\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 1.9959154075622558, Accuracy: 0.4633\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.076775809249878, Accuracy: 0.48236\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 2.0003640398025513, Accuracy: 0.4626\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.079502633895874, Accuracy: 0.47752\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 2.0015832973480223, Accuracy: 0.4616\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.0775136303710937, Accuracy: 0.48158\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 1.9951632904052734, Accuracy: 0.4696\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.074821978530884, Accuracy: 0.48332\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 1.9965737461090087, Accuracy: 0.4668\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.0783068436431886, Accuracy: 0.48204\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 1.9981732963562011, Accuracy: 0.4649\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.0768676758575437, Accuracy: 0.48156\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 1.9946844507217407, Accuracy: 0.4665\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.0743558684539796, Accuracy: 0.48214\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 1.9973716438293456, Accuracy: 0.4646\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.080702005081177, Accuracy: 0.48144\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 2.0011053327560426, Accuracy: 0.4582\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.0797201832580567, Accuracy: 0.48016\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 1.9992507358551026, Accuracy: 0.4624\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.07553102973938, Accuracy: 0.48402\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 1.9974109539031983, Accuracy: 0.4685\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.076340467071533, Accuracy: 0.4817\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 2.0027844856262207, Accuracy: 0.4579\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.0766266403198244, Accuracy: 0.48268\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 1.9998984939575195, Accuracy: 0.4606\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.076487353439331, Accuracy: 0.48296\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 1.9964053764343261, Accuracy: 0.4664\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.075065687484741, Accuracy: 0.48172\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 2.004353274154663, Accuracy: 0.4585\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.075326799621582, Accuracy: 0.4839\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 1.9957970001220704, Accuracy: 0.471\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.07436241607666, Accuracy: 0.48434\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 1.998400131225586, Accuracy: 0.4632\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.077057141876221, Accuracy: 0.4829\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 2.007566551208496, Accuracy: 0.454\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.076645300140381, Accuracy: 0.48226\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 2.0017215103149413, Accuracy: 0.4596\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.0770628762054444, Accuracy: 0.4804\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 1.995710140991211, Accuracy: 0.468\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.077507254562378, Accuracy: 0.47994\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 2.0055432664871216, Accuracy: 0.456\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.074549244918823, Accuracy: 0.48244\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 1.997097571182251, Accuracy: 0.4632\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.073523863372803, Accuracy: 0.48302\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 1.9990013244628906, Accuracy: 0.4625\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.0777249965667726, Accuracy: 0.48152\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 1.9949154960632325, Accuracy: 0.4691\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.075653311843872, Accuracy: 0.48346\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 1.9997593685150146, Accuracy: 0.4589\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.075889044570923, Accuracy: 0.48144\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 1.9992791561126708, Accuracy: 0.4597\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.0740064965820313, Accuracy: 0.48396\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 2.00089577331543, Accuracy: 0.4645\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.0773604149627687, Accuracy: 0.48284\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 1.9958774864196778, Accuracy: 0.4698\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.0759599449157715, Accuracy: 0.48216\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 1.9992313716888428, Accuracy: 0.4624\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.075647487258911, Accuracy: 0.48212\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 2.00530322265625, Accuracy: 0.4555\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.0749367492675783, Accuracy: 0.4829\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 2.0178436408996583, Accuracy: 0.4439\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.0757167184448244, Accuracy: 0.48356\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 2.005881860923767, Accuracy: 0.4561\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.076463814315796, Accuracy: 0.48296\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 1.99180040435791, Accuracy: 0.4727\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.0748802919006346, Accuracy: 0.48482\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 1.9993226612091064, Accuracy: 0.4614\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.0730144105529784, Accuracy: 0.48578\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 2.0031967559814454, Accuracy: 0.4542\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.078183071517944, Accuracy: 0.48234\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 2.000990579223633, Accuracy: 0.4603\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.075298415298462, Accuracy: 0.48432\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 1.9945587326049805, Accuracy: 0.4672\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.0737439423370363, Accuracy: 0.48446\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 2.002574352645874, Accuracy: 0.4602\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.0760420574951173, Accuracy: 0.4832\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 2.0017068546295165, Accuracy: 0.4591\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.076635102005005, Accuracy: 0.48136\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 1.9979903301239013, Accuracy: 0.4653\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.07378973487854, Accuracy: 0.48418\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 1.99260570602417, Accuracy: 0.4694\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.0738023253631592, Accuracy: 0.48666\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 1.9969076555252074, Accuracy: 0.4651\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.074860503768921, Accuracy: 0.48326\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 1.9993943601608277, Accuracy: 0.4642\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.074798877487183, Accuracy: 0.48564\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 2.0068501747131346, Accuracy: 0.4548\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.0753753594970705, Accuracy: 0.48378\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 2.0047455141067503, Accuracy: 0.4553\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.0765599359130857, Accuracy: 0.48358\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 1.9963352081298829, Accuracy: 0.4649\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.0742600051879885, Accuracy: 0.48422\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 1.9982435810089112, Accuracy: 0.465\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.0758054582214354, Accuracy: 0.4843\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 1.9956795261383056, Accuracy: 0.4675\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.07418790184021, Accuracy: 0.48424\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 1.9973916732788086, Accuracy: 0.4634\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.075020997924805, Accuracy: 0.48322\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 2.0017473712921143, Accuracy: 0.4599\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.0747640629577635, Accuracy: 0.4826\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 2.008246357727051, Accuracy: 0.4562\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.076110143737793, Accuracy: 0.48428\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 1.9974253078460693, Accuracy: 0.4684\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.077448451538086, Accuracy: 0.48132\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 2.0000869905471803, Accuracy: 0.4612\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.0762023793792723, Accuracy: 0.4827\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 2.0057940170288084, Accuracy: 0.4552\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.0744770252227784, Accuracy: 0.48132\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 1.9949871286392211, Accuracy: 0.4687\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.074865372085571, Accuracy: 0.48378\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 2.0015913423538207, Accuracy: 0.4613\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.0742709017944336, Accuracy: 0.48382\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 2.0080984191894533, Accuracy: 0.4535\n",
      "[Finished Training with Adam+Nesterov]\n",
      "\n",
      "Total Training Time: 919.6869753077626\n"
     ]
    }
   ],
   "source": [
    "model = BasicNet().to(device)\n",
    "nadam_optimizer = optim.NAdam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with Adam+Nesterov]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, nadam_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "\n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    nadam_L2_train_loss.append(train_loss)\n",
    "    nadam_L2_validation_loss.append(val_loss)\n",
    "    nadam_L2_train_accuracy.append(train_acc)\n",
    "    nadam_L2_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with Adam+Nesterov]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vuLEdv8tPciQ"
   },
   "outputs": [],
   "source": [
    "nadam_L2D_train_loss = []\n",
    "nadam_L2D_validation_loss = []\n",
    "nadam_L2D_train_accuracy = []\n",
    "nadam_L2D_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Hi1fi1sqPciQ",
    "outputId": "746f804a-6c9f-46db-870f-e69b77fc5507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with Adam+Nesterov]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.34330686378479, Accuracy: 0.29928\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.1397062730789185, Accuracy: 0.3132\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.3062360012054444, Accuracy: 0.31718\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.1136447288513183, Accuracy: 0.3373\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.306551409225464, Accuracy: 0.3248\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.1110321491241457, Accuracy: 0.3428\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.3004896080017088, Accuracy: 0.32508\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.130937790298462, Accuracy: 0.3189\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.294539104232788, Accuracy: 0.32648\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.1416740283966065, Accuracy: 0.3127\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.29704870262146, Accuracy: 0.32818\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.1077891780853273, Accuracy: 0.3458\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.299006272354126, Accuracy: 0.3256\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.1220956493377687, Accuracy: 0.3316\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.300623125076294, Accuracy: 0.32728\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.1163146717071535, Accuracy: 0.3379\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.2949001327514646, Accuracy: 0.32884\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.1062735237121584, Accuracy: 0.3487\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.2876679309082033, Accuracy: 0.33022\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.0935449512481688, Accuracy: 0.3613\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.2995454063415526, Accuracy: 0.32894\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.0938242092132566, Accuracy: 0.36\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.292518900680542, Accuracy: 0.33322\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.091195983123779, Accuracy: 0.3613\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.2969849897766115, Accuracy: 0.33162\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.1083127494812013, Accuracy: 0.3433\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.299901252746582, Accuracy: 0.33056\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.0921910915374755, Accuracy: 0.3611\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.298353891143799, Accuracy: 0.3314\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.098102433013916, Accuracy: 0.3538\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.3020619467926027, Accuracy: 0.32812\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.107339611053467, Accuracy: 0.3451\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.2927386126708984, Accuracy: 0.3359\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.111153396987915, Accuracy: 0.3411\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.2969080252075194, Accuracy: 0.33356\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.0888714088439944, Accuracy: 0.3664\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.297402535247803, Accuracy: 0.3305\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.1030333499908447, Accuracy: 0.3495\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.2981043964385988, Accuracy: 0.32856\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.0835153787612914, Accuracy: 0.3719\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.2956969744873046, Accuracy: 0.33294\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.1084996337890627, Accuracy: 0.3462\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.2994379795074464, Accuracy: 0.33098\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.1092210704803467, Accuracy: 0.3449\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.2961977157592774, Accuracy: 0.3303\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.1017281379699706, Accuracy: 0.3511\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.303440601043701, Accuracy: 0.328\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.1063219244003295, Accuracy: 0.3459\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.290620954437256, Accuracy: 0.33082\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.089849800872803, Accuracy: 0.3639\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.2884712870788575, Accuracy: 0.33422\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.10272631855011, Accuracy: 0.3479\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.295762075881958, Accuracy: 0.32964\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.0892859519958495, Accuracy: 0.3634\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.2910015762329103, Accuracy: 0.33512\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.0886936305999755, Accuracy: 0.3667\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.291413797454834, Accuracy: 0.33174\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.0922852512359618, Accuracy: 0.3619\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.2870839804840086, Accuracy: 0.33152\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.108722567939758, Accuracy: 0.3443\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.293191489639282, Accuracy: 0.33212\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.1120453121185303, Accuracy: 0.3387\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.2958763711547854, Accuracy: 0.3313\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.094314708328247, Accuracy: 0.3605\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.3059158876800536, Accuracy: 0.32902\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.095841232299805, Accuracy: 0.3579\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.29519201675415, Accuracy: 0.33174\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.0925807304382325, Accuracy: 0.3621\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.2910403901672365, Accuracy: 0.33372\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 2.0981045001983643, Accuracy: 0.3556\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.2985587853240967, Accuracy: 0.33134\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.109908739089966, Accuracy: 0.3424\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.3011926251220705, Accuracy: 0.33278\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 2.0981938760757446, Accuracy: 0.3562\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.2955302025604247, Accuracy: 0.33068\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.105402959442139, Accuracy: 0.3466\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.2967251667022706, Accuracy: 0.33292\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.1059490861892702, Accuracy: 0.3472\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.292202032165527, Accuracy: 0.33376\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.0959439308166505, Accuracy: 0.3571\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.2912083275604247, Accuracy: 0.33114\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.0951105590820314, Accuracy: 0.3583\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.298935171585083, Accuracy: 0.33252\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 2.105810763931274, Accuracy: 0.3481\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.301901549682617, Accuracy: 0.33028\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 2.096591455078125, Accuracy: 0.3567\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.2976139221191407, Accuracy: 0.32968\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 2.116847523498535, Accuracy: 0.3355\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.2957091067504884, Accuracy: 0.33206\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 2.101680542373657, Accuracy: 0.3521\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.3026905368041994, Accuracy: 0.33124\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 2.109859814453125, Accuracy: 0.3446\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.2885932411193846, Accuracy: 0.33396\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 2.0858314746856688, Accuracy: 0.3693\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.2824974494171144, Accuracy: 0.33582\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 2.1020776481628416, Accuracy: 0.3526\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.295947770233154, Accuracy: 0.33294\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 2.0942572771072387, Accuracy: 0.3612\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.297422098007202, Accuracy: 0.32866\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 2.1042442768096925, Accuracy: 0.3488\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.297134221343994, Accuracy: 0.32838\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 2.0987934814453126, Accuracy: 0.3565\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.2971426126098633, Accuracy: 0.32866\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 2.1174109413146973, Accuracy: 0.3357\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.2968913179779054, Accuracy: 0.33104\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 2.0945041173934937, Accuracy: 0.3589\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.2981496774291994, Accuracy: 0.32918\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 2.0941352462768554, Accuracy: 0.361\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.295983367462158, Accuracy: 0.33232\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 2.1117333862304686, Accuracy: 0.3416\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.3069621432495118, Accuracy: 0.328\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 2.097980334854126, Accuracy: 0.3555\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.294539560852051, Accuracy: 0.3312\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 2.0997884979248047, Accuracy: 0.3578\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.2883214878845215, Accuracy: 0.3328\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 2.112028228759766, Accuracy: 0.3411\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.293245415878296, Accuracy: 0.33054\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 2.090864163208008, Accuracy: 0.3619\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.2933597082519532, Accuracy: 0.33222\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 2.1013745355606077, Accuracy: 0.3531\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.295410195159912, Accuracy: 0.33118\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 2.107231297302246, Accuracy: 0.3446\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.294821899795532, Accuracy: 0.3305\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 2.1138944618225097, Accuracy: 0.3411\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.2957146924591063, Accuracy: 0.33032\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 2.1006128940582274, Accuracy: 0.3541\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.29868773727417, Accuracy: 0.33156\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 2.118710634994507, Accuracy: 0.3338\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.2983800044250486, Accuracy: 0.33048\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 2.07877912979126, Accuracy: 0.3774\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.29608634765625, Accuracy: 0.32816\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 2.120651119995117, Accuracy: 0.334\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.2944855461883544, Accuracy: 0.3291\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 2.0828534379959107, Accuracy: 0.3712\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.2996617945861817, Accuracy: 0.33008\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 2.10951174621582, Accuracy: 0.3416\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.287827834625244, Accuracy: 0.32986\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 2.0904456199645995, Accuracy: 0.362\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.293272214279175, Accuracy: 0.33426\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 2.0887571174621584, Accuracy: 0.3655\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.2973145906829835, Accuracy: 0.32972\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 2.1167971385955813, Accuracy: 0.3358\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.2916315719604494, Accuracy: 0.33168\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 2.0898335845947265, Accuracy: 0.3641\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.286472888031006, Accuracy: 0.33404\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 2.1027650241851807, Accuracy: 0.3502\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.2883433196258545, Accuracy: 0.3323\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 2.1094093223571777, Accuracy: 0.3439\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.2861639072418214, Accuracy: 0.33178\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 2.092869208908081, Accuracy: 0.3601\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.295422896270752, Accuracy: 0.33084\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 2.0986913772583007, Accuracy: 0.3562\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.2953746675109863, Accuracy: 0.33208\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 2.1119315174102784, Accuracy: 0.3405\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.3010559565734865, Accuracy: 0.328\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 2.1112293323516846, Accuracy: 0.3449\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.2962376846313477, Accuracy: 0.32856\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 2.0917949447631834, Accuracy: 0.3636\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.299269019012451, Accuracy: 0.32658\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 2.1021920051574705, Accuracy: 0.3498\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.2904687450408936, Accuracy: 0.33244\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 2.0982505739212036, Accuracy: 0.3557\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.29883669883728, Accuracy: 0.32628\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 2.1045312660217284, Accuracy: 0.3483\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.297399990005493, Accuracy: 0.32852\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 2.0958984073638915, Accuracy: 0.3567\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.2978370362091063, Accuracy: 0.32948\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 2.134538442993164, Accuracy: 0.3171\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.291762810897827, Accuracy: 0.33226\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 2.1106779457092286, Accuracy: 0.3425\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.2995312925720213, Accuracy: 0.32926\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 2.0972510116577148, Accuracy: 0.3556\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.3070671933746336, Accuracy: 0.3274\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 2.1040102264404297, Accuracy: 0.35\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.295812295150757, Accuracy: 0.33126\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 2.1000953033447267, Accuracy: 0.352\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.3065844315338135, Accuracy: 0.33004\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 2.0869677003860474, Accuracy: 0.3667\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.298946329040527, Accuracy: 0.33164\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 2.095914637374878, Accuracy: 0.3602\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.2948460082244875, Accuracy: 0.33502\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 2.0916051612854005, Accuracy: 0.3606\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.3011173136138914, Accuracy: 0.32934\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 2.1063959814071653, Accuracy: 0.3473\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.2940660049438475, Accuracy: 0.3336\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 2.1113237239837646, Accuracy: 0.3407\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.2940446171569824, Accuracy: 0.33128\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 2.0957491720199584, Accuracy: 0.3578\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.288600503997803, Accuracy: 0.33328\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 2.072380689239502, Accuracy: 0.3885\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.2896039281463625, Accuracy: 0.3334\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 2.1031886428833007, Accuracy: 0.3508\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.2961453100585936, Accuracy: 0.33278\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 2.0904717555999754, Accuracy: 0.3649\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.2884553189086914, Accuracy: 0.3334\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 2.089883604431152, Accuracy: 0.3657\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.293732784576416, Accuracy: 0.3331\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 2.083969532394409, Accuracy: 0.3713\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.29809589881897, Accuracy: 0.32654\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 2.1112541984558106, Accuracy: 0.3415\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.2869551276397706, Accuracy: 0.3298\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 2.0957745666503906, Accuracy: 0.3569\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.2915798891448973, Accuracy: 0.3301\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 2.0933023736953738, Accuracy: 0.3606\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.293108913040161, Accuracy: 0.33024\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 2.0935674858093263, Accuracy: 0.3592\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.290271063995361, Accuracy: 0.3306\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 2.0971571369171143, Accuracy: 0.3594\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.299084908065796, Accuracy: 0.3284\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 2.102096020126343, Accuracy: 0.3502\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.2963192127227785, Accuracy: 0.3311\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 2.098009972000122, Accuracy: 0.3572\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.295043121795654, Accuracy: 0.32966\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 2.097242716217041, Accuracy: 0.3531\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.2948791954803465, Accuracy: 0.33104\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 2.127484600830078, Accuracy: 0.327\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.2964751696014405, Accuracy: 0.33188\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 2.1052414627075193, Accuracy: 0.3467\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.2914273224639894, Accuracy: 0.3321\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 2.0887344898223876, Accuracy: 0.3657\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.2923309712982176, Accuracy: 0.33048\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 2.099788236808777, Accuracy: 0.3532\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.297562176361084, Accuracy: 0.33148\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 2.0916680667877197, Accuracy: 0.3593\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.296187723083496, Accuracy: 0.33502\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 2.0982959342956544, Accuracy: 0.3542\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.3009734016418455, Accuracy: 0.32874\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 2.0901092807769777, Accuracy: 0.3651\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.2897181773376465, Accuracy: 0.33448\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 2.102416915512085, Accuracy: 0.3506\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.3010438537597655, Accuracy: 0.3277\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 2.110787875366211, Accuracy: 0.3438\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.2932090274810792, Accuracy: 0.33032\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 2.1036490005493165, Accuracy: 0.35\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.3003446113586428, Accuracy: 0.3285\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 2.1000342010498048, Accuracy: 0.3551\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.2982625900268556, Accuracy: 0.3244\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 2.0964363567352295, Accuracy: 0.3573\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.291339436264038, Accuracy: 0.33458\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 2.1158978931427, Accuracy: 0.3361\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.290423094406128, Accuracy: 0.32956\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 2.0838671155929567, Accuracy: 0.3709\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.2963708837890624, Accuracy: 0.3358\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 2.095048391723633, Accuracy: 0.3596\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.304325230636597, Accuracy: 0.33102\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 2.0856580394744872, Accuracy: 0.3691\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.303527283706665, Accuracy: 0.329\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 2.103277674102783, Accuracy: 0.3506\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.3004681214904785, Accuracy: 0.33078\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 2.10528977355957, Accuracy: 0.3473\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.295676776123047, Accuracy: 0.33168\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 2.102045680618286, Accuracy: 0.3547\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.2943581242370605, Accuracy: 0.32974\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 2.0912867443084715, Accuracy: 0.3635\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.2943296669769286, Accuracy: 0.32988\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 2.08810385017395, Accuracy: 0.3666\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.2982303605651855, Accuracy: 0.33174\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 2.0904330715179444, Accuracy: 0.3645\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.293751230316162, Accuracy: 0.33046\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 2.098276837539673, Accuracy: 0.3556\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.2912948371124267, Accuracy: 0.3308\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 2.103912036514282, Accuracy: 0.3489\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.2951780924987792, Accuracy: 0.33048\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 2.127450924682617, Accuracy: 0.3251\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.2954719718170167, Accuracy: 0.3325\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 2.0949788803100584, Accuracy: 0.3572\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.294803754348755, Accuracy: 0.32998\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 2.092521311569214, Accuracy: 0.3614\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.2986374824523925, Accuracy: 0.3325\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 2.1233998432159424, Accuracy: 0.3278\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.3017256365203855, Accuracy: 0.33178\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 2.1043751117706297, Accuracy: 0.3504\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.301709147949219, Accuracy: 0.327\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 2.101679363632202, Accuracy: 0.3504\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.2924246670532225, Accuracy: 0.33114\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 2.098552972793579, Accuracy: 0.3543\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.2956822690582275, Accuracy: 0.3306\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 2.098095920562744, Accuracy: 0.3526\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.2940598612976073, Accuracy: 0.33318\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 2.087307300567627, Accuracy: 0.3653\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.3001372576141357, Accuracy: 0.3291\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 2.082338593673706, Accuracy: 0.3751\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.292004262542725, Accuracy: 0.3332\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 2.1118046619415285, Accuracy: 0.3432\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.292045971984863, Accuracy: 0.33024\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 2.087967741394043, Accuracy: 0.3662\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.2968519011688233, Accuracy: 0.33154\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 2.100625579452515, Accuracy: 0.3551\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.293162120666504, Accuracy: 0.33196\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 2.1062341243743896, Accuracy: 0.3439\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.2988100239562987, Accuracy: 0.32746\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 2.09975732421875, Accuracy: 0.3529\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.2906921488952636, Accuracy: 0.3361\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 2.11805404548645, Accuracy: 0.3364\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.2959015935516356, Accuracy: 0.33376\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 2.104004873275757, Accuracy: 0.349\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.2939364586639406, Accuracy: 0.32942\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 2.101351657485962, Accuracy: 0.3529\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.291603858566284, Accuracy: 0.33092\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 2.091042085266113, Accuracy: 0.3637\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.289944317474365, Accuracy: 0.33218\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 2.099047487640381, Accuracy: 0.3551\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.2872733213806153, Accuracy: 0.33218\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 2.103928518676758, Accuracy: 0.3489\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.294656425476074, Accuracy: 0.3292\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 2.0972528163909914, Accuracy: 0.3566\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.2946623651123046, Accuracy: 0.33282\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 2.0866563232421873, Accuracy: 0.3698\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.2993249983215334, Accuracy: 0.32848\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 2.1148259742736815, Accuracy: 0.3365\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.3019501510620115, Accuracy: 0.3268\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 2.102696298599243, Accuracy: 0.3528\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.295557176589966, Accuracy: 0.33006\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 2.1003362228393554, Accuracy: 0.353\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.2973893761444093, Accuracy: 0.33296\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 2.1083357349395753, Accuracy: 0.3457\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.2987645446777343, Accuracy: 0.32816\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 2.095796798324585, Accuracy: 0.3587\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.291578945159912, Accuracy: 0.33136\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 2.0928690380096437, Accuracy: 0.3601\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.2963792557525635, Accuracy: 0.32936\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 2.121696446990967, Accuracy: 0.33\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.2899381396484375, Accuracy: 0.3318\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 2.084625751876831, Accuracy: 0.3663\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.2924765978240966, Accuracy: 0.32926\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 2.084272883605957, Accuracy: 0.3714\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.297038244018555, Accuracy: 0.3322\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 2.0859082984924315, Accuracy: 0.3667\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.2945751328277586, Accuracy: 0.33224\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 2.117592320251465, Accuracy: 0.3355\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.293281123428345, Accuracy: 0.32882\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 2.1019500675201415, Accuracy: 0.3509\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.2982708068084716, Accuracy: 0.33036\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 2.0985809799194337, Accuracy: 0.3557\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.296764684371948, Accuracy: 0.33228\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 2.0966195804595946, Accuracy: 0.358\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.2917684938812255, Accuracy: 0.33114\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 2.1107835906982424, Accuracy: 0.3412\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.2894213426208494, Accuracy: 0.33036\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 2.0952054546356202, Accuracy: 0.3568\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.291911886291504, Accuracy: 0.33138\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 2.08480154838562, Accuracy: 0.3678\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.2974664041137696, Accuracy: 0.32972\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 2.1132367069244387, Accuracy: 0.3387\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.300131761550903, Accuracy: 0.32978\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 2.1019752700805663, Accuracy: 0.353\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.2984692791748045, Accuracy: 0.33252\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 2.0956003456115724, Accuracy: 0.3582\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.288662687149048, Accuracy: 0.33434\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 2.0962399730682373, Accuracy: 0.3567\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.2925925358581543, Accuracy: 0.33238\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 2.0948215930938723, Accuracy: 0.3592\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.290306460723877, Accuracy: 0.3299\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 2.099508467102051, Accuracy: 0.353\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.2889014182281495, Accuracy: 0.3346\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 2.100484929275513, Accuracy: 0.3546\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.2884959534454348, Accuracy: 0.33338\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 2.1036037895202635, Accuracy: 0.3485\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.2888567879486086, Accuracy: 0.33062\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 2.1035225273132325, Accuracy: 0.3496\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.294080047225952, Accuracy: 0.33182\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 2.1053184438705443, Accuracy: 0.3461\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.301253505401611, Accuracy: 0.3278\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 2.086870756149292, Accuracy: 0.3679\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.301863765335083, Accuracy: 0.33136\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 2.1163785633087158, Accuracy: 0.3385\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.2968212680053712, Accuracy: 0.32976\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 2.1009411659240724, Accuracy: 0.3541\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.295489958114624, Accuracy: 0.32914\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 2.101469630432129, Accuracy: 0.3498\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.2905736672973633, Accuracy: 0.33336\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 2.090585669708252, Accuracy: 0.3644\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.293531850128174, Accuracy: 0.33046\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 2.0953217292785644, Accuracy: 0.3585\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.291339175415039, Accuracy: 0.33472\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 2.1011650533676147, Accuracy: 0.3519\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.2950841027069093, Accuracy: 0.32824\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 2.0969108125686646, Accuracy: 0.3562\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.2890327139282225, Accuracy: 0.32762\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 2.096919348144531, Accuracy: 0.3556\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.2839508261871337, Accuracy: 0.32932\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 2.094633668899536, Accuracy: 0.3598\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.2911287517547607, Accuracy: 0.33192\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 2.0910845153808593, Accuracy: 0.3654\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.287970808944702, Accuracy: 0.33128\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 2.090879354476929, Accuracy: 0.3628\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.29855601020813, Accuracy: 0.3304\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 2.1171268684387208, Accuracy: 0.3314\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.2950237464904784, Accuracy: 0.33264\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 2.093975915145874, Accuracy: 0.3608\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.3019273890686036, Accuracy: 0.3289\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 2.1201042602539064, Accuracy: 0.3333\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.299000290298462, Accuracy: 0.33082\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 2.0925887340545652, Accuracy: 0.3614\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.291634635009766, Accuracy: 0.33076\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 2.0884172523498536, Accuracy: 0.364\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.296057867965698, Accuracy: 0.32914\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 2.10482713432312, Accuracy: 0.3491\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.296005418701172, Accuracy: 0.33142\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 2.0978582138061523, Accuracy: 0.3555\n",
      "[Finished Training with Adam+Nesterov]\n",
      "\n",
      "Total Training Time: 918.9006990632042\n"
     ]
    }
   ],
   "source": [
    "model = BasicDropoutNet().to(device)\n",
    "nadam_optimizer = optim.NAdam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with Adam+Nesterov]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, nadam_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "    \n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    nadam_L2D_train_loss.append(train_loss)\n",
    "    nadam_L2D_validation_loss.append(val_loss)\n",
    "    nadam_L2D_train_accuracy.append(train_acc)\n",
    "    nadam_L2D_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with Adam+Nesterov]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrPYSpPoPciR"
   },
   "source": [
    "# AdaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "4CiiV6EQPciR"
   },
   "outputs": [],
   "source": [
    "adadelta_L2_train_loss = []\n",
    "adadelta_L2_validation_loss = []\n",
    "adadelta_L2_train_accuracy = []\n",
    "adadelta_L2_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1ysVAfWHPciR",
    "outputId": "4c9e9d98-0980-45b7-ef13-93b8e169d22e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with AdaDelta]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.971930519256592, Accuracy: 0.11652\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.302132526779175, Accuracy: 0.1213\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.970651746368408, Accuracy: 0.12488\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.30188897895813, Accuracy: 0.1276\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.969370416793823, Accuracy: 0.13278\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.3016419242858888, Accuracy: 0.1356\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.9680880934906004, Accuracy: 0.13956\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.3013919036865236, Accuracy: 0.1434\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.966806314086914, Accuracy: 0.14634\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.30114052734375, Accuracy: 0.1466\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.96552531578064, Accuracy: 0.15136\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.300887943649292, Accuracy: 0.151\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.964244641265869, Accuracy: 0.15606\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.3006329261779785, Accuracy: 0.1562\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.962963253326416, Accuracy: 0.15952\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.300374575805664, Accuracy: 0.161\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.9616794061279297, Accuracy: 0.16248\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.3001106311798094, Accuracy: 0.1639\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.9603914311981203, Accuracy: 0.16436\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.2998390865325926, Accuracy: 0.1667\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.9590978099060057, Accuracy: 0.1669\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.299558171081543, Accuracy: 0.1693\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.9577964713287352, Accuracy: 0.1684\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.2992657661437987, Accuracy: 0.1719\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.9564857299804688, Accuracy: 0.1702\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.298959958267212, Accuracy: 0.1734\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.9551633850097656, Accuracy: 0.1717\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.298638403701782, Accuracy: 0.1743\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.953827019805908, Accuracy: 0.17374\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.298297788619995, Accuracy: 0.1764\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.9524741946411135, Accuracy: 0.17488\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.297933795928955, Accuracy: 0.1795\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.951101124954224, Accuracy: 0.17648\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.297544543457031, Accuracy: 0.1806\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.949703878326416, Accuracy: 0.17788\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.297125338745117, Accuracy: 0.1817\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.9482799588012694, Accuracy: 0.17968\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.2966753101348876, Accuracy: 0.1828\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.946829194946289, Accuracy: 0.18078\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.2961927360534666, Accuracy: 0.184\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.9453494344329836, Accuracy: 0.18212\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.2956744983673096, Accuracy: 0.1849\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.943837543334961, Accuracy: 0.18394\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.2951177352905274, Accuracy: 0.1871\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.942291683807373, Accuracy: 0.18548\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.294518042755127, Accuracy: 0.1907\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.9407067570495604, Accuracy: 0.18798\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.2938699474334716, Accuracy: 0.1935\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.9390765716552734, Accuracy: 0.19108\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.2931660598754884, Accuracy: 0.1975\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.9373953706359863, Accuracy: 0.19476\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.292401934051514, Accuracy: 0.2001\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.9356603316497805, Accuracy: 0.19772\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.291572690200806, Accuracy: 0.2025\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.933864337463379, Accuracy: 0.2\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.290669342041016, Accuracy: 0.2055\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.932001640625, Accuracy: 0.20196\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.2896851905822753, Accuracy: 0.2083\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.930064321594238, Accuracy: 0.20346\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.288614989089966, Accuracy: 0.2104\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.928049400177002, Accuracy: 0.20448\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.2874567985534666, Accuracy: 0.2099\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.9259601591491697, Accuracy: 0.20452\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.2862136978149414, Accuracy: 0.2081\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.9237951159667968, Accuracy: 0.20484\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.2848865756988523, Accuracy: 0.2067\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.921558168411255, Accuracy: 0.2047\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.2834792945861815, Accuracy: 0.2065\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.9192572427368164, Accuracy: 0.2041\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 2.282014330291748, Accuracy: 0.2061\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.916909059906006, Accuracy: 0.20286\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.280504828643799, Accuracy: 0.2046\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.914518260498047, Accuracy: 0.20148\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 2.278949116516113, Accuracy: 0.2035\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.9120905018615724, Accuracy: 0.20056\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.2773637466430663, Accuracy: 0.2026\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.9096352426147463, Accuracy: 0.19942\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.2757547103881834, Accuracy: 0.202\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.907154105529785, Accuracy: 0.1986\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.2741155780792237, Accuracy: 0.2007\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.9046394834899902, Accuracy: 0.1979\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.2724533233642576, Accuracy: 0.2001\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.902101647415161, Accuracy: 0.19684\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 2.2707639762878418, Accuracy: 0.1997\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.899533383178711, Accuracy: 0.19618\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 2.269048431777954, Accuracy: 0.1996\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.896930263442993, Accuracy: 0.19616\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 2.2673005912780764, Accuracy: 0.1997\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.8942933877563477, Accuracy: 0.19602\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 2.265521368408203, Accuracy: 0.1998\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.891628783340454, Accuracy: 0.1963\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 2.2637292278289793, Accuracy: 0.1996\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.8889554817199707, Accuracy: 0.197\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 2.2619342334747317, Accuracy: 0.2\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.8862995126342774, Accuracy: 0.19804\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 2.2601722442626953, Accuracy: 0.2011\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.8836563121032714, Accuracy: 0.19924\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 2.2584134799957276, Accuracy: 0.2029\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.8810299281311034, Accuracy: 0.20006\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 2.25668823928833, Accuracy: 0.204\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.878432293701172, Accuracy: 0.2013\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 2.2549904430389405, Accuracy: 0.2063\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.8758646615600587, Accuracy: 0.2035\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 2.253321115875244, Accuracy: 0.2092\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.87333340133667, Accuracy: 0.20538\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 2.251689567565918, Accuracy: 0.2114\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.8708196950531004, Accuracy: 0.20704\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 2.2500699104309083, Accuracy: 0.2123\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.8683260356140137, Accuracy: 0.20898\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 2.2484720211029052, Accuracy: 0.214\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.865854272613525, Accuracy: 0.2112\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 2.246890259552002, Accuracy: 0.2156\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.863407104034424, Accuracy: 0.21304\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 2.2453347370147707, Accuracy: 0.2189\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.8609872833251955, Accuracy: 0.21504\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 2.243810083770752, Accuracy: 0.2212\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.8586021968078614, Accuracy: 0.2158\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 2.2423143383026125, Accuracy: 0.222\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.8562426732635497, Accuracy: 0.21688\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 2.2408403396606444, Accuracy: 0.2225\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.8539050801086425, Accuracy: 0.21796\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 2.2393773822784424, Accuracy: 0.2232\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.8515887699890134, Accuracy: 0.21924\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 2.2379347007751464, Accuracy: 0.225\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.8492918713378907, Accuracy: 0.22004\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 2.2364998455047607, Accuracy: 0.2253\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.8470142070007323, Accuracy: 0.22098\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 2.235083532333374, Accuracy: 0.2265\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.844749188232422, Accuracy: 0.22208\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 2.2336736671447754, Accuracy: 0.2264\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.842502015686035, Accuracy: 0.22276\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 2.232277799987793, Accuracy: 0.2269\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.8402654621887207, Accuracy: 0.22378\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 2.230889381408691, Accuracy: 0.2275\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.8380418519592285, Accuracy: 0.22458\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 2.229511276245117, Accuracy: 0.228\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.8358345999145507, Accuracy: 0.22546\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 2.2281503936767577, Accuracy: 0.2284\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.83365306930542, Accuracy: 0.22602\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 2.2268132484436034, Accuracy: 0.2295\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.8314959588623045, Accuracy: 0.22658\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 2.225503843307495, Accuracy: 0.2304\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.8293674851226807, Accuracy: 0.22712\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 2.2242255474090578, Accuracy: 0.2305\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.8272749353790285, Accuracy: 0.2278\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 2.222983387374878, Accuracy: 0.2317\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.8252280722808836, Accuracy: 0.22822\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 2.2217881549835203, Accuracy: 0.2325\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.823218352279663, Accuracy: 0.2289\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 2.220635500717163, Accuracy: 0.2332\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.821255089416504, Accuracy: 0.22946\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 2.219529260253906, Accuracy: 0.2332\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.8193409040832518, Accuracy: 0.2298\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 2.218471235656738, Accuracy: 0.2339\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.817474948654175, Accuracy: 0.23042\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 2.2174632347106935, Accuracy: 0.2347\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.8156482485961916, Accuracy: 0.23114\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 2.216497920227051, Accuracy: 0.2349\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.8138644470977785, Accuracy: 0.23148\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 2.2155736270904542, Accuracy: 0.2354\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.8121228550720216, Accuracy: 0.23218\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 2.214687971496582, Accuracy: 0.2363\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.810415428390503, Accuracy: 0.23268\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 2.213835305404663, Accuracy: 0.2371\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.8087401094055178, Accuracy: 0.23286\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 2.2130135208129884, Accuracy: 0.2373\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.8070910735321046, Accuracy: 0.23318\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 2.2122253528594973, Accuracy: 0.2376\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.805470923919678, Accuracy: 0.23364\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 2.2114604557037354, Accuracy: 0.2386\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.8038764405059813, Accuracy: 0.23396\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 2.2107215244293212, Accuracy: 0.2394\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.8023032917022705, Accuracy: 0.2346\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 2.2100068706512452, Accuracy: 0.2396\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.800752676239014, Accuracy: 0.23478\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 2.2093162071228027, Accuracy: 0.24\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.7992210452270507, Accuracy: 0.23512\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 2.208643257141113, Accuracy: 0.2404\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.797707229309082, Accuracy: 0.23548\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 2.207982190322876, Accuracy: 0.2407\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.7962085206604006, Accuracy: 0.23582\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 2.2073423889160155, Accuracy: 0.2409\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.794727180328369, Accuracy: 0.23634\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 2.206721870803833, Accuracy: 0.2413\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.793261051940918, Accuracy: 0.2367\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 2.206111528015137, Accuracy: 0.2418\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.791807543640137, Accuracy: 0.23684\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 2.2055156730651855, Accuracy: 0.2425\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.7903676735687255, Accuracy: 0.23716\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 2.2049312404632566, Accuracy: 0.2429\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.788940831604004, Accuracy: 0.2373\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 2.20436120262146, Accuracy: 0.2431\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.7875258195495607, Accuracy: 0.23782\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 2.2038072834014892, Accuracy: 0.2435\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.7861222006225588, Accuracy: 0.23814\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 2.2032602951049807, Accuracy: 0.244\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.7847298398590086, Accuracy: 0.23848\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 2.2027242195129393, Accuracy: 0.2443\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.7833471072387694, Accuracy: 0.2389\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 2.2021987182617186, Accuracy: 0.2443\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.7819762964630126, Accuracy: 0.23936\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 2.201683980560303, Accuracy: 0.2449\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.7806136434936524, Accuracy: 0.2397\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 2.201172721862793, Accuracy: 0.2453\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.779259814376831, Accuracy: 0.24018\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 2.200672943878174, Accuracy: 0.2458\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.7779140202331543, Accuracy: 0.24068\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 2.2001744808197023, Accuracy: 0.246\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.7765788803100584, Accuracy: 0.2408\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 2.19968779258728, Accuracy: 0.2464\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.775249241256714, Accuracy: 0.24132\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 2.199208963394165, Accuracy: 0.2466\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.773928831253052, Accuracy: 0.24158\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 2.1987392601013185, Accuracy: 0.2469\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.772618063735962, Accuracy: 0.24194\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 2.1982711009979248, Accuracy: 0.2474\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.771313809814453, Accuracy: 0.24228\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 2.197812658691406, Accuracy: 0.2473\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.770016831588745, Accuracy: 0.24248\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 2.197360153579712, Accuracy: 0.2474\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.7687265995788573, Accuracy: 0.2429\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 2.1969120559692383, Accuracy: 0.2475\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.7674424494934082, Accuracy: 0.24326\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 2.1964689453125, Accuracy: 0.2477\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.766165135269165, Accuracy: 0.2436\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 2.196028777694702, Accuracy: 0.2477\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.7648942111206054, Accuracy: 0.24372\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 2.1956015659332278, Accuracy: 0.2479\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.7636306885528565, Accuracy: 0.24394\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 2.1951725898742676, Accuracy: 0.2487\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.7623710398864745, Accuracy: 0.24414\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 2.194748677444458, Accuracy: 0.249\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.7611171060180664, Accuracy: 0.24446\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 2.194335441207886, Accuracy: 0.249\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.7598718950653076, Accuracy: 0.24486\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 2.1939191635131836, Accuracy: 0.2493\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.7586304479217527, Accuracy: 0.245\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 2.1935059524536134, Accuracy: 0.2496\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.757392848815918, Accuracy: 0.24538\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 2.193095713043213, Accuracy: 0.2506\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.756159158401489, Accuracy: 0.24566\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 2.1926859214782715, Accuracy: 0.2509\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.7549300553131104, Accuracy: 0.24618\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 2.1922837627410887, Accuracy: 0.2509\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.7537088999176027, Accuracy: 0.2468\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 2.191886030578613, Accuracy: 0.2513\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.7524892569732664, Accuracy: 0.24712\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 2.1914908740997316, Accuracy: 0.2514\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.7512752797698976, Accuracy: 0.24782\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 2.1910979484558104, Accuracy: 0.252\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.7500664794921876, Accuracy: 0.24824\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 2.190706437301636, Accuracy: 0.2525\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.7488602227783203, Accuracy: 0.24882\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 2.190317120742798, Accuracy: 0.2527\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.747658108444214, Accuracy: 0.24934\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 2.1899326469421387, Accuracy: 0.2538\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.746458704299927, Accuracy: 0.24998\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 2.1895479751586913, Accuracy: 0.2543\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.7452633348846436, Accuracy: 0.25062\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 2.189163133239746, Accuracy: 0.2546\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.7440721084594726, Accuracy: 0.25114\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 2.1887822116851807, Accuracy: 0.255\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.742884097137451, Accuracy: 0.25188\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 2.1884057243347166, Accuracy: 0.2552\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.741700375442505, Accuracy: 0.25262\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 2.1880318950653077, Accuracy: 0.2562\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.740520339050293, Accuracy: 0.2533\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 2.1876588180541994, Accuracy: 0.2571\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.739340150909424, Accuracy: 0.25386\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 2.187288390350342, Accuracy: 0.2572\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.7381643367767334, Accuracy: 0.25452\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 2.186914443206787, Accuracy: 0.2572\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.7369935000610353, Accuracy: 0.25508\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 2.1865454734802245, Accuracy: 0.2586\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.7358231224060057, Accuracy: 0.2554\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 2.186175798034668, Accuracy: 0.2597\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.7346552603912353, Accuracy: 0.2563\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 2.1858090595245363, Accuracy: 0.26\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.733489011993408, Accuracy: 0.25714\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 2.185441502380371, Accuracy: 0.2605\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.732323760910034, Accuracy: 0.25734\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 2.1850740222930907, Accuracy: 0.2609\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.7311647248077393, Accuracy: 0.25828\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 2.1847121200561523, Accuracy: 0.2612\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.7300051734161377, Accuracy: 0.25874\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 2.184345470046997, Accuracy: 0.2613\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.728847705154419, Accuracy: 0.25932\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 2.183978597640991, Accuracy: 0.2621\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.727689972076416, Accuracy: 0.26018\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 2.18361276512146, Accuracy: 0.2629\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.7265338972473145, Accuracy: 0.26088\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 2.1832453762054445, Accuracy: 0.264\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.7253796923065186, Accuracy: 0.26174\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 2.1828802669525147, Accuracy: 0.2648\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.7242243568420412, Accuracy: 0.26242\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 2.1825109237670897, Accuracy: 0.2653\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.723071141281128, Accuracy: 0.263\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 2.1821443809509278, Accuracy: 0.2661\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.7219200733947755, Accuracy: 0.26358\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 2.1817767742156984, Accuracy: 0.2665\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.7207666676330566, Accuracy: 0.26444\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 2.1814053089141847, Accuracy: 0.2669\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.719611761932373, Accuracy: 0.26526\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 2.181031882858276, Accuracy: 0.268\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.7184546506500245, Accuracy: 0.266\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 2.1806565685272217, Accuracy: 0.2683\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.7172973265075684, Accuracy: 0.26676\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 2.18027437210083, Accuracy: 0.2688\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.7161378872680664, Accuracy: 0.26744\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 2.1798939743041994, Accuracy: 0.2689\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.7149763946533203, Accuracy: 0.26878\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 2.1795060718536376, Accuracy: 0.2697\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.7138125289916992, Accuracy: 0.2696\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 2.179111868286133, Accuracy: 0.271\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.712641930923462, Accuracy: 0.27022\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 2.178711375427246, Accuracy: 0.2719\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.711466729736328, Accuracy: 0.2712\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 2.1783006828308107, Accuracy: 0.2727\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.7102883476257325, Accuracy: 0.27164\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 2.177887442779541, Accuracy: 0.2736\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.709102098312378, Accuracy: 0.27246\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 2.177461912536621, Accuracy: 0.2745\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.707911052246094, Accuracy: 0.27312\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 2.1770321815490723, Accuracy: 0.2757\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.7067108406066893, Accuracy: 0.27484\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 2.176587387084961, Accuracy: 0.2766\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.705507986450195, Accuracy: 0.27524\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 2.1761349098205565, Accuracy: 0.2778\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.7042928759002685, Accuracy: 0.27618\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 2.1756753787994385, Accuracy: 0.279\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.703070767288208, Accuracy: 0.27728\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 2.175201675796509, Accuracy: 0.2808\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.701836960296631, Accuracy: 0.27822\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 2.1747152843475344, Accuracy: 0.2819\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.700597427368164, Accuracy: 0.27954\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 2.1742175426483152, Accuracy: 0.2826\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.699348562774658, Accuracy: 0.28024\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 2.173711266708374, Accuracy: 0.2838\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.698091674957275, Accuracy: 0.2814\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 2.1731869777679442, Accuracy: 0.2852\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.696832421569824, Accuracy: 0.2826\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 2.1726617862701416, Accuracy: 0.287\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.6955675856781007, Accuracy: 0.28338\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 2.172136784362793, Accuracy: 0.2888\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.6943056761932374, Accuracy: 0.28426\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 2.171605565261841, Accuracy: 0.2888\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.6930447794342043, Accuracy: 0.28508\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 2.171069747543335, Accuracy: 0.2894\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.6917837176513673, Accuracy: 0.28648\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 2.170544436454773, Accuracy: 0.2896\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.69053068901062, Accuracy: 0.28716\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 2.1700202655792236, Accuracy: 0.2901\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.689283655471802, Accuracy: 0.28836\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 2.1695029933929444, Accuracy: 0.2911\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.6880389724731444, Accuracy: 0.28924\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 2.1689889854431152, Accuracy: 0.2927\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.686802621459961, Accuracy: 0.29006\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 2.1684835800170896, Accuracy: 0.2938\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.6855742232513427, Accuracy: 0.29044\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 2.167981941986084, Accuracy: 0.2945\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.6843520011138917, Accuracy: 0.29146\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 2.1674894634246824, Accuracy: 0.295\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.683139929962158, Accuracy: 0.29234\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 2.1670073707580566, Accuracy: 0.2953\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.681931573638916, Accuracy: 0.29266\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 2.1665313468933105, Accuracy: 0.2961\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.6807293852233887, Accuracy: 0.29312\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 2.1660597480773927, Accuracy: 0.2973\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.679537837600708, Accuracy: 0.29354\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 2.165592975616455, Accuracy: 0.2976\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.6783491549682616, Accuracy: 0.29424\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 2.1651263454437255, Accuracy: 0.2983\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.677166961364746, Accuracy: 0.29484\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 2.1646703159332277, Accuracy: 0.2984\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.6759912140655517, Accuracy: 0.29504\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 2.1642159812927244, Accuracy: 0.2989\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.674820072631836, Accuracy: 0.29588\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 2.1637659015655517, Accuracy: 0.2991\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.6736577237701415, Accuracy: 0.2961\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 2.163327563858032, Accuracy: 0.2998\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.6724961010742185, Accuracy: 0.29644\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 2.1628900846481325, Accuracy: 0.3001\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.6713404289245606, Accuracy: 0.29696\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 2.162454466629028, Accuracy: 0.3006\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.670188082733154, Accuracy: 0.29758\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 2.1620260665893554, Accuracy: 0.301\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.6690401588439943, Accuracy: 0.29808\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 2.1615968406677246, Accuracy: 0.3017\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.667894334640503, Accuracy: 0.2983\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 2.1611712112426757, Accuracy: 0.3014\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.666753388671875, Accuracy: 0.2987\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 2.1607487644195555, Accuracy: 0.302\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.6656175646972655, Accuracy: 0.2989\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 2.160325672149658, Accuracy: 0.3026\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.664486181640625, Accuracy: 0.29952\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 2.159913319396973, Accuracy: 0.3026\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.6633568180847167, Accuracy: 0.2997\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 2.1594989849090576, Accuracy: 0.3028\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.6622300777435304, Accuracy: 0.30044\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 2.1590904876708983, Accuracy: 0.3027\n",
      "[Finished Training with AdaDelta]\n",
      "\n",
      "Total Training Time: 919.4185678204522\n"
     ]
    }
   ],
   "source": [
    "model = BasicNet().to(device)\n",
    "adadelta_optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with AdaDelta]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, adadelta_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "    \n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    adadelta_L2_train_loss.append(train_loss)\n",
    "    adadelta_L2_validation_loss.append(val_loss)\n",
    "    adadelta_L2_train_accuracy.append(train_acc)\n",
    "    adadelta_L2_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with AdaDelta]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "FxwN-A1lPciS"
   },
   "outputs": [],
   "source": [
    "adadelta_L2D_train_loss = []\n",
    "adadelta_L2D_validation_loss = []\n",
    "adadelta_L2D_train_accuracy = []\n",
    "adadelta_L2D_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "choPHo_yPciS",
    "outputId": "e235c0bc-e647-4ace-cb01-7152fc201624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with AdaDelta]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.972553684768677, Accuracy: 0.1091\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.30227357673645, Accuracy: 0.1485\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.9713130800628664, Accuracy: 0.11416\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.302084398651123, Accuracy: 0.1586\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.970140672912598, Accuracy: 0.11946\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.3018941246032716, Accuracy: 0.1658\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.9689140578460695, Accuracy: 0.12616\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.3017008014678955, Accuracy: 0.1723\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.967776482849121, Accuracy: 0.1301\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.30150479888916, Accuracy: 0.1764\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.966512331237793, Accuracy: 0.13514\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.3013068618774413, Accuracy: 0.182\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.9653299001312257, Accuracy: 0.13878\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.301102705001831, Accuracy: 0.1862\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.9641010903930662, Accuracy: 0.14296\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.300891813659668, Accuracy: 0.1899\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.9629155726623537, Accuracy: 0.14708\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.30067922744751, Accuracy: 0.193\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.961673003616333, Accuracy: 0.15218\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.3004599678039552, Accuracy: 0.1969\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.9603813469696045, Accuracy: 0.15806\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.3002344203948977, Accuracy: 0.1981\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.9591466134643554, Accuracy: 0.16344\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.30000052986145, Accuracy: 0.2006\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.9578966857147218, Accuracy: 0.16556\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.2997592960357665, Accuracy: 0.2005\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.9566365548706055, Accuracy: 0.16864\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.2995082244873046, Accuracy: 0.2029\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.955403202285767, Accuracy: 0.17058\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.2992464500427245, Accuracy: 0.2032\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.954092480316162, Accuracy: 0.17328\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.2989708724975584, Accuracy: 0.2034\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.952806667480469, Accuracy: 0.17518\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.2986820652008055, Accuracy: 0.2034\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.9515495603179933, Accuracy: 0.17828\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.298379104232788, Accuracy: 0.2031\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.9502164917755125, Accuracy: 0.18024\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.298059800720215, Accuracy: 0.2037\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.948900992279053, Accuracy: 0.17996\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.297721816253662, Accuracy: 0.2037\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.947656603927612, Accuracy: 0.18144\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.297367853164673, Accuracy: 0.2033\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.9462395709228515, Accuracy: 0.18514\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.296993597793579, Accuracy: 0.2033\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.9448353086853025, Accuracy: 0.1841\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.2965891677856445, Accuracy: 0.2026\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.9435640195465087, Accuracy: 0.1869\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.2961694053649904, Accuracy: 0.2033\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.942103527145386, Accuracy: 0.18904\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.295718576812744, Accuracy: 0.2027\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.940641388397217, Accuracy: 0.1898\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.2952342170715334, Accuracy: 0.2029\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.939272700805664, Accuracy: 0.18888\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.2947182144165037, Accuracy: 0.2025\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.937827657775879, Accuracy: 0.18936\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.294171008682251, Accuracy: 0.2024\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.936254804840088, Accuracy: 0.19044\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.2935831016540527, Accuracy: 0.202\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.934655625076294, Accuracy: 0.19238\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.292944938278198, Accuracy: 0.2016\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.9331247507476808, Accuracy: 0.19296\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.2922562927246095, Accuracy: 0.2011\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.931520668563843, Accuracy: 0.19104\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.2915203983306887, Accuracy: 0.2001\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.929884319000244, Accuracy: 0.19106\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.290729592514038, Accuracy: 0.1989\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.92800958190918, Accuracy: 0.19108\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.2898726974487307, Accuracy: 0.1982\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.9263265824890135, Accuracy: 0.19182\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 2.2889537754058837, Accuracy: 0.1975\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.9244793737792967, Accuracy: 0.19252\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.287972149658203, Accuracy: 0.1968\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.922670751800537, Accuracy: 0.19116\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 2.2869237476348876, Accuracy: 0.196\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.920703356552124, Accuracy: 0.19084\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.2858056007385255, Accuracy: 0.1957\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.918683563995361, Accuracy: 0.1911\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.28463178024292, Accuracy: 0.1953\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.916680762786865, Accuracy: 0.1894\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.283403112030029, Accuracy: 0.1945\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.9146645294189453, Accuracy: 0.19078\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.2821320957183837, Accuracy: 0.1947\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.912607008972168, Accuracy: 0.19068\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 2.280816279220581, Accuracy: 0.1947\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.9103638066101074, Accuracy: 0.19134\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 2.2794654750823975, Accuracy: 0.1948\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.908023709106445, Accuracy: 0.19092\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 2.2780779678344727, Accuracy: 0.1954\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.9059835635375975, Accuracy: 0.1916\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 2.276674577331543, Accuracy: 0.196\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.9038347368621826, Accuracy: 0.19038\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 2.27524787902832, Accuracy: 0.1965\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.9015293408966065, Accuracy: 0.19148\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 2.2738024868011473, Accuracy: 0.1963\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.899216920700073, Accuracy: 0.1911\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 2.272320426940918, Accuracy: 0.1964\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.8969203479003904, Accuracy: 0.19228\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 2.270790488052368, Accuracy: 0.1972\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.8946106202697752, Accuracy: 0.19268\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 2.269239266586304, Accuracy: 0.1972\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.89219731300354, Accuracy: 0.1935\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 2.2676261714935304, Accuracy: 0.1983\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.8898994721984863, Accuracy: 0.19338\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 2.265974612045288, Accuracy: 0.1987\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.887392915725708, Accuracy: 0.19396\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 2.264263386917114, Accuracy: 0.1989\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.8847747777557373, Accuracy: 0.194\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 2.262497886276245, Accuracy: 0.1988\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.882172511367798, Accuracy: 0.19472\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 2.2607008361816407, Accuracy: 0.1994\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.879555129547119, Accuracy: 0.19424\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 2.258895034790039, Accuracy: 0.1994\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.877207241516113, Accuracy: 0.19436\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 2.257097360610962, Accuracy: 0.1992\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.8744791830444334, Accuracy: 0.1954\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 2.255331385040283, Accuracy: 0.1996\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.8719309378814697, Accuracy: 0.19578\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 2.2536181507110595, Accuracy: 0.1996\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.8694474420166016, Accuracy: 0.19552\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 2.251976484680176, Accuracy: 0.199\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.8671876467132567, Accuracy: 0.19548\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 2.2504105602264404, Accuracy: 0.199\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.865027897949219, Accuracy: 0.19568\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 2.248949556732178, Accuracy: 0.1988\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.8625746909332275, Accuracy: 0.19552\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 2.2475765632629394, Accuracy: 0.1987\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.86031059135437, Accuracy: 0.19638\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 2.2462801746368406, Accuracy: 0.1988\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.8583628519439697, Accuracy: 0.1963\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 2.2450676330566406, Accuracy: 0.1986\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.8562871576690676, Accuracy: 0.19572\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 2.2439394134521486, Accuracy: 0.199\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.8541777297973634, Accuracy: 0.19622\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 2.242874308013916, Accuracy: 0.1993\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.852451001358032, Accuracy: 0.1978\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 2.2418835304260254, Accuracy: 0.1997\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.8504367462158204, Accuracy: 0.19692\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 2.2409427131652833, Accuracy: 0.2002\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.84876503326416, Accuracy: 0.19718\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 2.240051612854004, Accuracy: 0.2002\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.847118981628418, Accuracy: 0.19722\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 2.2392037017822264, Accuracy: 0.2003\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.8452463270568846, Accuracy: 0.19776\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 2.2383927028656005, Accuracy: 0.2006\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.8436623085021973, Accuracy: 0.1983\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 2.237610079574585, Accuracy: 0.2005\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.8417497190856933, Accuracy: 0.19874\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 2.2368548477172854, Accuracy: 0.201\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.840430347290039, Accuracy: 0.19916\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 2.2361185371398924, Accuracy: 0.2015\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.83894777885437, Accuracy: 0.19876\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 2.2353976516723635, Accuracy: 0.2018\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.8369431463623047, Accuracy: 0.1998\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 2.2346927947998045, Accuracy: 0.2022\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.835661103668213, Accuracy: 0.19968\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 2.233996367263794, Accuracy: 0.2024\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.834155859375, Accuracy: 0.2001\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 2.2333070949554443, Accuracy: 0.2032\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.83261126953125, Accuracy: 0.20164\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 2.232617092895508, Accuracy: 0.2037\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.831310813522339, Accuracy: 0.20094\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 2.2319208290100097, Accuracy: 0.2041\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.8292328359222414, Accuracy: 0.20168\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 2.2312204696655273, Accuracy: 0.2047\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.827815870513916, Accuracy: 0.20162\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 2.230509505844116, Accuracy: 0.2056\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.8262731520843505, Accuracy: 0.2028\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 2.229786612701416, Accuracy: 0.2062\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.824635791015625, Accuracy: 0.20322\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 2.2290456775665284, Accuracy: 0.2071\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.823353715209961, Accuracy: 0.20316\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 2.2282884342193605, Accuracy: 0.2081\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.821362921142578, Accuracy: 0.20476\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 2.2274980773925783, Accuracy: 0.2091\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.8198933282470704, Accuracy: 0.20416\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 2.226666664505005, Accuracy: 0.2095\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.817943457183838, Accuracy: 0.20554\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 2.2258005310058593, Accuracy: 0.2105\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.8165387396240233, Accuracy: 0.20672\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 2.22488895111084, Accuracy: 0.2115\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.814869993972778, Accuracy: 0.20764\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 2.223969681549072, Accuracy: 0.2133\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.813019182434082, Accuracy: 0.20976\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 2.2229756572723387, Accuracy: 0.2159\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.8113866995239256, Accuracy: 0.21012\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 2.221957608795166, Accuracy: 0.2183\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.8091894309234617, Accuracy: 0.21456\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 2.2209055324554443, Accuracy: 0.221\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.807425471191406, Accuracy: 0.21596\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 2.2198399227142334, Accuracy: 0.2248\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.8059463790893555, Accuracy: 0.21902\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 2.21876810836792, Accuracy: 0.2275\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.8037015336608886, Accuracy: 0.22178\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 2.21768133392334, Accuracy: 0.2294\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.802156192779541, Accuracy: 0.22414\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 2.216635517501831, Accuracy: 0.2324\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.8004890826416013, Accuracy: 0.22556\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 2.2156207721710204, Accuracy: 0.2352\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.798421444091797, Accuracy: 0.22874\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 2.2146247428894044, Accuracy: 0.2381\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.7967642869567872, Accuracy: 0.23044\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 2.2136626064300535, Accuracy: 0.2392\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.7948242823028564, Accuracy: 0.23122\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 2.212731997299194, Accuracy: 0.2402\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.793060270843506, Accuracy: 0.23354\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 2.211825168991089, Accuracy: 0.2421\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.791860150299072, Accuracy: 0.23426\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 2.210946232223511, Accuracy: 0.243\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.7898325039672853, Accuracy: 0.2354\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 2.210082919692993, Accuracy: 0.2442\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.7881350912475584, Accuracy: 0.23756\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 2.2092198257446287, Accuracy: 0.2451\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.7865231672668456, Accuracy: 0.23826\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 2.208382353210449, Accuracy: 0.2456\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.78495546081543, Accuracy: 0.23974\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 2.2075562393188477, Accuracy: 0.247\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.7831762237548827, Accuracy: 0.24202\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 2.2067383907318114, Accuracy: 0.2484\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.7814451129150393, Accuracy: 0.243\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 2.2059286403656007, Accuracy: 0.2501\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.780038169708252, Accuracy: 0.24296\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 2.2051361019134523, Accuracy: 0.2511\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.779005916748047, Accuracy: 0.24448\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 2.2043569858551026, Accuracy: 0.2524\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.7767526523590087, Accuracy: 0.24596\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 2.203574180221558, Accuracy: 0.2533\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.775602772064209, Accuracy: 0.24572\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 2.2028029388427735, Accuracy: 0.2538\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.7740282231903075, Accuracy: 0.24704\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 2.202045063781738, Accuracy: 0.2552\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.7723098125457764, Accuracy: 0.24922\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 2.2012921504974363, Accuracy: 0.2558\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.7706140435791013, Accuracy: 0.2499\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 2.200537483215332, Accuracy: 0.2569\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.769519814682007, Accuracy: 0.25046\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 2.199807201385498, Accuracy: 0.2587\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.7679687897491454, Accuracy: 0.25266\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 2.1990745162963865, Accuracy: 0.2596\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.7661147844696043, Accuracy: 0.25324\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 2.198366480636597, Accuracy: 0.2608\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.7646694189453127, Accuracy: 0.25544\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 2.1976438899993895, Accuracy: 0.2628\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.763032213821411, Accuracy: 0.25684\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 2.196937352371216, Accuracy: 0.2636\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.7616855895233154, Accuracy: 0.25752\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 2.1962331604003906, Accuracy: 0.2641\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.7606001348876954, Accuracy: 0.25594\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 2.1955508346557617, Accuracy: 0.2648\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.759139429626465, Accuracy: 0.25858\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 2.194865210342407, Accuracy: 0.2662\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.7572001644134523, Accuracy: 0.2603\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 2.194182834625244, Accuracy: 0.2673\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.75591879737854, Accuracy: 0.26016\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 2.193511658859253, Accuracy: 0.2684\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.754140609741211, Accuracy: 0.26126\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 2.192839491653442, Accuracy: 0.2701\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.7531042457580566, Accuracy: 0.26196\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 2.1921688732147215, Accuracy: 0.2709\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.75144492729187, Accuracy: 0.26338\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 2.1915034362792967, Accuracy: 0.2712\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.750002855758667, Accuracy: 0.265\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 2.1908400581359864, Accuracy: 0.2727\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.7488579808044435, Accuracy: 0.26594\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 2.1901984546661377, Accuracy: 0.2736\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.7475246726989746, Accuracy: 0.26536\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 2.1895499923706057, Accuracy: 0.2739\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.745342340698242, Accuracy: 0.26786\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 2.188908638381958, Accuracy: 0.2748\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.7443994438171386, Accuracy: 0.26842\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 2.1882717739105226, Accuracy: 0.276\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.7428664516448973, Accuracy: 0.26864\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 2.1876232921600343, Accuracy: 0.277\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.7421735568237304, Accuracy: 0.26956\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 2.18700316696167, Accuracy: 0.2774\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.7400060186767576, Accuracy: 0.27148\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 2.186377328872681, Accuracy: 0.278\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.7386622985839844, Accuracy: 0.2704\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 2.1857438343048097, Accuracy: 0.2783\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.7375403704071046, Accuracy: 0.27186\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 2.1851182754516603, Accuracy: 0.2793\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.7359140758514404, Accuracy: 0.27296\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 2.1844983516693115, Accuracy: 0.2798\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.7346625050354003, Accuracy: 0.27444\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 2.183883411026001, Accuracy: 0.2808\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.7332109254455568, Accuracy: 0.2735\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 2.1832652484893798, Accuracy: 0.282\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.7318924535369873, Accuracy: 0.27576\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 2.1826609191894533, Accuracy: 0.2818\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.730690860824585, Accuracy: 0.27636\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 2.1820517570495603, Accuracy: 0.2829\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.7289824517822265, Accuracy: 0.2777\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 2.181438310623169, Accuracy: 0.2834\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.7281706032562254, Accuracy: 0.27662\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 2.1808518486022948, Accuracy: 0.2843\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.726426750946045, Accuracy: 0.2776\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 2.18025849609375, Accuracy: 0.2848\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.7254719065856934, Accuracy: 0.27822\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 2.179664643096924, Accuracy: 0.2857\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.7238961804962156, Accuracy: 0.27708\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 2.1790744915008546, Accuracy: 0.2865\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.722857363128662, Accuracy: 0.2776\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 2.178481158065796, Accuracy: 0.2875\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.7210077295684814, Accuracy: 0.27936\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 2.1779044998168944, Accuracy: 0.2882\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.719743109588623, Accuracy: 0.28044\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 2.1773319229125976, Accuracy: 0.2887\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.7184984088897703, Accuracy: 0.27922\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 2.1767518173217772, Accuracy: 0.2887\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.7171984326171876, Accuracy: 0.28094\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 2.17619701461792, Accuracy: 0.2885\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.716048663787842, Accuracy: 0.28202\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 2.1756450969696046, Accuracy: 0.2892\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.7147929514312743, Accuracy: 0.28186\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 2.175086626434326, Accuracy: 0.2891\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.7132831062316893, Accuracy: 0.28302\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 2.174549012756348, Accuracy: 0.2889\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.7120791728210447, Accuracy: 0.2816\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 2.174006948471069, Accuracy: 0.2898\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.7109208712768553, Accuracy: 0.28308\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 2.1734797534942625, Accuracy: 0.2906\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.709950382232666, Accuracy: 0.28308\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 2.172960248184204, Accuracy: 0.2911\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.708849012756348, Accuracy: 0.28302\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 2.1724438053131103, Accuracy: 0.2916\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.7069320514678954, Accuracy: 0.28434\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 2.171930989074707, Accuracy: 0.2922\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.7054990910339356, Accuracy: 0.2845\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 2.17142583694458, Accuracy: 0.2926\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.7043033462524413, Accuracy: 0.2863\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 2.1709349426269533, Accuracy: 0.2925\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.70354150680542, Accuracy: 0.28466\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 2.1704443244934084, Accuracy: 0.2934\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.7019581312561036, Accuracy: 0.28658\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 2.169945553970337, Accuracy: 0.2937\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.7010179859924315, Accuracy: 0.28628\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 2.169463960266113, Accuracy: 0.2942\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.699857782745361, Accuracy: 0.28718\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 2.1690022346496582, Accuracy: 0.2948\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.6983826917266844, Accuracy: 0.28746\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 2.16854129447937, Accuracy: 0.2956\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.6972579134368897, Accuracy: 0.28842\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 2.168069404220581, Accuracy: 0.2965\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.6958601319885256, Accuracy: 0.28756\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 2.167624034500122, Accuracy: 0.2967\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.6952014658355714, Accuracy: 0.28744\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 2.1671716793060303, Accuracy: 0.2968\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.6935767959594727, Accuracy: 0.28926\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 2.1667313041687013, Accuracy: 0.2971\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.692905020904541, Accuracy: 0.28806\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 2.1663002922058103, Accuracy: 0.2972\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.6911194422912597, Accuracy: 0.2904\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 2.1658812507629395, Accuracy: 0.2971\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.690375338058472, Accuracy: 0.28996\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 2.1654683452606203, Accuracy: 0.2976\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.689416019592285, Accuracy: 0.28872\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 2.16505411529541, Accuracy: 0.2974\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.687908663864136, Accuracy: 0.29014\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 2.1646509696960448, Accuracy: 0.2981\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.6864969215393066, Accuracy: 0.2901\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 2.1642515071868895, Accuracy: 0.2983\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.6855662565612795, Accuracy: 0.29178\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 2.163847036361694, Accuracy: 0.2985\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.6845905248260498, Accuracy: 0.2914\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 2.163466062927246, Accuracy: 0.299\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.683736537475586, Accuracy: 0.29066\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 2.16308565826416, Accuracy: 0.2989\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.682344198913574, Accuracy: 0.2925\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 2.1627119457244874, Accuracy: 0.2992\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.681337037277222, Accuracy: 0.29164\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 2.16234662399292, Accuracy: 0.2993\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.6800051594543457, Accuracy: 0.29274\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 2.161975386810303, Accuracy: 0.2997\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.678716656036377, Accuracy: 0.29388\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 2.1616082679748536, Accuracy: 0.2997\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.677548782043457, Accuracy: 0.29318\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 2.161257234954834, Accuracy: 0.2999\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.6761930856323244, Accuracy: 0.29354\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 2.1609133098602293, Accuracy: 0.3004\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.675689083862305, Accuracy: 0.2944\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 2.160572803878784, Accuracy: 0.3006\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.67544701461792, Accuracy: 0.29274\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 2.160244024658203, Accuracy: 0.3008\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.6735870069885252, Accuracy: 0.29468\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 2.159909159088135, Accuracy: 0.3011\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.672263790588379, Accuracy: 0.2944\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 2.159566640853882, Accuracy: 0.301\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.671239778213501, Accuracy: 0.29536\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 2.1592320293426512, Accuracy: 0.3015\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.6706472411346436, Accuracy: 0.29566\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 2.1589117027282714, Accuracy: 0.3023\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.668779552078247, Accuracy: 0.29644\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 2.158593712234497, Accuracy: 0.3025\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.6683655683898926, Accuracy: 0.29604\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 2.158286710357666, Accuracy: 0.3028\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.6673395063781737, Accuracy: 0.29542\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 2.1579726951599123, Accuracy: 0.3028\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.6661878730773925, Accuracy: 0.29624\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 2.157673896408081, Accuracy: 0.3027\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.664841192626953, Accuracy: 0.29694\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 2.1573601303100585, Accuracy: 0.3028\n",
      "[Finished Training with AdaDelta]\n",
      "\n",
      "Total Training Time: 1837.0741803962737\n"
     ]
    }
   ],
   "source": [
    "#  L2 + Dropout\n",
    "model = BasicDropoutNet().to(device)\n",
    "adadelta_optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with AdaDelta]\")\n",
    "\n",
    "tarin_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, adadelta_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "\n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    adadelta_L2D_train_loss.append(train_loss)\n",
    "    adadelta_L2D_validation_loss.append(val_loss)\n",
    "    adadelta_L2D_train_accuracy.append(train_acc)\n",
    "    adadelta_L2D_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with AdaDelta]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PudDj3udPciS"
   },
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "yYx0xfqNPciT"
   },
   "outputs": [],
   "source": [
    "adam_L2_train_loss = []\n",
    "adam_L2_validation_loss = []\n",
    "adam_L2_train_accuracy = []\n",
    "adam_L2_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "fGq7VBrIPciT",
    "outputId": "4c427739-ffb3-4ebd-e339-c05b89dde7c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with AdaGrad]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.2460907688140868, Accuracy: 0.2903\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.1431783557891846, Accuracy: 0.311\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.206095140304565, Accuracy: 0.32002\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.119228798675537, Accuracy: 0.3317\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.1853194888305665, Accuracy: 0.35084\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.0970114547729493, Accuracy: 0.363\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.166796661148071, Accuracy: 0.36768\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.0714786670684813, Accuracy: 0.3845\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.160654355621338, Accuracy: 0.37732\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.0726577659606935, Accuracy: 0.3827\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.1531171892547607, Accuracy: 0.38872\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.0848733472824095, Accuracy: 0.371\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.1485395834350585, Accuracy: 0.39604\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.0453738483428956, Accuracy: 0.4121\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.1445938831329348, Accuracy: 0.40064\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.055886333847046, Accuracy: 0.3981\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.137854119720459, Accuracy: 0.40876\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.0804817878723143, Accuracy: 0.3755\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.131734713745117, Accuracy: 0.41614\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.0337567764282225, Accuracy: 0.423\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.1315739311218262, Accuracy: 0.41766\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.0468944217681884, Accuracy: 0.4119\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.1290802978515626, Accuracy: 0.42256\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.0339248010635376, Accuracy: 0.4246\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.1317564199066164, Accuracy: 0.4236\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.0521461391448974, Accuracy: 0.4022\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.125005196990967, Accuracy: 0.42984\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.0457916576385498, Accuracy: 0.4109\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.1205443747711183, Accuracy: 0.43328\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.037787303543091, Accuracy: 0.4213\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.1117868767547607, Accuracy: 0.4421\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.0413273277282715, Accuracy: 0.4174\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.110343931350708, Accuracy: 0.44144\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.0225832553863525, Accuracy: 0.4378\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.1103074839782714, Accuracy: 0.4436\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.0323717041015623, Accuracy: 0.4215\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.1173265856170653, Accuracy: 0.44008\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.029354723739624, Accuracy: 0.4274\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.111036657714844, Accuracy: 0.44554\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.013235732650757, Accuracy: 0.4479\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.109391545333862, Accuracy: 0.44556\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.0150702003479, Accuracy: 0.4455\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.1135881188964842, Accuracy: 0.44518\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.022903745651245, Accuracy: 0.4372\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.102317912902832, Accuracy: 0.45174\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.019002977371216, Accuracy: 0.4432\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.108209423751831, Accuracy: 0.44706\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.012617742538452, Accuracy: 0.4493\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.1034719989013673, Accuracy: 0.45224\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.0175932998657227, Accuracy: 0.4414\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.1094224683380127, Accuracy: 0.4491\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.0279377223968504, Accuracy: 0.426\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.1032209981536867, Accuracy: 0.45578\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.0223513633728025, Accuracy: 0.4365\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.103589180603027, Accuracy: 0.45564\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.0239745994567873, Accuracy: 0.4355\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.1004325698852537, Accuracy: 0.45712\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.020141036224365, Accuracy: 0.4402\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.1098946646118164, Accuracy: 0.45342\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.0124363494873045, Accuracy: 0.4473\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.105266491088867, Accuracy: 0.4548\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.0167406200408937, Accuracy: 0.4384\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.099306271209717, Accuracy: 0.45896\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.0097105087280274, Accuracy: 0.45\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.098933489151001, Accuracy: 0.4602\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.0044536609649657, Accuracy: 0.4565\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.1039296178436278, Accuracy: 0.4575\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.0088104793548585, Accuracy: 0.453\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.099342116394043, Accuracy: 0.4605\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 2.022272485923767, Accuracy: 0.4385\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.09719339012146, Accuracy: 0.46226\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.0054883636474607, Accuracy: 0.4557\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.10224318321228, Accuracy: 0.45806\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 2.014356472206116, Accuracy: 0.444\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.10365118560791, Accuracy: 0.45774\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.002488306427002, Accuracy: 0.4588\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.0954603063964843, Accuracy: 0.4621\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.019430196380615, Accuracy: 0.4437\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.094177751083374, Accuracy: 0.4638\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.0084784530639648, Accuracy: 0.451\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.097584145965576, Accuracy: 0.46342\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.0118573932647705, Accuracy: 0.4476\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.1011056494903566, Accuracy: 0.46146\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 2.007957179069519, Accuracy: 0.4532\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.0939324981689453, Accuracy: 0.4667\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 2.002528137588501, Accuracy: 0.4566\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.0991706289672853, Accuracy: 0.46214\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 2.012812043762207, Accuracy: 0.4475\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.099653757095337, Accuracy: 0.46192\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 2.011592445373535, Accuracy: 0.4478\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.093159604721069, Accuracy: 0.4678\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 2.0043954290390014, Accuracy: 0.457\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.0921229846191407, Accuracy: 0.46752\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 2.0029233978271486, Accuracy: 0.4584\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.0948417736053466, Accuracy: 0.46592\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 2.008611568641663, Accuracy: 0.4528\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.0959125387573243, Accuracy: 0.46546\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 2.0064435174942017, Accuracy: 0.4533\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.0977968740081785, Accuracy: 0.46536\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 2.0048736558914184, Accuracy: 0.4546\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.095131726150513, Accuracy: 0.46626\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 2.006344253158569, Accuracy: 0.4549\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.0960107841491697, Accuracy: 0.4645\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 2.0131480857849122, Accuracy: 0.447\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.0935660230255126, Accuracy: 0.4666\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 2.0098865575790406, Accuracy: 0.4532\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.091774657058716, Accuracy: 0.46874\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 2.0238686714172363, Accuracy: 0.4372\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.0984583110809325, Accuracy: 0.46486\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 2.00359075717926, Accuracy: 0.4599\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.0942761931610105, Accuracy: 0.46676\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 2.007779475402832, Accuracy: 0.4538\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.0950344383239745, Accuracy: 0.46728\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 2.0041450660705564, Accuracy: 0.4587\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.089923635787964, Accuracy: 0.46868\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 2.0119826866149904, Accuracy: 0.4477\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.093644613571167, Accuracy: 0.4693\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 2.0200790508270265, Accuracy: 0.437\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.091858991241455, Accuracy: 0.46842\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 2.0063640594482424, Accuracy: 0.4552\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.0909420638275145, Accuracy: 0.46928\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 2.010225059509277, Accuracy: 0.4514\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.0957214363861083, Accuracy: 0.46802\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 2.0116274993896486, Accuracy: 0.4485\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.0885202951049804, Accuracy: 0.47096\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 2.001001230430603, Accuracy: 0.4578\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.092062935333252, Accuracy: 0.46962\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 2.009654496765137, Accuracy: 0.4499\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.093187835006714, Accuracy: 0.46908\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 2.0060600357055662, Accuracy: 0.4541\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.096607847290039, Accuracy: 0.46676\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 2.005982115936279, Accuracy: 0.4537\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.095443373336792, Accuracy: 0.46674\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 2.011451926422119, Accuracy: 0.4493\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.0927361296844484, Accuracy: 0.4678\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 2.0072472930908205, Accuracy: 0.4528\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.087944538192749, Accuracy: 0.47292\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 2.000367381286621, Accuracy: 0.4649\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.0918964190673828, Accuracy: 0.47106\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 2.011399202346802, Accuracy: 0.4482\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.090592487335205, Accuracy: 0.4713\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 2.0124881378173827, Accuracy: 0.4481\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.0904308725738527, Accuracy: 0.46972\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 2.0058103302001955, Accuracy: 0.4546\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.088064050750732, Accuracy: 0.47228\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 2.0069848236083985, Accuracy: 0.4525\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.0910913998413085, Accuracy: 0.47174\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 2.0092661319732668, Accuracy: 0.449\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.0989310221099853, Accuracy: 0.46684\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 2.013402043914795, Accuracy: 0.4461\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.085446088104248, Accuracy: 0.4732\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 2.01452733001709, Accuracy: 0.4418\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.092438373565674, Accuracy: 0.46982\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 2.0077346725463867, Accuracy: 0.4528\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.0885700720214846, Accuracy: 0.47204\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 1.9972346073150635, Accuracy: 0.4631\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.0904477767944334, Accuracy: 0.47074\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 2.0037452167510987, Accuracy: 0.4593\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.091602071762085, Accuracy: 0.46934\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 2.0238336639404295, Accuracy: 0.4337\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.090493828125, Accuracy: 0.471\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 1.9992198040008544, Accuracy: 0.4612\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.0886643128204345, Accuracy: 0.47238\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 2.013240723609924, Accuracy: 0.4463\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.089596266860962, Accuracy: 0.472\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 2.0033726358413695, Accuracy: 0.459\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.0868978940582275, Accuracy: 0.47252\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 2.004674716567993, Accuracy: 0.4584\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.0932362465667724, Accuracy: 0.46922\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 2.0020714630126952, Accuracy: 0.4613\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.0899989967346193, Accuracy: 0.47212\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 2.0077711811065675, Accuracy: 0.4513\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.08623106010437, Accuracy: 0.4746\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 2.00717439289093, Accuracy: 0.4541\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.0905458879852294, Accuracy: 0.47106\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 2.011560683631897, Accuracy: 0.4452\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.0887664642333985, Accuracy: 0.47214\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 2.0148151302337647, Accuracy: 0.445\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.0972696885681152, Accuracy: 0.46672\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 2.0137216066360475, Accuracy: 0.4472\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.0916516694641114, Accuracy: 0.47128\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 2.005218200683594, Accuracy: 0.4543\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.0857747127532957, Accuracy: 0.47534\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 2.0025584434509276, Accuracy: 0.4539\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.084793146133423, Accuracy: 0.47306\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 1.9983575298309326, Accuracy: 0.4625\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.0845767713928223, Accuracy: 0.47364\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 2.008903211402893, Accuracy: 0.45\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.087168942718506, Accuracy: 0.47358\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 1.9999275848388671, Accuracy: 0.4624\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.088511390762329, Accuracy: 0.47494\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 2.0033190845489504, Accuracy: 0.4538\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.085856336364746, Accuracy: 0.47518\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 2.0040713680267332, Accuracy: 0.4589\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.08458772064209, Accuracy: 0.47536\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 2.0050356662750244, Accuracy: 0.457\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.088397180557251, Accuracy: 0.47212\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 2.021368915939331, Accuracy: 0.4395\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.087493879318237, Accuracy: 0.4754\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 1.9997438034057617, Accuracy: 0.465\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.0884060736846926, Accuracy: 0.47444\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 1.9965889965057373, Accuracy: 0.4671\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.0876468096160887, Accuracy: 0.47432\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 2.003851566696167, Accuracy: 0.459\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.0840119098663332, Accuracy: 0.47594\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 2.011339893722534, Accuracy: 0.4499\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.0917482585144045, Accuracy: 0.47066\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 2.001083402633667, Accuracy: 0.46\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.088049578399658, Accuracy: 0.4735\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 1.9952578670501708, Accuracy: 0.4692\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.087340302352905, Accuracy: 0.47366\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 2.0002060007095337, Accuracy: 0.4635\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.085921204071045, Accuracy: 0.47574\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 2.004186297225952, Accuracy: 0.4556\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.0902609239959715, Accuracy: 0.47156\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 2.0019467792510985, Accuracy: 0.4606\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.0854493798828124, Accuracy: 0.4765\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 2.0150918895721435, Accuracy: 0.4477\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.088450984649658, Accuracy: 0.47494\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 2.0038015655517576, Accuracy: 0.4532\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.0855727500152588, Accuracy: 0.47596\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 2.0101695434570312, Accuracy: 0.4488\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.091603583908081, Accuracy: 0.47112\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 1.9944758548736572, Accuracy: 0.4692\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.083059838562012, Accuracy: 0.4784\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 1.9982478805541992, Accuracy: 0.4627\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.0851380888366697, Accuracy: 0.47526\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 2.004227425575256, Accuracy: 0.4561\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.0870898611450195, Accuracy: 0.47716\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 2.0034801914215086, Accuracy: 0.4582\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.08887657913208, Accuracy: 0.47296\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 2.0085863346099853, Accuracy: 0.4516\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.087159529953003, Accuracy: 0.47432\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 2.0109115070343018, Accuracy: 0.4488\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.086786203575134, Accuracy: 0.4748\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 2.013185548019409, Accuracy: 0.446\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.087917737426758, Accuracy: 0.47484\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 1.996283939743042, Accuracy: 0.4682\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.084750759124756, Accuracy: 0.4774\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 2.0070051107406615, Accuracy: 0.454\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.0870332736206056, Accuracy: 0.47452\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 1.9941170989990233, Accuracy: 0.4711\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.0872316087341307, Accuracy: 0.47568\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 2.0082101736068725, Accuracy: 0.4533\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.082033664932251, Accuracy: 0.47886\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 2.01734155921936, Accuracy: 0.4418\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.0908968284606932, Accuracy: 0.47176\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 2.023867593383789, Accuracy: 0.436\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.0888652560424803, Accuracy: 0.47446\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 2.004062738990784, Accuracy: 0.4564\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.084914113845825, Accuracy: 0.4741\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 2.0022036128997804, Accuracy: 0.4581\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.0859036222076415, Accuracy: 0.47416\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 2.009353915023804, Accuracy: 0.4504\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.0885375035858154, Accuracy: 0.47248\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 2.0014835899353027, Accuracy: 0.4611\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.0871565896606445, Accuracy: 0.47456\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 2.000133173751831, Accuracy: 0.4614\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.0851877880096437, Accuracy: 0.47502\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 2.0176042179107667, Accuracy: 0.4412\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.0886877486419677, Accuracy: 0.47182\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 2.0070841165542603, Accuracy: 0.4537\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.08771272644043, Accuracy: 0.47514\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 2.002920263671875, Accuracy: 0.4569\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.086558727416992, Accuracy: 0.47202\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 2.022134984970093, Accuracy: 0.4358\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.086399659118652, Accuracy: 0.47628\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 2.0045057134628297, Accuracy: 0.4576\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.09011871925354, Accuracy: 0.47292\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 2.0019603101730348, Accuracy: 0.4582\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.085549796600342, Accuracy: 0.47346\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 2.011053438949585, Accuracy: 0.4513\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.0872715796661376, Accuracy: 0.47456\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 2.0050676635742186, Accuracy: 0.4573\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.0851842482757568, Accuracy: 0.47622\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 1.9980339645385743, Accuracy: 0.4677\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.092381496582031, Accuracy: 0.4706\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 2.007515386581421, Accuracy: 0.4539\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.0866914211273193, Accuracy: 0.47362\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 2.0067775409698485, Accuracy: 0.4548\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.084246528930664, Accuracy: 0.47658\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 1.9973852172851563, Accuracy: 0.4648\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.086186259994507, Accuracy: 0.47578\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 2.0101788921356203, Accuracy: 0.4521\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.084793817062378, Accuracy: 0.47542\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 2.0072811471939085, Accuracy: 0.4524\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.0860108921051026, Accuracy: 0.47688\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 2.003134494781494, Accuracy: 0.4601\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.0868639836883545, Accuracy: 0.4757\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 2.0091684452056886, Accuracy: 0.4513\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.0832394454193115, Accuracy: 0.47608\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 2.0102599609375, Accuracy: 0.4519\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.086989510269165, Accuracy: 0.47542\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 2.006588854789734, Accuracy: 0.4509\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.0836619842529296, Accuracy: 0.47728\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 1.998842580795288, Accuracy: 0.4652\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.083607489013672, Accuracy: 0.47622\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 1.9979396884918212, Accuracy: 0.4663\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.0872095010375977, Accuracy: 0.47538\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 2.0279765625, Accuracy: 0.4278\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.0916387200927735, Accuracy: 0.47278\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 2.002557953643799, Accuracy: 0.4554\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.082591170196533, Accuracy: 0.4771\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 1.9978759008407592, Accuracy: 0.4647\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.082912155075073, Accuracy: 0.47638\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 2.0024154706954955, Accuracy: 0.4569\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.086693434906006, Accuracy: 0.47608\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 2.004652795600891, Accuracy: 0.4539\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.0817030632019042, Accuracy: 0.47878\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 2.001956203651428, Accuracy: 0.4601\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.0837132054901124, Accuracy: 0.4775\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 2.0106593431472777, Accuracy: 0.4512\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.0884479512786864, Accuracy: 0.47454\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 2.00620583190918, Accuracy: 0.4543\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.0842889745330813, Accuracy: 0.47672\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 2.012916219329834, Accuracy: 0.4443\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.0859315713500974, Accuracy: 0.47576\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 1.9965247211456298, Accuracy: 0.466\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.085631200942993, Accuracy: 0.4751\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 1.9957056621551514, Accuracy: 0.4662\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.089394019241333, Accuracy: 0.47464\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 2.004343676376343, Accuracy: 0.4548\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.0849920677185056, Accuracy: 0.47768\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 2.0174590915679933, Accuracy: 0.4443\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.083034217910767, Accuracy: 0.4779\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 1.9999014013290406, Accuracy: 0.4618\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.084205907287598, Accuracy: 0.47694\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 2.0014958196640014, Accuracy: 0.4615\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.0818711154174805, Accuracy: 0.47856\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 2.000175930023193, Accuracy: 0.4632\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.084849514923096, Accuracy: 0.47706\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 2.016752463531494, Accuracy: 0.4459\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.084429977874756, Accuracy: 0.47836\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 1.9965687316894531, Accuracy: 0.4633\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.0822713547515868, Accuracy: 0.47754\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 2.0059142486572266, Accuracy: 0.4529\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.08477758102417, Accuracy: 0.47632\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 2.0055897079467773, Accuracy: 0.4574\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.0807063230895997, Accuracy: 0.4794\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 2.0193444065093993, Accuracy: 0.4403\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.084292656173706, Accuracy: 0.47912\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 2.00556583480835, Accuracy: 0.4539\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.0861586332702635, Accuracy: 0.47618\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 1.995458264541626, Accuracy: 0.4661\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.082890173034668, Accuracy: 0.47734\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 2.008392643737793, Accuracy: 0.4544\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.0853984283447264, Accuracy: 0.47652\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 2.0050887561798096, Accuracy: 0.4552\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.0872742012786865, Accuracy: 0.47484\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 2.0051735260009766, Accuracy: 0.4528\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.080928432998657, Accuracy: 0.4796\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 1.9974391899108888, Accuracy: 0.4651\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.0834461750793456, Accuracy: 0.47826\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 2.0062596950531004, Accuracy: 0.4563\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.080335821456909, Accuracy: 0.48114\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 2.009425802230835, Accuracy: 0.4517\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.083687747192383, Accuracy: 0.47832\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 2.001395227622986, Accuracy: 0.4601\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.0878293058013915, Accuracy: 0.4751\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 2.0062927686691285, Accuracy: 0.4563\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.0882430236816405, Accuracy: 0.47528\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 2.002487790298462, Accuracy: 0.4609\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.0862390420532226, Accuracy: 0.47504\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 2.0077025764465333, Accuracy: 0.4518\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.0827838220214843, Accuracy: 0.47726\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 2.0079991691589356, Accuracy: 0.4549\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.0812586478424073, Accuracy: 0.47824\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 1.9994319850921631, Accuracy: 0.4653\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.0821161553955077, Accuracy: 0.47868\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 2.0128417434692385, Accuracy: 0.4482\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.087281039505005, Accuracy: 0.47794\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 2.009223476409912, Accuracy: 0.4509\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.0815991213226317, Accuracy: 0.4787\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 1.9961252330780028, Accuracy: 0.4668\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.0837158823394777, Accuracy: 0.4761\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 2.0072842666625976, Accuracy: 0.4544\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.08674163269043, Accuracy: 0.47596\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 2.012173779296875, Accuracy: 0.45\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.084748448867798, Accuracy: 0.47722\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 2.009259306144714, Accuracy: 0.4511\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.083057139892578, Accuracy: 0.47854\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 2.0014734771728517, Accuracy: 0.4626\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.084520936012268, Accuracy: 0.47662\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 1.9972192562103273, Accuracy: 0.4653\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.081534593811035, Accuracy: 0.47848\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 2.002381454086304, Accuracy: 0.4592\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.085037080001831, Accuracy: 0.48006\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 2.003142631530762, Accuracy: 0.4569\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.0828425415802, Accuracy: 0.47764\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 2.01322835483551, Accuracy: 0.4461\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.0778626165008545, Accuracy: 0.48046\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 2.005510245513916, Accuracy: 0.457\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.079326649551392, Accuracy: 0.47942\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 1.9981186302185059, Accuracy: 0.4636\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.0889522511291503, Accuracy: 0.4764\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 2.0040501636505126, Accuracy: 0.456\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.0857866068267823, Accuracy: 0.47606\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 1.9987033504486085, Accuracy: 0.4647\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.0833678730010985, Accuracy: 0.4769\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 2.011262890815735, Accuracy: 0.4487\n",
      "[Finished Training with AdaGrad]\n",
      "\n",
      "Total Training Time: 919.4897332647815\n"
     ]
    }
   ],
   "source": [
    "model = BasicNet().to(device)\n",
    "adam_optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with AdaGrad]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, adam_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "\n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    adam_L2_train_loss.append(train_loss)\n",
    "    adam_L2_validation_loss.append(val_loss)\n",
    "    adam_L2_train_accuracy.append(train_acc)\n",
    "    adam_L2_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with AdaGrad]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HZY47HrFPciT"
   },
   "outputs": [],
   "source": [
    "adam_L2D_train_loss = []\n",
    "adam_L2D_validation_loss = []\n",
    "adam_L2D_train_accuracy = []\n",
    "adam_L2D_validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "XMMsn3QoPciT",
    "outputId": "cb197d02-fa1f-40e7-deb5-c9b90c044203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Started Training with AdaGrad]\n",
      "[Training] Epoch: 0\n",
      "[Training] Loss: 2.3456327074432375, Accuracy: 0.28942\n",
      "[Validation] Epoch: 0\n",
      "[Validation] Loss: 2.1339063274383543, Accuracy: 0.3191\n",
      "[Training] Epoch: 1\n",
      "[Training] Loss: 2.3141175094604494, Accuracy: 0.30978\n",
      "[Validation] Epoch: 1\n",
      "[Validation] Loss: 2.133437303543091, Accuracy: 0.3187\n",
      "[Training] Epoch: 2\n",
      "[Training] Loss: 2.3182794803619386, Accuracy: 0.30772\n",
      "[Validation] Epoch: 2\n",
      "[Validation] Loss: 2.1300298139572145, Accuracy: 0.3242\n",
      "[Training] Epoch: 3\n",
      "[Training] Loss: 2.3081135816955567, Accuracy: 0.31504\n",
      "[Validation] Epoch: 3\n",
      "[Validation] Loss: 2.1181259239196777, Accuracy: 0.3317\n",
      "[Training] Epoch: 4\n",
      "[Training] Loss: 2.3150811289215087, Accuracy: 0.31706\n",
      "[Validation] Epoch: 4\n",
      "[Validation] Loss: 2.1329786457061766, Accuracy: 0.3176\n",
      "[Training] Epoch: 5\n",
      "[Training] Loss: 2.314443435974121, Accuracy: 0.31576\n",
      "[Validation] Epoch: 5\n",
      "[Validation] Loss: 2.109091664505005, Accuracy: 0.3445\n",
      "[Training] Epoch: 6\n",
      "[Training] Loss: 2.305518091583252, Accuracy: 0.31578\n",
      "[Validation] Epoch: 6\n",
      "[Validation] Loss: 2.1049194057464597, Accuracy: 0.3476\n",
      "[Training] Epoch: 7\n",
      "[Training] Loss: 2.2975741284179687, Accuracy: 0.32334\n",
      "[Validation] Epoch: 7\n",
      "[Validation] Loss: 2.1178260692596433, Accuracy: 0.3337\n",
      "[Training] Epoch: 8\n",
      "[Training] Loss: 2.3023057376098635, Accuracy: 0.32116\n",
      "[Validation] Epoch: 8\n",
      "[Validation] Loss: 2.1102287727355957, Accuracy: 0.3438\n",
      "[Training] Epoch: 9\n",
      "[Training] Loss: 2.304292340774536, Accuracy: 0.3178\n",
      "[Validation] Epoch: 9\n",
      "[Validation] Loss: 2.111679116439819, Accuracy: 0.342\n",
      "[Training] Epoch: 10\n",
      "[Training] Loss: 2.3011575904083252, Accuracy: 0.32426\n",
      "[Validation] Epoch: 10\n",
      "[Validation] Loss: 2.1439625396728514, Accuracy: 0.3082\n",
      "[Training] Epoch: 11\n",
      "[Training] Loss: 2.3059953060913085, Accuracy: 0.31666\n",
      "[Validation] Epoch: 11\n",
      "[Validation] Loss: 2.1144215896606444, Accuracy: 0.3395\n",
      "[Training] Epoch: 12\n",
      "[Training] Loss: 2.3032754077911375, Accuracy: 0.31972\n",
      "[Validation] Epoch: 12\n",
      "[Validation] Loss: 2.1046461711883544, Accuracy: 0.3496\n",
      "[Training] Epoch: 13\n",
      "[Training] Loss: 2.296239980392456, Accuracy: 0.32064\n",
      "[Validation] Epoch: 13\n",
      "[Validation] Loss: 2.1149164447784425, Accuracy: 0.3368\n",
      "[Training] Epoch: 14\n",
      "[Training] Loss: 2.3003063764190674, Accuracy: 0.32104\n",
      "[Validation] Epoch: 14\n",
      "[Validation] Loss: 2.108652072906494, Accuracy: 0.3454\n",
      "[Training] Epoch: 15\n",
      "[Training] Loss: 2.2943277950286864, Accuracy: 0.32242\n",
      "[Validation] Epoch: 15\n",
      "[Validation] Loss: 2.1316952280044554, Accuracy: 0.3211\n",
      "[Training] Epoch: 16\n",
      "[Training] Loss: 2.30591368812561, Accuracy: 0.3231\n",
      "[Validation] Epoch: 16\n",
      "[Validation] Loss: 2.1039708335876464, Accuracy: 0.3455\n",
      "[Training] Epoch: 17\n",
      "[Training] Loss: 2.306674774017334, Accuracy: 0.32022\n",
      "[Validation] Epoch: 17\n",
      "[Validation] Loss: 2.10498168296814, Accuracy: 0.3501\n",
      "[Training] Epoch: 18\n",
      "[Training] Loss: 2.304107866744995, Accuracy: 0.32116\n",
      "[Validation] Epoch: 18\n",
      "[Validation] Loss: 2.121153085708618, Accuracy: 0.3304\n",
      "[Training] Epoch: 19\n",
      "[Training] Loss: 2.300477085647583, Accuracy: 0.32732\n",
      "[Validation] Epoch: 19\n",
      "[Validation] Loss: 2.1152597682952883, Accuracy: 0.3392\n",
      "[Training] Epoch: 20\n",
      "[Training] Loss: 2.3042290716552736, Accuracy: 0.31878\n",
      "[Validation] Epoch: 20\n",
      "[Validation] Loss: 2.1119021350860594, Accuracy: 0.3423\n",
      "[Training] Epoch: 21\n",
      "[Training] Loss: 2.2998759785461425, Accuracy: 0.32388\n",
      "[Validation] Epoch: 21\n",
      "[Validation] Loss: 2.097309129333496, Accuracy: 0.3564\n",
      "[Training] Epoch: 22\n",
      "[Training] Loss: 2.301842596435547, Accuracy: 0.32122\n",
      "[Validation] Epoch: 22\n",
      "[Validation] Loss: 2.109270447921753, Accuracy: 0.3466\n",
      "[Training] Epoch: 23\n",
      "[Training] Loss: 2.296016276168823, Accuracy: 0.32376\n",
      "[Validation] Epoch: 23\n",
      "[Validation] Loss: 2.122033101272583, Accuracy: 0.3288\n",
      "[Training] Epoch: 24\n",
      "[Training] Loss: 2.3035853691101074, Accuracy: 0.3234\n",
      "[Validation] Epoch: 24\n",
      "[Validation] Loss: 2.099003484725952, Accuracy: 0.3564\n",
      "[Training] Epoch: 25\n",
      "[Training] Loss: 2.3088200756073, Accuracy: 0.32062\n",
      "[Validation] Epoch: 25\n",
      "[Validation] Loss: 2.11125424156189, Accuracy: 0.3438\n",
      "[Training] Epoch: 26\n",
      "[Training] Loss: 2.2989761849975587, Accuracy: 0.32068\n",
      "[Validation] Epoch: 26\n",
      "[Validation] Loss: 2.1072045154571533, Accuracy: 0.347\n",
      "[Training] Epoch: 27\n",
      "[Training] Loss: 2.2931424369049074, Accuracy: 0.32182\n",
      "[Validation] Epoch: 27\n",
      "[Validation] Loss: 2.1046064712524415, Accuracy: 0.3497\n",
      "[Training] Epoch: 28\n",
      "[Training] Loss: 2.2955089569091798, Accuracy: 0.32598\n",
      "[Validation] Epoch: 28\n",
      "[Validation] Loss: 2.116479936981201, Accuracy: 0.3314\n",
      "[Training] Epoch: 29\n",
      "[Training] Loss: 2.3166693978881834, Accuracy: 0.3246\n",
      "[Validation] Epoch: 29\n",
      "[Validation] Loss: 2.125756583023071, Accuracy: 0.3297\n",
      "[Training] Epoch: 30\n",
      "[Training] Loss: 2.2936217433929444, Accuracy: 0.32432\n",
      "[Validation] Epoch: 30\n",
      "[Validation] Loss: 2.107935403442383, Accuracy: 0.3451\n",
      "[Training] Epoch: 31\n",
      "[Training] Loss: 2.2906485641479493, Accuracy: 0.32796\n",
      "[Validation] Epoch: 31\n",
      "[Validation] Loss: 2.0969287601470947, Accuracy: 0.3566\n",
      "[Training] Epoch: 32\n",
      "[Training] Loss: 2.296962145767212, Accuracy: 0.32424\n",
      "[Validation] Epoch: 32\n",
      "[Validation] Loss: 2.1319578788757325, Accuracy: 0.3219\n",
      "[Training] Epoch: 33\n",
      "[Training] Loss: 2.3015748374176024, Accuracy: 0.32522\n",
      "[Validation] Epoch: 33\n",
      "[Validation] Loss: 2.089600029373169, Accuracy: 0.3666\n",
      "[Training] Epoch: 34\n",
      "[Training] Loss: 2.308696592178345, Accuracy: 0.32348\n",
      "[Validation] Epoch: 34\n",
      "[Validation] Loss: 2.094840368270874, Accuracy: 0.3593\n",
      "[Training] Epoch: 35\n",
      "[Training] Loss: 2.303046866149902, Accuracy: 0.32476\n",
      "[Validation] Epoch: 35\n",
      "[Validation] Loss: 2.106108762931824, Accuracy: 0.3455\n",
      "[Training] Epoch: 36\n",
      "[Training] Loss: 2.29404111038208, Accuracy: 0.32494\n",
      "[Validation] Epoch: 36\n",
      "[Validation] Loss: 2.10439167175293, Accuracy: 0.3473\n",
      "[Training] Epoch: 37\n",
      "[Training] Loss: 2.300394914779663, Accuracy: 0.32746\n",
      "[Validation] Epoch: 37\n",
      "[Validation] Loss: 2.0889801326751707, Accuracy: 0.3641\n",
      "[Training] Epoch: 38\n",
      "[Training] Loss: 2.306068361358643, Accuracy: 0.3225\n",
      "[Validation] Epoch: 38\n",
      "[Validation] Loss: 2.104210315322876, Accuracy: 0.3482\n",
      "[Training] Epoch: 39\n",
      "[Training] Loss: 2.301307314300537, Accuracy: 0.3219\n",
      "[Validation] Epoch: 39\n",
      "[Validation] Loss: 2.0990977283477785, Accuracy: 0.3524\n",
      "[Training] Epoch: 40\n",
      "[Training] Loss: 2.2890481018066406, Accuracy: 0.3278\n",
      "[Validation] Epoch: 40\n",
      "[Validation] Loss: 2.0963837368011475, Accuracy: 0.3591\n",
      "[Training] Epoch: 41\n",
      "[Training] Loss: 2.2992493687438964, Accuracy: 0.32656\n",
      "[Validation] Epoch: 41\n",
      "[Validation] Loss: 2.104196690750122, Accuracy: 0.3499\n",
      "[Training] Epoch: 42\n",
      "[Training] Loss: 2.300504768676758, Accuracy: 0.3229\n",
      "[Validation] Epoch: 42\n",
      "[Validation] Loss: 2.102413014411926, Accuracy: 0.3502\n",
      "[Training] Epoch: 43\n",
      "[Training] Loss: 2.297412024307251, Accuracy: 0.32662\n",
      "[Validation] Epoch: 43\n",
      "[Validation] Loss: 2.1134320960998534, Accuracy: 0.34\n",
      "[Training] Epoch: 44\n",
      "[Training] Loss: 2.3003249144744875, Accuracy: 0.32732\n",
      "[Validation] Epoch: 44\n",
      "[Validation] Loss: 2.09928896522522, Accuracy: 0.355\n",
      "[Training] Epoch: 45\n",
      "[Training] Loss: 2.2968591320037843, Accuracy: 0.32756\n",
      "[Validation] Epoch: 45\n",
      "[Validation] Loss: 2.084889422225952, Accuracy: 0.3712\n",
      "[Training] Epoch: 46\n",
      "[Training] Loss: 2.2948185761260986, Accuracy: 0.3259\n",
      "[Validation] Epoch: 46\n",
      "[Validation] Loss: 2.0965050205230713, Accuracy: 0.3577\n",
      "[Training] Epoch: 47\n",
      "[Training] Loss: 2.303393177719116, Accuracy: 0.32494\n",
      "[Validation] Epoch: 47\n",
      "[Validation] Loss: 2.105111707305908, Accuracy: 0.351\n",
      "[Training] Epoch: 48\n",
      "[Training] Loss: 2.2989358534240725, Accuracy: 0.32508\n",
      "[Validation] Epoch: 48\n",
      "[Validation] Loss: 2.103663728713989, Accuracy: 0.3504\n",
      "[Training] Epoch: 49\n",
      "[Training] Loss: 2.291465881652832, Accuracy: 0.32474\n",
      "[Validation] Epoch: 49\n",
      "[Validation] Loss: 2.1075585189819335, Accuracy: 0.3449\n",
      "[Training] Epoch: 50\n",
      "[Training] Loss: 2.2905725183868406, Accuracy: 0.32394\n",
      "[Validation] Epoch: 50\n",
      "[Validation] Loss: 2.0843371421813965, Accuracy: 0.3702\n",
      "[Training] Epoch: 51\n",
      "[Training] Loss: 2.2946487354278564, Accuracy: 0.32562\n",
      "[Validation] Epoch: 51\n",
      "[Validation] Loss: 2.080619304275513, Accuracy: 0.3733\n",
      "[Training] Epoch: 52\n",
      "[Training] Loss: 2.2893458779144287, Accuracy: 0.32446\n",
      "[Validation] Epoch: 52\n",
      "[Validation] Loss: 2.1036950897216795, Accuracy: 0.3502\n",
      "[Training] Epoch: 53\n",
      "[Training] Loss: 2.3050179592132567, Accuracy: 0.32254\n",
      "[Validation] Epoch: 53\n",
      "[Validation] Loss: 2.0958618000030516, Accuracy: 0.3601\n",
      "[Training] Epoch: 54\n",
      "[Training] Loss: 2.3034765296173094, Accuracy: 0.3241\n",
      "[Validation] Epoch: 54\n",
      "[Validation] Loss: 2.1084303020477293, Accuracy: 0.3426\n",
      "[Training] Epoch: 55\n",
      "[Training] Loss: 2.2991662979125977, Accuracy: 0.32334\n",
      "[Validation] Epoch: 55\n",
      "[Validation] Loss: 2.1115760105133057, Accuracy: 0.3426\n",
      "[Training] Epoch: 56\n",
      "[Training] Loss: 2.291613631362915, Accuracy: 0.32708\n",
      "[Validation] Epoch: 56\n",
      "[Validation] Loss: 2.0990477088928223, Accuracy: 0.3589\n",
      "[Training] Epoch: 57\n",
      "[Training] Loss: 2.2928366304779053, Accuracy: 0.32708\n",
      "[Validation] Epoch: 57\n",
      "[Validation] Loss: 2.1055359210968017, Accuracy: 0.3471\n",
      "[Training] Epoch: 58\n",
      "[Training] Loss: 2.2994670709991456, Accuracy: 0.3273\n",
      "[Validation] Epoch: 58\n",
      "[Validation] Loss: 2.0937162315368654, Accuracy: 0.3603\n",
      "[Training] Epoch: 59\n",
      "[Training] Loss: 2.298833408126831, Accuracy: 0.3294\n",
      "[Validation] Epoch: 59\n",
      "[Validation] Loss: 2.0980717288970947, Accuracy: 0.3561\n",
      "[Training] Epoch: 60\n",
      "[Training] Loss: 2.2989178818511964, Accuracy: 0.32388\n",
      "[Validation] Epoch: 60\n",
      "[Validation] Loss: 2.128780495834351, Accuracy: 0.3223\n",
      "[Training] Epoch: 61\n",
      "[Training] Loss: 2.2931705558013915, Accuracy: 0.32652\n",
      "[Validation] Epoch: 61\n",
      "[Validation] Loss: 2.1007777404785157, Accuracy: 0.3524\n",
      "[Training] Epoch: 62\n",
      "[Training] Loss: 2.3025149672698975, Accuracy: 0.32692\n",
      "[Validation] Epoch: 62\n",
      "[Validation] Loss: 2.0804584802627564, Accuracy: 0.376\n",
      "[Training] Epoch: 63\n",
      "[Training] Loss: 2.3111229341125488, Accuracy: 0.32156\n",
      "[Validation] Epoch: 63\n",
      "[Validation] Loss: 2.1184488426208494, Accuracy: 0.3337\n",
      "[Training] Epoch: 64\n",
      "[Training] Loss: 2.3048900567626953, Accuracy: 0.3207\n",
      "[Validation] Epoch: 64\n",
      "[Validation] Loss: 2.1232219703674318, Accuracy: 0.3291\n",
      "[Training] Epoch: 65\n",
      "[Training] Loss: 2.293287138519287, Accuracy: 0.32566\n",
      "[Validation] Epoch: 65\n",
      "[Validation] Loss: 2.109632438278198, Accuracy: 0.3406\n",
      "[Training] Epoch: 66\n",
      "[Training] Loss: 2.297036497955322, Accuracy: 0.32314\n",
      "[Validation] Epoch: 66\n",
      "[Validation] Loss: 2.090740340423584, Accuracy: 0.365\n",
      "[Training] Epoch: 67\n",
      "[Training] Loss: 2.3036415923309326, Accuracy: 0.3235\n",
      "[Validation] Epoch: 67\n",
      "[Validation] Loss: 2.1022066284179686, Accuracy: 0.3472\n",
      "[Training] Epoch: 68\n",
      "[Training] Loss: 2.2876952305603027, Accuracy: 0.32892\n",
      "[Validation] Epoch: 68\n",
      "[Validation] Loss: 2.1023351596832276, Accuracy: 0.3494\n",
      "[Training] Epoch: 69\n",
      "[Training] Loss: 2.2913501831817626, Accuracy: 0.32864\n",
      "[Validation] Epoch: 69\n",
      "[Validation] Loss: 2.1035813934326173, Accuracy: 0.3508\n",
      "[Training] Epoch: 70\n",
      "[Training] Loss: 2.297905161819458, Accuracy: 0.32604\n",
      "[Validation] Epoch: 70\n",
      "[Validation] Loss: 2.1091695615768433, Accuracy: 0.3434\n",
      "[Training] Epoch: 71\n",
      "[Training] Loss: 2.299510927581787, Accuracy: 0.32664\n",
      "[Validation] Epoch: 71\n",
      "[Validation] Loss: 2.099138879776001, Accuracy: 0.3558\n",
      "[Training] Epoch: 72\n",
      "[Training] Loss: 2.2995604664611817, Accuracy: 0.32536\n",
      "[Validation] Epoch: 72\n",
      "[Validation] Loss: 2.0989849254608153, Accuracy: 0.3559\n",
      "[Training] Epoch: 73\n",
      "[Training] Loss: 2.2877872315979, Accuracy: 0.32992\n",
      "[Validation] Epoch: 73\n",
      "[Validation] Loss: 2.1161909156799315, Accuracy: 0.337\n",
      "[Training] Epoch: 74\n",
      "[Training] Loss: 2.2998529988861085, Accuracy: 0.32334\n",
      "[Validation] Epoch: 74\n",
      "[Validation] Loss: 2.1044188213348387, Accuracy: 0.3506\n",
      "[Training] Epoch: 75\n",
      "[Training] Loss: 2.301595046157837, Accuracy: 0.32668\n",
      "[Validation] Epoch: 75\n",
      "[Validation] Loss: 2.104703225326538, Accuracy: 0.3491\n",
      "[Training] Epoch: 76\n",
      "[Training] Loss: 2.300714351348877, Accuracy: 0.32188\n",
      "[Validation] Epoch: 76\n",
      "[Validation] Loss: 2.1050865928649904, Accuracy: 0.3501\n",
      "[Training] Epoch: 77\n",
      "[Training] Loss: 2.2904220026397706, Accuracy: 0.3273\n",
      "[Validation] Epoch: 77\n",
      "[Validation] Loss: 2.1071532844543457, Accuracy: 0.3479\n",
      "[Training] Epoch: 78\n",
      "[Training] Loss: 2.2980791596984864, Accuracy: 0.32552\n",
      "[Validation] Epoch: 78\n",
      "[Validation] Loss: 2.117209014892578, Accuracy: 0.3339\n",
      "[Training] Epoch: 79\n",
      "[Training] Loss: 2.3038257569122313, Accuracy: 0.32616\n",
      "[Validation] Epoch: 79\n",
      "[Validation] Loss: 2.088696638870239, Accuracy: 0.3645\n",
      "[Training] Epoch: 80\n",
      "[Training] Loss: 2.2999896171569825, Accuracy: 0.32294\n",
      "[Validation] Epoch: 80\n",
      "[Validation] Loss: 2.0967487813949583, Accuracy: 0.3574\n",
      "[Training] Epoch: 81\n",
      "[Training] Loss: 2.2975834897613527, Accuracy: 0.32642\n",
      "[Validation] Epoch: 81\n",
      "[Validation] Loss: 2.0967793746948242, Accuracy: 0.3577\n",
      "[Training] Epoch: 82\n",
      "[Training] Loss: 2.2956874786376953, Accuracy: 0.32856\n",
      "[Validation] Epoch: 82\n",
      "[Validation] Loss: 2.1188962211608886, Accuracy: 0.3347\n",
      "[Training] Epoch: 83\n",
      "[Training] Loss: 2.3013693671417235, Accuracy: 0.32554\n",
      "[Validation] Epoch: 83\n",
      "[Validation] Loss: 2.0943676105499267, Accuracy: 0.361\n",
      "[Training] Epoch: 84\n",
      "[Training] Loss: 2.3079999951171875, Accuracy: 0.32122\n",
      "[Validation] Epoch: 84\n",
      "[Validation] Loss: 2.0907049272537233, Accuracy: 0.3615\n",
      "[Training] Epoch: 85\n",
      "[Training] Loss: 2.2927777240753175, Accuracy: 0.32682\n",
      "[Validation] Epoch: 85\n",
      "[Validation] Loss: 2.0876032920837404, Accuracy: 0.3682\n",
      "[Training] Epoch: 86\n",
      "[Training] Loss: 2.2956181172943113, Accuracy: 0.3265\n",
      "[Validation] Epoch: 86\n",
      "[Validation] Loss: 2.094068088340759, Accuracy: 0.3598\n",
      "[Training] Epoch: 87\n",
      "[Training] Loss: 2.293458789291382, Accuracy: 0.33176\n",
      "[Validation] Epoch: 87\n",
      "[Validation] Loss: 2.100190296173096, Accuracy: 0.3547\n",
      "[Training] Epoch: 88\n",
      "[Training] Loss: 2.3051930419158935, Accuracy: 0.32444\n",
      "[Validation] Epoch: 88\n",
      "[Validation] Loss: 2.104646054840088, Accuracy: 0.3482\n",
      "[Training] Epoch: 89\n",
      "[Training] Loss: 2.2941234629058838, Accuracy: 0.3254\n",
      "[Validation] Epoch: 89\n",
      "[Validation] Loss: 2.106703371429443, Accuracy: 0.3499\n",
      "[Training] Epoch: 90\n",
      "[Training] Loss: 2.3025730280303955, Accuracy: 0.31886\n",
      "[Validation] Epoch: 90\n",
      "[Validation] Loss: 2.1211526809692383, Accuracy: 0.3338\n",
      "[Training] Epoch: 91\n",
      "[Training] Loss: 2.298839180831909, Accuracy: 0.32224\n",
      "[Validation] Epoch: 91\n",
      "[Validation] Loss: 2.0949245082855223, Accuracy: 0.3584\n",
      "[Training] Epoch: 92\n",
      "[Training] Loss: 2.3018686088562013, Accuracy: 0.32224\n",
      "[Validation] Epoch: 92\n",
      "[Validation] Loss: 2.109520723724365, Accuracy: 0.3415\n",
      "[Training] Epoch: 93\n",
      "[Training] Loss: 2.296903394088745, Accuracy: 0.3264\n",
      "[Validation] Epoch: 93\n",
      "[Validation] Loss: 2.1227207008361817, Accuracy: 0.3322\n",
      "[Training] Epoch: 94\n",
      "[Training] Loss: 2.292642761001587, Accuracy: 0.32704\n",
      "[Validation] Epoch: 94\n",
      "[Validation] Loss: 2.097304124450684, Accuracy: 0.3552\n",
      "[Training] Epoch: 95\n",
      "[Training] Loss: 2.2942928218841554, Accuracy: 0.32716\n",
      "[Validation] Epoch: 95\n",
      "[Validation] Loss: 2.1026341159820556, Accuracy: 0.3491\n",
      "[Training] Epoch: 96\n",
      "[Training] Loss: 2.299527297744751, Accuracy: 0.3248\n",
      "[Validation] Epoch: 96\n",
      "[Validation] Loss: 2.121392783355713, Accuracy: 0.3326\n",
      "[Training] Epoch: 97\n",
      "[Training] Loss: 2.3018320346069334, Accuracy: 0.32422\n",
      "[Validation] Epoch: 97\n",
      "[Validation] Loss: 2.0880527416229246, Accuracy: 0.3658\n",
      "[Training] Epoch: 98\n",
      "[Training] Loss: 2.3013409049224856, Accuracy: 0.33012\n",
      "[Validation] Epoch: 98\n",
      "[Validation] Loss: 2.1138308395385743, Accuracy: 0.3405\n",
      "[Training] Epoch: 99\n",
      "[Training] Loss: 2.3016318717956543, Accuracy: 0.32582\n",
      "[Validation] Epoch: 99\n",
      "[Validation] Loss: 2.113512670516968, Accuracy: 0.3388\n",
      "[Training] Epoch: 100\n",
      "[Training] Loss: 2.299558998184204, Accuracy: 0.32802\n",
      "[Validation] Epoch: 100\n",
      "[Validation] Loss: 2.1063082801818847, Accuracy: 0.3463\n",
      "[Training] Epoch: 101\n",
      "[Training] Loss: 2.2943953593444824, Accuracy: 0.32896\n",
      "[Validation] Epoch: 101\n",
      "[Validation] Loss: 2.101593682861328, Accuracy: 0.3502\n",
      "[Training] Epoch: 102\n",
      "[Training] Loss: 2.292499201965332, Accuracy: 0.32932\n",
      "[Validation] Epoch: 102\n",
      "[Validation] Loss: 2.0892275634765625, Accuracy: 0.3636\n",
      "[Training] Epoch: 103\n",
      "[Training] Loss: 2.288664497909546, Accuracy: 0.32538\n",
      "[Validation] Epoch: 103\n",
      "[Validation] Loss: 2.101025621032715, Accuracy: 0.3543\n",
      "[Training] Epoch: 104\n",
      "[Training] Loss: 2.298072891998291, Accuracy: 0.32692\n",
      "[Validation] Epoch: 104\n",
      "[Validation] Loss: 2.079531569671631, Accuracy: 0.3747\n",
      "[Training] Epoch: 105\n",
      "[Training] Loss: 2.3019359717559813, Accuracy: 0.32608\n",
      "[Validation] Epoch: 105\n",
      "[Validation] Loss: 2.0963410400390625, Accuracy: 0.357\n",
      "[Training] Epoch: 106\n",
      "[Training] Loss: 2.293674347457886, Accuracy: 0.32634\n",
      "[Validation] Epoch: 106\n",
      "[Validation] Loss: 2.10725616645813, Accuracy: 0.3464\n",
      "[Training] Epoch: 107\n",
      "[Training] Loss: 2.3002658089447023, Accuracy: 0.32456\n",
      "[Validation] Epoch: 107\n",
      "[Validation] Loss: 2.103207155418396, Accuracy: 0.3485\n",
      "[Training] Epoch: 108\n",
      "[Training] Loss: 2.296026629333496, Accuracy: 0.32664\n",
      "[Validation] Epoch: 108\n",
      "[Validation] Loss: 2.110722689819336, Accuracy: 0.3433\n",
      "[Training] Epoch: 109\n",
      "[Training] Loss: 2.2918532336425783, Accuracy: 0.3234\n",
      "[Validation] Epoch: 109\n",
      "[Validation] Loss: 2.1111481363296507, Accuracy: 0.3415\n",
      "[Training] Epoch: 110\n",
      "[Training] Loss: 2.29665818069458, Accuracy: 0.32692\n",
      "[Validation] Epoch: 110\n",
      "[Validation] Loss: 2.110552265548706, Accuracy: 0.3395\n",
      "[Training] Epoch: 111\n",
      "[Training] Loss: 2.2978068095397948, Accuracy: 0.3264\n",
      "[Validation] Epoch: 111\n",
      "[Validation] Loss: 2.0885898162841796, Accuracy: 0.3641\n",
      "[Training] Epoch: 112\n",
      "[Training] Loss: 2.2991663121795654, Accuracy: 0.32296\n",
      "[Validation] Epoch: 112\n",
      "[Validation] Loss: 2.0865484443664553, Accuracy: 0.3687\n",
      "[Training] Epoch: 113\n",
      "[Training] Loss: 2.304288769836426, Accuracy: 0.32332\n",
      "[Validation] Epoch: 113\n",
      "[Validation] Loss: 2.1084610744476318, Accuracy: 0.3444\n",
      "[Training] Epoch: 114\n",
      "[Training] Loss: 2.295919562225342, Accuracy: 0.32886\n",
      "[Validation] Epoch: 114\n",
      "[Validation] Loss: 2.098573300933838, Accuracy: 0.3555\n",
      "[Training] Epoch: 115\n",
      "[Training] Loss: 2.2904974680328367, Accuracy: 0.328\n",
      "[Validation] Epoch: 115\n",
      "[Validation] Loss: 2.102870166015625, Accuracy: 0.35\n",
      "[Training] Epoch: 116\n",
      "[Training] Loss: 2.29591151184082, Accuracy: 0.32744\n",
      "[Validation] Epoch: 116\n",
      "[Validation] Loss: 2.090195521736145, Accuracy: 0.3667\n",
      "[Training] Epoch: 117\n",
      "[Training] Loss: 2.2930823348236085, Accuracy: 0.3254\n",
      "[Validation] Epoch: 117\n",
      "[Validation] Loss: 2.114825835418701, Accuracy: 0.3393\n",
      "[Training] Epoch: 118\n",
      "[Training] Loss: 2.2914981970977784, Accuracy: 0.32728\n",
      "[Validation] Epoch: 118\n",
      "[Validation] Loss: 2.0889783411026, Accuracy: 0.3661\n",
      "[Training] Epoch: 119\n",
      "[Training] Loss: 2.2971938119506836, Accuracy: 0.32432\n",
      "[Validation] Epoch: 119\n",
      "[Validation] Loss: 2.1025978527069094, Accuracy: 0.3512\n",
      "[Training] Epoch: 120\n",
      "[Training] Loss: 2.29863643119812, Accuracy: 0.32812\n",
      "[Validation] Epoch: 120\n",
      "[Validation] Loss: 2.1396807949066163, Accuracy: 0.3158\n",
      "[Training] Epoch: 121\n",
      "[Training] Loss: 2.290173607254028, Accuracy: 0.32756\n",
      "[Validation] Epoch: 121\n",
      "[Validation] Loss: 2.112740894317627, Accuracy: 0.3408\n",
      "[Training] Epoch: 122\n",
      "[Training] Loss: 2.2894804335021974, Accuracy: 0.32684\n",
      "[Validation] Epoch: 122\n",
      "[Validation] Loss: 2.0902102584838866, Accuracy: 0.363\n",
      "[Training] Epoch: 123\n",
      "[Training] Loss: 2.294483480758667, Accuracy: 0.32564\n",
      "[Validation] Epoch: 123\n",
      "[Validation] Loss: 2.105715254974365, Accuracy: 0.3478\n",
      "[Training] Epoch: 124\n",
      "[Training] Loss: 2.3003342443847656, Accuracy: 0.32124\n",
      "[Validation] Epoch: 124\n",
      "[Validation] Loss: 2.104852489089966, Accuracy: 0.3513\n",
      "[Training] Epoch: 125\n",
      "[Training] Loss: 2.2988985703277587, Accuracy: 0.3247\n",
      "[Validation] Epoch: 125\n",
      "[Validation] Loss: 2.098073136329651, Accuracy: 0.3573\n",
      "[Training] Epoch: 126\n",
      "[Training] Loss: 2.300310045089722, Accuracy: 0.32724\n",
      "[Validation] Epoch: 126\n",
      "[Validation] Loss: 2.0971913261413575, Accuracy: 0.3558\n",
      "[Training] Epoch: 127\n",
      "[Training] Loss: 2.2977049446105955, Accuracy: 0.32806\n",
      "[Validation] Epoch: 127\n",
      "[Validation] Loss: 2.098432604217529, Accuracy: 0.3557\n",
      "[Training] Epoch: 128\n",
      "[Training] Loss: 2.2993956002807616, Accuracy: 0.32496\n",
      "[Validation] Epoch: 128\n",
      "[Validation] Loss: 2.121037241744995, Accuracy: 0.3325\n",
      "[Training] Epoch: 129\n",
      "[Training] Loss: 2.3002193704986573, Accuracy: 0.323\n",
      "[Validation] Epoch: 129\n",
      "[Validation] Loss: 2.0829761074066164, Accuracy: 0.3717\n",
      "[Training] Epoch: 130\n",
      "[Training] Loss: 2.295094396896362, Accuracy: 0.32762\n",
      "[Validation] Epoch: 130\n",
      "[Validation] Loss: 2.0817511112213136, Accuracy: 0.3711\n",
      "[Training] Epoch: 131\n",
      "[Training] Loss: 2.291888960418701, Accuracy: 0.3278\n",
      "[Validation] Epoch: 131\n",
      "[Validation] Loss: 2.098874480819702, Accuracy: 0.3543\n",
      "[Training] Epoch: 132\n",
      "[Training] Loss: 2.293129885864258, Accuracy: 0.32592\n",
      "[Validation] Epoch: 132\n",
      "[Validation] Loss: 2.092460963821411, Accuracy: 0.3624\n",
      "[Training] Epoch: 133\n",
      "[Training] Loss: 2.3014492609405517, Accuracy: 0.32424\n",
      "[Validation] Epoch: 133\n",
      "[Validation] Loss: 2.108583253860474, Accuracy: 0.3436\n",
      "[Training] Epoch: 134\n",
      "[Training] Loss: 2.2957725466156007, Accuracy: 0.3272\n",
      "[Validation] Epoch: 134\n",
      "[Validation] Loss: 2.1087639183044433, Accuracy: 0.3459\n",
      "[Training] Epoch: 135\n",
      "[Training] Loss: 2.295143509597778, Accuracy: 0.32612\n",
      "[Validation] Epoch: 135\n",
      "[Validation] Loss: 2.1194896198272706, Accuracy: 0.3338\n",
      "[Training] Epoch: 136\n",
      "[Training] Loss: 2.296586664352417, Accuracy: 0.32432\n",
      "[Validation] Epoch: 136\n",
      "[Validation] Loss: 2.1121871910095216, Accuracy: 0.3414\n",
      "[Training] Epoch: 137\n",
      "[Training] Loss: 2.2955896703338623, Accuracy: 0.32374\n",
      "[Validation] Epoch: 137\n",
      "[Validation] Loss: 2.0908779542922975, Accuracy: 0.3643\n",
      "[Training] Epoch: 138\n",
      "[Training] Loss: 2.2988296216583253, Accuracy: 0.32404\n",
      "[Validation] Epoch: 138\n",
      "[Validation] Loss: 2.1026079429626465, Accuracy: 0.3508\n",
      "[Training] Epoch: 139\n",
      "[Training] Loss: 2.2984048627471925, Accuracy: 0.32796\n",
      "[Validation] Epoch: 139\n",
      "[Validation] Loss: 2.102701240158081, Accuracy: 0.3503\n",
      "[Training] Epoch: 140\n",
      "[Training] Loss: 2.3016272245025635, Accuracy: 0.32494\n",
      "[Validation] Epoch: 140\n",
      "[Validation] Loss: 2.115305311203003, Accuracy: 0.3366\n",
      "[Training] Epoch: 141\n",
      "[Training] Loss: 2.3056578467559814, Accuracy: 0.32378\n",
      "[Validation] Epoch: 141\n",
      "[Validation] Loss: 2.0933171047210695, Accuracy: 0.3592\n",
      "[Training] Epoch: 142\n",
      "[Training] Loss: 2.296622645111084, Accuracy: 0.32826\n",
      "[Validation] Epoch: 142\n",
      "[Validation] Loss: 2.099659270095825, Accuracy: 0.3566\n",
      "[Training] Epoch: 143\n",
      "[Training] Loss: 2.296124405593872, Accuracy: 0.32836\n",
      "[Validation] Epoch: 143\n",
      "[Validation] Loss: 2.1483367000579836, Accuracy: 0.3035\n",
      "[Training] Epoch: 144\n",
      "[Training] Loss: 2.303029842376709, Accuracy: 0.32164\n",
      "[Validation] Epoch: 144\n",
      "[Validation] Loss: 2.105807707977295, Accuracy: 0.3484\n",
      "[Training] Epoch: 145\n",
      "[Training] Loss: 2.2995091160583496, Accuracy: 0.32712\n",
      "[Validation] Epoch: 145\n",
      "[Validation] Loss: 2.0939847648620606, Accuracy: 0.3604\n",
      "[Training] Epoch: 146\n",
      "[Training] Loss: 2.2949571168518066, Accuracy: 0.32664\n",
      "[Validation] Epoch: 146\n",
      "[Validation] Loss: 2.095201979827881, Accuracy: 0.3586\n",
      "[Training] Epoch: 147\n",
      "[Training] Loss: 2.3004019284820556, Accuracy: 0.32604\n",
      "[Validation] Epoch: 147\n",
      "[Validation] Loss: 2.103214826965332, Accuracy: 0.3495\n",
      "[Training] Epoch: 148\n",
      "[Training] Loss: 2.301073939666748, Accuracy: 0.32246\n",
      "[Validation] Epoch: 148\n",
      "[Validation] Loss: 2.121766658782959, Accuracy: 0.3297\n",
      "[Training] Epoch: 149\n",
      "[Training] Loss: 2.2894541680908205, Accuracy: 0.32538\n",
      "[Validation] Epoch: 149\n",
      "[Validation] Loss: 2.0984036293029784, Accuracy: 0.3549\n",
      "[Training] Epoch: 150\n",
      "[Training] Loss: 2.2905381910705565, Accuracy: 0.32504\n",
      "[Validation] Epoch: 150\n",
      "[Validation] Loss: 2.1208953231811525, Accuracy: 0.3325\n",
      "[Training] Epoch: 151\n",
      "[Training] Loss: 2.294026055984497, Accuracy: 0.32498\n",
      "[Validation] Epoch: 151\n",
      "[Validation] Loss: 2.1129403350830076, Accuracy: 0.3401\n",
      "[Training] Epoch: 152\n",
      "[Training] Loss: 2.2971124279785156, Accuracy: 0.3274\n",
      "[Validation] Epoch: 152\n",
      "[Validation] Loss: 2.0973446983337403, Accuracy: 0.3591\n",
      "[Training] Epoch: 153\n",
      "[Training] Loss: 2.294182289505005, Accuracy: 0.32592\n",
      "[Validation] Epoch: 153\n",
      "[Validation] Loss: 2.0991257442474365, Accuracy: 0.3548\n",
      "[Training] Epoch: 154\n",
      "[Training] Loss: 2.300494884262085, Accuracy: 0.32292\n",
      "[Validation] Epoch: 154\n",
      "[Validation] Loss: 2.1105602054595947, Accuracy: 0.3426\n",
      "[Training] Epoch: 155\n",
      "[Training] Loss: 2.297052655334473, Accuracy: 0.32604\n",
      "[Validation] Epoch: 155\n",
      "[Validation] Loss: 2.087354161071777, Accuracy: 0.3675\n",
      "[Training] Epoch: 156\n",
      "[Training] Loss: 2.300184593963623, Accuracy: 0.32528\n",
      "[Validation] Epoch: 156\n",
      "[Validation] Loss: 2.1062623901367186, Accuracy: 0.3461\n",
      "[Training] Epoch: 157\n",
      "[Training] Loss: 2.2955152542114257, Accuracy: 0.32742\n",
      "[Validation] Epoch: 157\n",
      "[Validation] Loss: 2.1208911518096922, Accuracy: 0.3324\n",
      "[Training] Epoch: 158\n",
      "[Training] Loss: 2.301680192184448, Accuracy: 0.32732\n",
      "[Validation] Epoch: 158\n",
      "[Validation] Loss: 2.089190613937378, Accuracy: 0.3642\n",
      "[Training] Epoch: 159\n",
      "[Training] Loss: 2.303287251663208, Accuracy: 0.32706\n",
      "[Validation] Epoch: 159\n",
      "[Validation] Loss: 2.0870724563598633, Accuracy: 0.368\n",
      "[Training] Epoch: 160\n",
      "[Training] Loss: 2.301927551498413, Accuracy: 0.32462\n",
      "[Validation] Epoch: 160\n",
      "[Validation] Loss: 2.1140689151763916, Accuracy: 0.3385\n",
      "[Training] Epoch: 161\n",
      "[Training] Loss: 2.299003058013916, Accuracy: 0.33016\n",
      "[Validation] Epoch: 161\n",
      "[Validation] Loss: 2.0998397857666014, Accuracy: 0.3531\n",
      "[Training] Epoch: 162\n",
      "[Training] Loss: 2.3032864101409913, Accuracy: 0.32536\n",
      "[Validation] Epoch: 162\n",
      "[Validation] Loss: 2.1054549713134767, Accuracy: 0.3476\n",
      "[Training] Epoch: 163\n",
      "[Training] Loss: 2.2945336851501463, Accuracy: 0.3261\n",
      "[Validation] Epoch: 163\n",
      "[Validation] Loss: 2.111574112701416, Accuracy: 0.3406\n",
      "[Training] Epoch: 164\n",
      "[Training] Loss: 2.29860702293396, Accuracy: 0.32582\n",
      "[Validation] Epoch: 164\n",
      "[Validation] Loss: 2.0877659797668455, Accuracy: 0.367\n",
      "[Training] Epoch: 165\n",
      "[Training] Loss: 2.2957165830993653, Accuracy: 0.32916\n",
      "[Validation] Epoch: 165\n",
      "[Validation] Loss: 2.0991809772491457, Accuracy: 0.3534\n",
      "[Training] Epoch: 166\n",
      "[Training] Loss: 2.3035732601165773, Accuracy: 0.32316\n",
      "[Validation] Epoch: 166\n",
      "[Validation] Loss: 2.0926999519348146, Accuracy: 0.3604\n",
      "[Training] Epoch: 167\n",
      "[Training] Loss: 2.2936748316192626, Accuracy: 0.32488\n",
      "[Validation] Epoch: 167\n",
      "[Validation] Loss: 2.0899055082321167, Accuracy: 0.3636\n",
      "[Training] Epoch: 168\n",
      "[Training] Loss: 2.2921871553039552, Accuracy: 0.32498\n",
      "[Validation] Epoch: 168\n",
      "[Validation] Loss: 2.119807388687134, Accuracy: 0.3328\n",
      "[Training] Epoch: 169\n",
      "[Training] Loss: 2.3039347760009767, Accuracy: 0.3223\n",
      "[Validation] Epoch: 169\n",
      "[Validation] Loss: 2.110483356285095, Accuracy: 0.3416\n",
      "[Training] Epoch: 170\n",
      "[Training] Loss: 2.300995661315918, Accuracy: 0.32604\n",
      "[Validation] Epoch: 170\n",
      "[Validation] Loss: 2.1074300811767577, Accuracy: 0.3474\n",
      "[Training] Epoch: 171\n",
      "[Training] Loss: 2.3030278997039795, Accuracy: 0.32256\n",
      "[Validation] Epoch: 171\n",
      "[Validation] Loss: 2.0959716941833495, Accuracy: 0.3571\n",
      "[Training] Epoch: 172\n",
      "[Training] Loss: 2.3021826866149904, Accuracy: 0.32592\n",
      "[Validation] Epoch: 172\n",
      "[Validation] Loss: 2.1156816436767576, Accuracy: 0.3348\n",
      "[Training] Epoch: 173\n",
      "[Training] Loss: 2.2927754728698733, Accuracy: 0.3251\n",
      "[Validation] Epoch: 173\n",
      "[Validation] Loss: 2.094655525970459, Accuracy: 0.3608\n",
      "[Training] Epoch: 174\n",
      "[Training] Loss: 2.2903916847229002, Accuracy: 0.32788\n",
      "[Validation] Epoch: 174\n",
      "[Validation] Loss: 2.1116539985656737, Accuracy: 0.3423\n",
      "[Training] Epoch: 175\n",
      "[Training] Loss: 2.2892658365631102, Accuracy: 0.32488\n",
      "[Validation] Epoch: 175\n",
      "[Validation] Loss: 2.0948428909301757, Accuracy: 0.3592\n",
      "[Training] Epoch: 176\n",
      "[Training] Loss: 2.2885122090148924, Accuracy: 0.33144\n",
      "[Validation] Epoch: 176\n",
      "[Validation] Loss: 2.0882516090393066, Accuracy: 0.3643\n",
      "[Training] Epoch: 177\n",
      "[Training] Loss: 2.2969058771514894, Accuracy: 0.3248\n",
      "[Validation] Epoch: 177\n",
      "[Validation] Loss: 2.1123659381866453, Accuracy: 0.3411\n",
      "[Training] Epoch: 178\n",
      "[Training] Loss: 2.3006606886291503, Accuracy: 0.3263\n",
      "[Validation] Epoch: 178\n",
      "[Validation] Loss: 2.106663939285278, Accuracy: 0.3471\n",
      "[Training] Epoch: 179\n",
      "[Training] Loss: 2.299705520782471, Accuracy: 0.32518\n",
      "[Validation] Epoch: 179\n",
      "[Validation] Loss: 2.0950390655517577, Accuracy: 0.359\n",
      "[Training] Epoch: 180\n",
      "[Training] Loss: 2.2973536832427977, Accuracy: 0.32756\n",
      "[Validation] Epoch: 180\n",
      "[Validation] Loss: 2.0991180854797364, Accuracy: 0.3558\n",
      "[Training] Epoch: 181\n",
      "[Training] Loss: 2.2967426779174804, Accuracy: 0.32954\n",
      "[Validation] Epoch: 181\n",
      "[Validation] Loss: 2.0892868213653566, Accuracy: 0.3657\n",
      "[Training] Epoch: 182\n",
      "[Training] Loss: 2.3007721060180666, Accuracy: 0.3311\n",
      "[Validation] Epoch: 182\n",
      "[Validation] Loss: 2.123913356399536, Accuracy: 0.3299\n",
      "[Training] Epoch: 183\n",
      "[Training] Loss: 2.296456952896118, Accuracy: 0.32548\n",
      "[Validation] Epoch: 183\n",
      "[Validation] Loss: 2.1066461067199707, Accuracy: 0.3467\n",
      "[Training] Epoch: 184\n",
      "[Training] Loss: 2.290688199996948, Accuracy: 0.33066\n",
      "[Validation] Epoch: 184\n",
      "[Validation] Loss: 2.097126441955566, Accuracy: 0.3563\n",
      "[Training] Epoch: 185\n",
      "[Training] Loss: 2.301728424606323, Accuracy: 0.3274\n",
      "[Validation] Epoch: 185\n",
      "[Validation] Loss: 2.0883791454315186, Accuracy: 0.3659\n",
      "[Training] Epoch: 186\n",
      "[Training] Loss: 2.3022964792633056, Accuracy: 0.324\n",
      "[Validation] Epoch: 186\n",
      "[Validation] Loss: 2.113090699005127, Accuracy: 0.3397\n",
      "[Training] Epoch: 187\n",
      "[Training] Loss: 2.2933953215026857, Accuracy: 0.32732\n",
      "[Validation] Epoch: 187\n",
      "[Validation] Loss: 2.102261470413208, Accuracy: 0.3515\n",
      "[Training] Epoch: 188\n",
      "[Training] Loss: 2.298979395980835, Accuracy: 0.32674\n",
      "[Validation] Epoch: 188\n",
      "[Validation] Loss: 2.1034506057739257, Accuracy: 0.3474\n",
      "[Training] Epoch: 189\n",
      "[Training] Loss: 2.2965891025543215, Accuracy: 0.32426\n",
      "[Validation] Epoch: 189\n",
      "[Validation] Loss: 2.1116494789123537, Accuracy: 0.3408\n",
      "[Training] Epoch: 190\n",
      "[Training] Loss: 2.2934514633178713, Accuracy: 0.32964\n",
      "[Validation] Epoch: 190\n",
      "[Validation] Loss: 2.0963911876678467, Accuracy: 0.3595\n",
      "[Training] Epoch: 191\n",
      "[Training] Loss: 2.3047861920928954, Accuracy: 0.32566\n",
      "[Validation] Epoch: 191\n",
      "[Validation] Loss: 2.110292936897278, Accuracy: 0.3432\n",
      "[Training] Epoch: 192\n",
      "[Training] Loss: 2.292369034729004, Accuracy: 0.32726\n",
      "[Validation] Epoch: 192\n",
      "[Validation] Loss: 2.0847640659332276, Accuracy: 0.369\n",
      "[Training] Epoch: 193\n",
      "[Training] Loss: 2.2870018943786623, Accuracy: 0.32716\n",
      "[Validation] Epoch: 193\n",
      "[Validation] Loss: 2.091993745803833, Accuracy: 0.3618\n",
      "[Training] Epoch: 194\n",
      "[Training] Loss: 2.3010942938995362, Accuracy: 0.32946\n",
      "[Validation] Epoch: 194\n",
      "[Validation] Loss: 2.0974619398117067, Accuracy: 0.3547\n",
      "[Training] Epoch: 195\n",
      "[Training] Loss: 2.30366943939209, Accuracy: 0.32406\n",
      "[Validation] Epoch: 195\n",
      "[Validation] Loss: 2.0912703338623047, Accuracy: 0.3647\n",
      "[Training] Epoch: 196\n",
      "[Training] Loss: 2.2947689765930175, Accuracy: 0.32568\n",
      "[Validation] Epoch: 196\n",
      "[Validation] Loss: 2.0991342082977296, Accuracy: 0.3534\n",
      "[Training] Epoch: 197\n",
      "[Training] Loss: 2.29413696105957, Accuracy: 0.32524\n",
      "[Validation] Epoch: 197\n",
      "[Validation] Loss: 2.0889323970794678, Accuracy: 0.3645\n",
      "[Training] Epoch: 198\n",
      "[Training] Loss: 2.3002660837554934, Accuracy: 0.32458\n",
      "[Validation] Epoch: 198\n",
      "[Validation] Loss: 2.1079826961517334, Accuracy: 0.3416\n",
      "[Training] Epoch: 199\n",
      "[Training] Loss: 2.3021960646820068, Accuracy: 0.32166\n",
      "[Validation] Epoch: 199\n",
      "[Validation] Loss: 2.0968511821746825, Accuracy: 0.3545\n",
      "[Finished Training with AdaGrad]\n",
      "\n",
      "Total Training Time: 918.4741656240076\n"
     ]
    }
   ],
   "source": [
    "model = BasicDropoutNet().to(device)\n",
    "adam_optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"[Started Training with AdaGrad]\")\n",
    "\n",
    "train_time = 0.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training Phase\n",
    "    print(f\"[Training] Epoch: {epoch}\")\n",
    "    start = time.monotonic()\n",
    "    train_loss, train_acc = train(model, train_loader, adam_optimizer, device)\n",
    "    end = time.monotonic()\n",
    "    train_time += (end - start)\n",
    "\n",
    "    # Validation Phase\n",
    "    print(f\"[Validation] Epoch: {epoch}\")\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    adam_L2D_train_loss.append(train_loss)\n",
    "    adam_L2D_validation_loss.append(val_loss)\n",
    "    adam_L2D_train_accuracy.append(train_acc)\n",
    "    adam_L2D_validation_accuracy.append(val_acc)\n",
    "\n",
    "print(f\"[Finished Training with AdaGrad]\", end=\"\\n\\n\")\n",
    "print(f\"Total Training Time: {train_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-e7k46thPciU"
   },
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "kPRl9tK3PciU",
    "outputId": "000b9132-4619-4707-c203-4ef414dd4f82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x148e008d4be0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABPkklEQVR4nO3dd3xc1Z3//9dn+kga9eIiyZItF7k3MM1gqoEECCnAJiGYkJBkk5C2BJIlCdlf2N0Ekk02m4SQLwspxCQhtCUJvbiADS7CTW6yJVuW1S1p1Kae3x93NJZkyRZGI9nW5/l4zGPu3HvuvWfuSPOee+6954oxBqWUUmOXbbQroJRSanRpECil1BinQaCUUmOcBoFSSo1xGgRKKTXGaRAopdQYp0GgRp2I/ENEbhnusu+xDstEpHq4l3umEZHXReQzo10PNbwco10BdXoSkfZeL5OAABCJvf6cMeaxoS7LGHNVIsqe6UTkUeDjQLDX6ApjzLzRqZE6XWkQqJNijEnpGRaRSuAzxpiX+5cTEYcxJjySdRtjfmSMuWe0K6FOb9o0pIZVTxOLiNwlIrXAIyKSISLPiUiDiByJDef3mife3CAiK0RkjYg8ECu7X0SuOsmyxSKySkT8IvKyiPxCRP4wxPdRGltXi4hsF5Fre027WkR2xJZ7SET+JTY+O/beWkSkWURWi8gx/2Mi8isReaDfuGdE5Oux4btiy/WLyC4RuXSIm7/38opExIjI7SJSIyKHe+oZm+4WkZ/GptXEht29pl8nImUi0iYiFSJyZa/FTxKRtbH6vSgi2bF5PCLyBxFpim2Dd0Qk773WXY08DQKVCOOATGAScDvW39kjsdeFQBfwP8eZfwmwC8gGfgQ8LCJyEmX/CLwNZAH3AjcPpfIi4gT+D3gRyAW+DDwmItNjRR7Gav7yAbOBV2PjvwFUAzlAHvBtYKA+XFYCN/bUU0QygCuAx2Pr+BJwVmz5y4HKodR7EBcDU2PLv0tELouN/1fgHGA+MA84G7gnVp+zgd8BdwLpwIX96vBx4FasbeMCegLmFiANKMDa5p/H+qzVKU6DQCVCFPieMSZgjOkyxjQZY/5qjOk0xviB+4CLjjN/lTHmN8aYCPBbYDzWF+uQy4pIIXAW8F1jTNAYswZ4doj1PwdIAf4zNu+rwHPAP8Wmh4CZIpJqjDlijNnUa/x4YJIxJmSMWW0G7sxrNVZALI29/ijwljGmBus4izu2fKcxptIYU3Gcuv5L7Nd3z+O3/aZ/3xjTYYzZihXGPe/hE8C/GWPqjTENwPc5GpS3Af9rjHnJGBM1xhwyxuzstcxHjDG7jTFdwJ+xwqTn/WcBJcaYiDFmozGm7Th1V6cIDQKVCA3GmO6eFyKSJCK/FpEqEWkDVgHpImIfZP7angFjTGdsMOU9lp0ANPcaB3BwiPWfABw0xkR7jasCJsaGPwJcDVSJyBsicm5s/P3AXuBFEdknIncPtPBYODzO0S/ljwOPxabtBb6KtQdTLyKPi8iE49T1AWNMeq9H/zOqer/nqth763mPVYNMKwCOFz61vYY7OfrZ/B54AWvPpkZEfhTbu1KnOA0ClQj9fwV/A5gOLDHGpGI1NQAM1twzHA4DmSKS1GtcwRDnrQEK+rXvFwKHAIwx7xhjrsNqGnka61cxxhi/MeYbxpjJwLXA14/Tvr8S+KiITMJq3vprzwRjzB+NMRdgNaUZ4IdDrPdAer/nwth763mPkwaZdhCY8l5XFNsL+r4xZiZwHvBB4FPvucZqxGkQqJHgw2orbhGRTOB7iV6hMaYK2ADcKyKu2K/2a4Y4+3qsX7rfFBGniCyLzft4bFmfEJE0Y0wIaMNqCkNEPigiJbG2/1asZp7oQCswxmwGGoH/B7xgjGmJLWO6iFwSO3DbjbXdBlzGEH0ntkc2C6td/0+x8SuBe0QkJ3aw97tAz4H0h4FbReRSEbGJyEQRmXGiFYnIxSIyJ7an14bVVPR+6q5GiAaBGgk/BbxYX3zrgOdHaL2fAM4FmoAfYH0JBk40kzEmiPXFfxVWnX8JfKpXO/nNQGWsmevzsfWAdVD2ZaAdeAv4pTHmteOs6o/AZbHnHm7gP2PrrcXa6/jWcZbxTRFp7/Vo7Df9DazmqlewmpFejI3/AVZQbgG2Apti4zDGvI0VGv+FFWhv0HfvYTDjgCewQqA8Nt/vhzCfGmWiN6ZRY4WI/AnYaYxJ+B7JaBORImA/4NTrONSJ6B6BOmOJyFkiMiXWvHElcB1Wm75Sqhe9slidycYBT2Kd0lgNfCHWNq+U6kWbhpRSaozTpiGllBrjTrumoezsbFNUVDTa1VBKqdPKxo0bG40xOQNNO+2CoKioiA0bNox2NZRS6rQiIlWDTUtY01CsJ8K3ReRdsXpv/P4AZdwi8icR2Ssi62OnvCmllBpBiTxGEAAuid0kYz5wpYic06/MbcARY0wJ1sUr7+dSeqWUUichYUFgLD13sXLGHv1PUboOq8dIsK5IvPQ43Q0rpZRKgISeNSQidhEpA+qBl4wx6/sVmUisd8TY1Y+tWOd891/O7SKyQUQ2NDQ0JLLKSik15iQ0CGJ9ks8H8oGzRWT2SS7nIWPMYmPM4pycAQ96K6WUOkkjch1BrGfF14Ar+006RKybXBFxYN3dqGkk6qSUUsqSyLOGckQkPTbsBS4HdvYr9izW7e3AukvTq4Pc0UkppVSCJPI6gvHAb2N9k9uAPxtjnhORfwM2GGOexer3/PcishdoBm5KVGUC+/bR9txzuEtKcE0pwVVchM3lStTqlFLqtJGwIDDGbAEWDDD+u72Gu4GPJaoOvQV27qTxwV9DNHafDLsdV2Eh7pIS3FNLcE2ZgrtkqgaEUmrMOe2uLD5ZqVdfTcqllxLcv5/A3goCe/cQ2LuXwJ49+F95RQNCKTVmjZkgALC53XhmzMAzo+9d96KBAMHKSgJ79hLYu4dgRcVxA8JVMsUKipISXMXFGhBKqdPamAqCwdjcbjzTp+OZPr3P+D4BUbGX4N69BPbuxf/qqxCJWIXiATEFV0kJ7ikluKdOxT25GHE6R+HdKKXUe6NBcByDBkQwGGtisoIhuLciFhCvxQNCnE4rEGaW4iktxVM6E8/0adiSk0fjrSil1KA0CE6CzeU6TkBUEti9m+6d5QTKy2l/+RVan/irVUAEV1ERntIZuEtL8c6dh3fObGxJSaPwLpRSynLa3aFs8eLF5nTqhtoYQ7i2lu7ynXSX76C7vJzAjnJCNTVWAbsd97RpeOfPI2n+fLzz5+MsLES7XFJKDScR2WiMWTzgNA2C0RE+coTuLVvoevddusrK6Hp3C9GODgDsGRl4FywgecnZJJ1zLu5pUzUYlFLvy/GCQJuGRokjI4OUiy4i5aKLADCRCIGKCisUyt6lc+MG2l99FQB7VhbJS5aQdO45JJ97Hq78iaNZdaXUGUb3CE5hoZoaOt5aR8f6dXS+tY5wrOdVV8kUfMuWkbJsGd758xGH5rlS6vi0aegMYIwhuG8fHWvX0v7663S8swFCIexpaSRfeCEpyy4i5YILsKeljXZVlVKnIA2CM1CkvZ2ONVYotL/xBpEjR8BuJ2nxYnyXX47v8stw5uWNdjWVUqcIDYIznIlE6NqyhfbXXsf/yisEKyoA8M6bh++Ky/FdfjmuwsJRrqVSajRpEIwxgYoK/C+9hP/Fl+jesQMA9/Tp8VBwT9WzkJQaazQIxrBg9SErFF56ia7Nm8EYXEVF+JYvJ3X5FbhLSzUUlBoDNAgUAKH6etpfeYW2F1+kc/3bEI3iLCwkdfkV+K5Yjmf2LA0Fpc5QGgTqGOHmZvyvvIL/+RfoWLcOIhGcEyfG9xQ8c+dqKCh1BtEgUMcVPnKE9ldfpe2FF+h4ax2EQjjGjyf1iivwXbkc77x5iG1Ebm+tlEoQDQI1ZJHWVvyvvob/hRfoWLsWEwrhyMvDd8UVpF65HO+CBRoKSp2GNAjUSYn4/bS//jptz79Ax+rVmGAQR06OdZ3ClctJWrQIsdtHu5pKqSHQIFDvW6S9g/Y3Xsf//Au0r1qFCQSwZ2WRcvEyfBdfTPK552p32kqdwjQI1LCKdnTQvno1/hdfpH3VaqLt7YjbTdI5S/BdfDEpy5bhHDdutKuplOpFg0AljAkG6dy4Ef9rr9H+2uuEDh4EwDNzJikXX0zKxRfjmTVTz0BSapRpEKgRYYwhWFERD4WusjKIRnHk5pJy0UUkX7iU5HPPxZ6SMtpVVWrM0SBQoyLc3Ez7G6tof+01OtautW6843CQNH++1WPq0gtwz5ihewtKjQANAjXqTChEV1kZ7avX0L5mNYEd5QDYc7JJOf8CkpdeQPJ55+HIyBjlmip1ZtIgUKeccEMD7WvX0rFqNR1r1xJpbQURPHPnkLLU2lvwzJ6tp6cqNUw0CNQpzUQidG/bRvvqNXSsXk3X1q0QjWJPSyPpvHOt23SevQRXcZE2Iyl1kjQI1GklfOQInW+9Rfuq1XSsW0e4thYAR24uSUuWkLzkbJKWLMGZn6/BoNQQaRCo05YxhtCBA3SsX0/nuvV0vP02kcZGAJwTJuBdtAjvgvkkLViAe9o0bUpSahAaBOqMEb9387p1dK5/m87Nm4g0WMFgS0rCO38e3vkL8C5YgHfeXOypqaNcY6VODaMSBCJSAPwOyAMM8JAx5mf9yqQBfwAKAQfwgDHmkeMtV4NA9WaMIXSohq7Nm+navInOzWUEdu2CaBQAV1ERntmz8cyehXf2bDylpdiSk0e51kqNvNEKgvHAeGPMJhHxARuBDxljdvQq820gzRhzl4jkALuAccaY4GDL1SBQJxJp76B76xa6ysro2r6d7m3b48cZEME1ZTLeWbPjAeEpLcXm8YxupZVKsOMFgSNRKzXGHAYOx4b9IlIOTAR29C4G+MQ64pcCNAPhRNVJjQ32lGSSzz2X5HPPjY8LNzTEQ6F72zba166l9ZlnYjPYcU+ZgnvGdDwzSvHMmI57xgwcmZmj9A6UGlkjcoxARIqAVcBsY0xbr/E+4FlgBuADbjTG/G2A+W8HbgcoLCxcVFVVlfA6qzObMYZwfT3d27bRtXUr3eXlBHbuIlxXFy/jyM09JhxckybpAWl1WhrVg8UikgK8AdxnjHmy37SPAucDXwemAC8B83qHRX/aNKQSKXzkCIGdO+neuYvAznLruaICwtaOqng8uKdNwzNjhhUS06fjLinBnpY2yjVX6vhGpWkotmIn8Ffgsf4hEHMr8J/GSqO9IrIfa+/g7UTWS6nBODIycPRrVooGgwQrKugu30lglxUSbS+8QPTPfz46X24u7qlTjz6mTcU9ZYreo0GdFhIWBLF2/4eBcmPMTwYpdgC4FFgtInnAdGBfouqk1MmwuVx4SkvxlJbGxxljCNfWEtizx3rstp6PrFyJCQTi5ZwFBbhLSvoEhKu4GJvLNRpvRakBJfKsoQuA1cBWIBob/W2sU0UxxjwoIhOAR4HxgGDtHfzheMvVpiF1KjORCKGDB+mOBURw714rKPZXxpuXsNtxFRVZwVBSgrtkCq7Jk3EVFWlAqITRC8qUGmUmGCRQWXl0D2KPFRChgweh53/QbseVn49ryhTcUybjmtzzPFnv4aDet1E7RqCUsojLhWfaNDzTpvUZH+3qIrh/P4GKfQT2VRCMPbevXg2hULycIy+vXzhMwT25GHt2tva3pN43DQKlRpHN68UzcyaemTP7jDfhMMEDBwnuqyCwbz/BigoC+/bR+uSTRDs7j86floa7uBjXlMm4J0+xnqdMwTlxImKzjfTbUacpDQKlTkHicOCeXIx7cjG+XuONMYTr6ghUHN17CFbso/31N2j969ET88TlwjVpEq7iYutRVIS7uAhXcbGe6qqOoUGg1GlERHCOG4dz3Dg4//w+0yItLQT27bNCYn+l1eS0ezf+V189eqAasGdkxAKiKBYQsbAoKED0YPWYpAeLlTrDmVCIYHV1PByClbGQqKyMd+kNgM2GMz8fV3ER7qKeoLBCwpGbo8ciTnN6sFipMUycTtzFxbiLi4GL+0yL+P1HgyEeEpV0rn8b090dL2dLSsJVVBRvZorvUUwqwp6ivbme7jQIlBrD7D4f3jlz8M6Z02e8iUYJ19X1Cogqgvv301VWRtvf/370lFesq6rjAVFUFNujKLLuIOfQr5jTgX5KSqljiM2Gc/x4nOPHk3zeeX2mRbu7CR44cLSpKbYn0fb880RbW48WdDhwFRT02pOYFD8moae9nlo0CJRS74nN4xnwmgiwOu0L7q+0mpgqjx6T6Fi7FhM8epsRW0rK0T2I2F6Eq0ibmkaLBoFSatg4MjJwZGSQtHBBn/EmEiF0uPaYgOjavJm2v/3t2KameEBYexLu4mLr2ginc6Tf0pigQaCUSjix23HlT8SVPxEu6Hvaa5+mpl5B4X/xRSItLUcLOhxWFxz9jke4iopw5OhZTe+HBoFSalSdsKmpstI6WN27qenNN/v08mpLTu63F3G02Umbmk5Mg0ApdcqKNzUt6NfUFI0SPnyYQHwPwnruevfdY89qysnpGxCTi3FPnmw1Nend5gANAqXUaUhsNpwTJ+KcOPGYK6yjgQChAweskNjfq6nppZeIHDlydBk93XBMnhwPB1fxZNzFRdiSx9ZehAaBUuqMYnO74zcC6i/S0mJdF7Fvv9VP0779BHbuxP/yyxCJxMs5xo+3ut7oFxJn6hXWGgRKqTHDnp5O0oIFxzQ1RYNBay9i3z6C+/YT3L+PwL79tD71FNGOjng5W3IyrsmTcU8uxlXcKyQKC0/rfpo0CJRSY57N5YrdLa6kz3hjDOH6hlgwxEJi3z463n6H1meePVqw56ZC/ZuZJhdjT08f2TdzEjQIlFJqECKCMy8XZ14uyeec02datKPDOg6xr19IrFmD6XVTIXtGxtGzmCZNil9h7SosxJaUNNJvaUAaBEopdRJsycl4Z83CO2tWn/EmEiF06FCfZqZgZRUda9fS+tRTfco68vKscJgUC4dYSDgLCkb0/tUaBEopNYzEbsdVWIirsBCWLeszLdrRYV08V1lJsKoqfn2E/+WX+5zRRKyvp/57Ee7p03Hm5Q17nTUIVMKFQiGqq6vp7tWtsTq9eTwe8vPzcWqXD++JLTkZT2kpntLSY6ZFWlutcKiqsk57rbJCovXdd4m2twOQedunybvzzmGvlwaBSrjq6mp8Ph9FRUVn5Kl3Y40xhqamJqqrqykuLh7t6pwx7GlpeOfOxTt3bp/xxhgizc0EKyuxZ2YmZN0aBCrhuru7NQTOICJCVlYWDQ0No12VMUFEcGRl4cjKStg6bAlbslK9aAicWfTzPLNoECil1BinQaDGjKeffhoRYefOnQNOX7ZsGRs2bDjuMsLhMN/+9reZOnUq8+fPZ/78+dx3333vq16vv/46H/zgB9/XMpR6PzQI1JixcuVKLrjgAlauXHnSy7jnnnuoqalh69atlJWVsXr1akK9Lh7qYYwhGo2+n+oqNWI0CNSY0N7ezpo1a3j44Yd5/PHHAejq6uKmm26itLSU66+/nq6urnj5L3zhCyxevJhZs2bxve99D4DOzk5+85vf8POf/xyPxwOAz+fj3nvvBaCyspLp06fzqU99itmzZ3Pw4MEBlwPw/PPPM2PGDBYuXMiTTz45QltBqYHpWUNqRH3//7azo6ZtWJc5c0Iq37tm1nHLPPPMM1x55ZVMmzaNrKwsNm7cyBtvvEFSUhLl5eVs2bKFhQsXxsvfd999ZGZmEolEuPTSS9myZQsAhYWF+Hy+QdezZ88efvvb33JOrDuCgZYzbdo0PvvZz/Lqq69SUlLCjTfeOAxbQamTl7A9AhEpEJHXRGSHiGwXka8MUm6ZiJTFyryRqPqosW3lypXcdNNNANx0002sXLmSVatW8clPfhKAuXPnMrfX+dt//vOfWbhwIQsWLGD79u3s2LHjmGU+8sgjzJ8/n4KCAg4ePAjApEmT4iEw2HJ27txJcXExU6dORUTidVBqtCRyjyAMfMMYs0lEfMBGEXnJGBP/jxKRdOCXwJXGmAMikpvA+qhTwIl+uSdCc3Mzr776Klu3bkVEiEQiiAgL+nVF3GP//v088MADvPPOO2RkZLBixQq6u7spKSnhwIED+P1+fD4ft956K7feeiuzZ88mEuvLPrnXDU0GW45Sp5qE7REYYw4bYzbFhv1AOTCxX7GPA08aYw7EytUnqj5q7HriiSe4+eabqaqqorKykoMHD1JcXMyiRYv44x//CMC2bdvizT9tbW0kJyeTlpZGXV0d//jHPwBISkritttu40tf+lL8Cz0SiRAMBgdc72DLmTFjBpWVlVRUVAC8r4PXSg2HETlGICJFwAJgfb9J0wCniLwO+ICfGWN+NxJ1UmPHypUrueuuu/qM+8hHPsLmzZvp6uqitLSU0tJSFi1aBMC8efNYsGABM2bMoKCggPN73Qrxvvvu4zvf+Q6zZ8/G5/Ph9Xq55ZZbmDBhAjU1NX3WMdhyPB4PDz30EB/4wAdISkpi6dKl+P3+BG8FpQYnptdNnhOyApEU4A3gPmPMk/2m/Q+wGLgU8AJvAR8wxuzuV+524HaAwsLCRVVVVQmtsxpe5eXllA7QyZY6vennenoRkY3GmMUDTUvo6aMi4gT+CjzWPwRiqoEXjDEdxphGYBUwr38hY8xDxpjFxpjFOTk5iayyUkqNOYk8a0iAh4FyY8xPBin2DHCBiDhEJAlYgnUsQSml1Ag54TECEZkCVBtjAiKyDJgL/M4Y03KCWc8Hbga2ikhZbNy3gUIAY8yDxphyEXke2AJEgf9njNl2Eu9DKaXUSRrKweK/AotFpAR4COtX/B+Bq483kzFmDXDCLgqNMfcD9w+hHkoppRJgKE1DUWNMGLge+Lkx5k5gfGKrpZRSaqQMJQhCIvJPwC3Ac7Fxen86pZQ6QwwlCG4FzsU6/XO/iBQDv09stZQaXna7nfnz5zN79myuueYaWlpaAKujOBHhnnvuiZdtbGzE6XTypS99CYBdu3axbNky5s+fT2lpKbfffjtgdR+dlpYWH//9739/xN+XUsPhhEFgjNlhjLnDGLNSRDIAnzHmhyNQN6WGjdfrpaysjG3btpGZmckvfvGL+LTi4mL+9re/xV//5S9/Ydaso11h3HHHHXzta1+jrKyM8vJyvvzlL8enLV26lLKyMjZs2MAf/vAHNm3a1Ge94XA4ge9KqeFxwiAQkddFJFVEMoFNwG9EZLDTQZU65Z177rkcOnQo/jopKYnS0tL4TWn+9Kc/ccMNN8SnHz58mPz8/PjrOXPmHLPM5ORkFi1axN69e7n33nu5+eabOf/887n55puprKzkkksuYe7cuVx66aUcOHAAgBUrVvD5z3+exYsXM23aNJ577rljlqvUSBjKWUNpxpg2EfkM1mmj3xORLYmumDpD/eNuqN06vMscNweu+s8hFY1EIrzyyivcdtttfcbfdNNNPP744+Tl5WG32/t0GfG1r32NSy65hPPOO48rrriCW2+9lfT09D7zNzU1sW7dOr7zne+wY8cOduzYwZo1a/B6vVxzzTXccsst3HLLLfzv//4vd9xxB08//TRgNU29/fbbVFRUcPHFF7N37974vQ6UGilDOUbgEJHxwA0cPVis1Gmlq6uL+fPnM27cOOrq6rj88sv7TL/yyit56aWXePzxx4+5P8Ctt95KeXk5H/vYx3j99dc555xzCAQCAKxevZoFCxZwxRVXcPfdd8eblK699lq8Xi8Ab731Fh//+McBuPnmm1mzZk182TfccAM2m42pU6cyefLkQW+jqVQiDWWP4N+AF4C1xph3RGQysCex1VJnrCH+ch9uPccIOjs7Wb58Ob/4xS+444474tNdLheLFi3ixz/+MTt27ODZZ5/tM/+ECRP49Kc/zac//Wlmz57Ntm3WdY9Lly4dsEmnd3fUx2NdgD/4a6VGwlAOFv/FGDPXGPOF2Ot9xpiPJL5qSg2/pKQk/vu//5sf//jHxxzI/cY3vsEPf/hDMjMz+4x//vnn4/clrq2tpampiYkT+/eoPrjzzjsvfnvMxx57jKVLl8an/eUvfyEajVJRUcG+ffuYPn36yb41pU7aULqYyAd+jtVlBMBq4CvGmOpEVkypRFmwYAFz585l5cqVfb6UZ82a1edsoR4vvvgiX/nKV+Jt9/fffz/jxo0bcjPOz3/+c2699Vbuv/9+cnJyeOSRR+LTCgsLOfvss2lra+PBBx/U4wNqVJywG2oReQmrS4meawc+CXzCGHP54HMlzuLFi03P2R3q9KDdFQ9sxYoVfPCDH+SjH/3oaFflpOjnenp5v91Q5xhjHjHGhGOPRwHtC1oppc4QQzlY3CQinwR67qf3T0BT4qqk1Njw6KOPjnYVlAKGtkfwaaxTR2uBw8BHgRUJrJNSSqkRdMI9AmNMFXBt73Ei8gDwL4mqlFJKqZFzsncou+HERZRSSp0OTjYI9KoXpZQ6QwwaBCKSOcgjCw0CdRp6+umnEZFBz/9ftmwZI3Vq8rJly1i8+OiZfBs2bGDZsmUntax///d/H6ZaqbHqeHsEG4ENsefejw1AMPFVU2p4rVy5kgsuuICVK1eeuPAwefTRR7n33nsHnFZfX88//vGP972OkwmCSCTyvterzhyDBoExptgYMzn23P8xeSQrqdT71d7ezpo1a3j44Yfj3T10dXVx0003UVpayvXXX09XV1e8/Be+8AUWL17MrFmz+N73vhcfX1RUxLe+9S3mz5/P4sWL2bRpE8uXL2fKlCk8+OCD76lOd955J/fdd98x4yORCHfeeSdnnXUWc+fO5de//jVgdYd94YUXxm+ws3r1au6+++54h3qf+MQnAPjDH/7A2Wefzfz58/nc5z4X/9JPSUnhG9/4BvPmzeOtt97iJz/5CbNnz2b27Nn89Kc/BeDuu+/uc6+Ge++9lwceeOA9vS91+hnKdQRKDZsfvv1DdjYPbw+bMzJncNfZdx23zDPPPMOVV17JtGnTyMrKYuPGjbzxxhskJSVRXl7Oli1bWLhwYbz8fffdR2ZmJpFIhEsvvZQtW7Ywd+5cwOoWoqysjK997WusWLGCtWvX0t3dzezZs/n85z8/5Hqfe+65PPXUU7z22mv4fL74+Icffpi0tDTeeecdAoEA559/PldccQVPPvkky5cv51//9V+JRCJ0dnaydOlS/ud//oeysjLAutr3T3/6E2vXrsXpdPLP//zPPPbYY3zqU5+io6ODJUuW8OMf/5iNGzfyyCOPsH79eowxLFmyhIsuuogbb7yRr371q3zxi18E4M9//jMvvPDCkN+TOj1pEKgxYeXKlXzlK18BrHsPrFy5kr1798Z7IJ07d278ix6sL8CHHnqIcDjM4cOH2bFjR3z6tddaZ1PPmTOH9vZ2fD4fPp8Pt9tNS0tLPDwAmpubCQaD8fsP/P73v+9zY5t77rmHH/zgB/zwh0dv+vfiiy+yZcsWnnjiCQBaW1vZs2cPZ511Fp/+9KcJhUJ86EMfYv78+ce8z1deeYWNGzdy1llnAdZeT25uLmDdrvMjH7H6i1yzZg3XX399vJfUD3/4w6xevZo77riD+vp6ampqaGhoICMjg4KCgvex5dXpQINAjagT/XJPhObmZl599VW2bt2KiBCJRBARFixYMGD5/fv388ADD/DOO++QkZHBihUr6O7ujk93u90A2Gy2+HDP63A4THZ2dvwX+qOPPkplZeWgxwkuueQS7rnnHtatWxcfZ4zh5z//OcuXLz+m/KpVq/jb3/7GihUr+PrXv86nPvWpPtONMdxyyy38x3/8xzHzejwe7Hb7wBupl4997GM88cQT1NbWHnNvBnVmGtLpoyJiF5EJIlLY80h0xZQaLk888QQ333wzVVVVVFZWcvDgQYqLi1m0aBF//OMfAdi2bRtbtlg33mtrayM5OZm0tDTq6uqG5YDu8dxzzz386Ec/ir9evnw5v/rVr+JdX+/evZuOjg6qqqrIy8vjs5/9LJ/5zGfi90d2Op3xspdeeilPPPEE9fX1gBWCVVVVx6xz6dKlPP3003R2dtLR0cFTTz0V74n1xhtv5PHHH+eJJ57gYx/7WELfuzo1DKUb6i8D3wPqgGhstAHmDjqTUqeQlStXctddffdEPvKRj7B582a6urooLS2ltLSURYsWATBv3jwWLFjAjBkzKCgo4Pzzzx9oscPm6quvJifnaD+On/nMZ6isrGThwoUYY8jJyeHpp5/m9ddf5/7778fpdJKSksLvfvc7AG6//Xbmzp3LwoULeeyxx/jBD37AFVdcQTQaxel08otf/IJJkyb1WefChQtZsWIFZ599dnydPXtIs2bNwu/3M3HiRMaPH5/Q965ODUPphnovsMQYc0p0NKfdUJ9+tLviM5N+rqeX99sN9UGgdXirpJRS6lQxlIPF+4DXReRvQKBnpDHmJwmrlVJKqREzlCA4EHu4Yg+llFJnkKF0Q/39kaiIUkqp0TFoEIjIT40xXxWR/8M6S6gPY8y1A8zWe/4C4HdAXmz+h4wxPxuk7FnAW8BNxpgn3kP9lVJKvU/H2yPouVn9yXY0Ega+YYzZJCI+YKOIvGSM2dG7kIjYgR8CL57kepRSSr0Px+t0bmPs+Y2BHidasDHmsDFmU2zYD5QDEwco+mXgr0D9Sb0DpYZoOLqhXrZsGdOnT2fu3LnMmDGDL33pS7S0tJxw3UVFRTQ2NtLS0sIvf/nLk6m+UglzwtNHRWSqiDwhIjtEZF/P472sRESKgAXA+n7jJwLXA796L8tT6mQMVzfUjz32GFu2bGHLli243W6uu+66Ic+rQaBORUO5juARrC/qMHAxVrv/H4a6AhFJwfrF/1VjTFu/yT8F7jLGRI+Zse8ybheRDSKyoaGhYairVipuuLqh7s3lcvGjH/2IAwcO8O677wKDdwHd4+6776aiooL58+dz55130t7ezqWXXsrChQuZM2cOzzzzTIK2gFKDG8rpo15jzCsiIrEb2d8rIhuB755oRhFxYoXAY8aYJwcoshh4XEQAsoGrRSRsjHm6dyFjzEPAQ2BdWTyEOqtTVO2//zuB8uHthtpdOoNx3/72ccsMZzfUvdntdubNm8fOnTtxuVyDdgHd4z//8z/Ztm1bvFO6cDjMU089RWpqKo2NjZxzzjlce+21xP4nlBoRQwmCgIjYgD0i8iXgEJByopnE+kt+GCgf7OIzY0xxr/KPAs/1DwGlhsNwdkPdX083LcfrAnowxhi+/e1vs2rVKmw2G4cOHaKuro5x48a97/es1FANJQi+AiQBdwD/H1bz0C1DmO984GZgq4iUxcZ9GygEMMa8t9s5qTPCiX65J8Jwd0PdWyQSYevWrZSWllJfXz9oF9CDeeyxx2hoaGDjxo04nU6KiooGXZdSiXLcYwSxUztvNMa0G2OqjTG3GmM+YoxZd7z5AIwxa4wxYoyZa4yZH3v83Rjz4EAhYIxZodcQqERIVDfUoVCIb33rWxQUFDB37twhdQHt8/nw+/3x162treTm5uJ0OnnttdcG7DJaqUQ73gVlDmNMWEQuGMkKKTXchrsb6k984hO43W4CgQCXXXZZ/ADvzJkzT9gFdFZWFueffz6zZ8/mqquu4q677uKaa65hzpw5LF68mBkzZiR4ayh1rEG7oRaRTcaYhSLyK6zz//8CdPRMH+Tgb8JpN9SnH+2u+Mykn+vp5XjdUA/lGIEHaAIuweoqQmLPoxIESimlhtfxgiBXRL4ObONoAPTQUziVUuoMcbwgsGOdJjrQCc0aBEopdYY4XhAcNsb824jVRCml1Kg43umjemmjUkqNAccLgktHrBZKKaVGzfG6oW4eyYoolWjD0Q21UmeiofQ+qtQZYbi6oVbqTDNmgsDfHWJHTRvdociJC6szznB1Q11UVMS3vvUt5s+fz+LFi9m0aRPLly9nypQpPPigdp+lTk9DuaDsjPD6rga+vHIzL33tQqbm+Ua7OmPW6j/vpvFg+7AuM7sghaU3TDtumeHshrqwsJCysjK+9rWvsWLFCtauXUt3dzezZ8/m85///LC+N6VGwpjZI/B5rMzzB8KjXBM1GlauXMlNN90EHO2GetWqVXzyk58EBu6GeuHChSxYsIDt27ezY8fRW21fe+21AMyZM4clS5bg8/nIycnB7XYP6baVSp1qxsweQTwIujUIRtOJfrknwnB3Q+12uwGw2Wzx4Z7X4bD+fanTz5jZI0hxOwFo1yAYcxLVDbVSZ4oxt0fQHgiNck3USBvubqiVOtMM2g31qepku6Fu6w4x994XuecDpXxm6eQE1EwNRrsrPjPp53p6OV431GOmaSjZpccIlFJqIGMmCOw2IcXtoF3PGlJKqT7GTBAAVhDoHsGoON2aINXx6ed5ZhlbQeBx4NeDxSPO4/HQ1NSkXx5nCGMMTU1NeDye0a6KGiZj5qwhsM4c0mMEIy8/P5/q6moaGhpGuypqmHg8HvLz80e7GmqYjJ0gaNzLxwJP87fo5aNdkzHH6XRSXFw82tVQSg1izDQNBQ7u4Pz6d0jpPDTaVVFKqVPKmAmCqrpsnjvyXTLa/aNdFaWUOqWMmSDImZIHQFp3dJRropRSp5YxEwRdOQ5EuvAGnUSievaKUkr1GDNBsL11N4dSDmGPpNIR1DOHlFKqx5gJggkpE2hMrkbCOfg79VoCpZTqMWaCYGLyRBpTqhHjorZ6eO+QpZRSp7OEBYGIFIjIayKyQ0S2i8hXBijzCRHZIiJbReRNEZmXqPqkudPwJ1unjjYcbEvUapRS6rSTyAvKwsA3jDGbRMQHbBSRl4wxO3qV2Q9cZIw5IiJXAQ8BSxJRGRHBk9xJVAK0HNRTSJVSqkfCgsAYcxg4HBv2i0g5MBHY0avMm71mWQck9Jr1PHc6bclVePZ7McYgIolcnVJKnRZG5BiBiBQBC4D1xyl2GzDgPQFF5HYR2SAiG95PfzXjk8exK3sjwdYo9VW6V6CUUjACQSAiKcBfga8aYwZsnBeRi7GC4K6BphtjHjLGLDbGLM7JyTnpuuSnF7E9pwyxRdn55uGTXo5SSp1JEhoEIuLECoHHjDFPDlJmLvD/gOuMMU2JrM+k7GkEHd3YM2vYs6GOcCiSyNUppdRpIZFnDQnwMFBujPnJIGUKgSeBm40xuxNVlx75WTMACGaUEegMU7GxPtGrVEqpU14i9wjOB24GLhGRstjjahH5vIh8Plbmu0AW8MvY9Pd+V/r3YILPOhbt92whY1wSW16rTuTqlFLqtJDIs4bWAMc9LccY8xngM4mqQ3/p7nTcUSEarWLOOamserqWuv1t5BWnjlQVlFLqlDNmriwG61oCF7nsdNmY3vxjnB4765+tIBTUYwVKqbFrTAUBwKyMq3nX42Ljgf/j3CmbObjzCH/94Ub8zd2jXTWllBoVYy4IbppxI9FgOvdPmMqspnv5YPHv8Dd18tQDm2ht6Bzt6iml1Igbc0GwqDCHQMMV7DFtfG/JR5gQ/AfXFfyCYHeIP933Dhv+XkkooE1FSqmxY8wFQXqSi4nO8yngOp6uf5t/nnMBzsAaPpr7XfIn2Vj/7D7+8N232LlOLzhTSo0NYy4IAOblZ3Ck5mL+7bx/Y1NbJTdOmc4RTwNXt13Hh89dQ2q6nVceLef1P+4iEtZbWyqlzmxjMgjm5qdxuLWb8/Ou4ndX/Y4Ahs9NnEDdopsZX/Uzro98lIWlNWxfdYhnf1ZGlz842lVWSqmESWQ31Kess4szAXh9VwM3nDWLX132Kz79wqdZYdvNjz7+B+ZsWsm5O75IZu4HeG3vLfzvnauxO2zkFaeRmuXh4M4jFM3NZumNU7Hbx2SWKqXOIGPyW2zOxDSKs5N5crN1ZfHMrJn8+vJfEzZhPvXmt3lqwfVw28tMnyl8dM6fWJz6FLO9z9N9uJJ9Gw+RkSVsX3WI//vpZlrq9EwjpdTpTYwxo12H92Tx4sVmw4b33xPFz17ew3+9vJu1d1/CxHQvAK2BVr656pu8WfMmn53zWT5e+nGyvdnQvB9evhcOvg3+GgB2di1jVdvtRHBx/jlHmHvZFMibDQ43AIHOEDa7Dafb/r7rqpRS75eIbDTGLB5w2lgNggNNnVx4/2t888rp/POykvj4UCTEd9/8Ls/tew6HOLh97u18bt7nsEls5+lIFVS8At2tdNQ18PraXCo753JZ2k+ZlrQWyZtJfdKFPLfxQuxuF1d9cRG5k1Lpbg+xf0sjJYtzcbo0HJRSI0uDYBA3PPgW1Uc6efVfluFx9v1yrmip4KEtD/H3/X9nYspEusJdXFp4KZ+b+zmq26uZlDqJbG824WCY//uvt6nZ343HFcRr9+PvTsErrRiETpNBjqeaI4E8glEvM4truHC5h/07/ORn1GM6j7CxfAIl5xYz7tJrrJVHwkT8jaz+WwsZ45KZvWyiHotQSr0vGgSDeKuiiX/6zTruXD6dL15ccsx0Ywx/2f0XVlWvwuvw8mLVi0SNdTqpXewszV/K9SXXMy15BnVl3bTVBAh0hnElOVhyeTay81k2v9FEXWcBSd4Qrmgr5fWzyHQcoDlciFv8OGxhOiIZ2Agxb9wmHElexne9wp6WOZR3XQZAZlonV1xUS9aMEiLZs9n+/Lt4PWFKFmQhvlyMN4dD+7torG4nOz+F/BmZA74XvTWnUmOXBsFx3P67Dazd28gr31jGuDTPcctua9zGusPrmJI2hbKGMp6teJbGrkYAXDYXn5v3OW6eeTNeh3fA+SOhKE/8xzpaGwMs+UA++7f76WwLcuGNJZQ9sYaqQ317QV08bS85gXW8fvADhKJJFHnepjk8ieZwIQDjnDsp8aylovs8DodKARCiXFH4OCUFzYQ9eeyuKeDdA9OJRG18cO5LNJiZ7K0tJBQIMWtyDVPG10HnEUgdD7mlRJ2pNNRG8DcHyM9rw52Ricmajs2XBe5UiIapev1NgkEouew8xOUeeGNFI2AM2Ac+Ma27IwSAJ9l53G3eW7ArzLuvHmTmBRNIThtkvSfJGEPjwXay8lOw2TQw1ZlHg+A4Khs7uOpnq5lXkMZjnzkH+3v4EghHw6w7vI7ajlrerHmTl6peAqxQiJooSc4kCnwFzM6ejc/lo6qtiurmGiZ4JnL3RXcyLnkch/yH2NK4hRxvDiUp00hxJVOxuYGO1gALLitEbEJHs59VK3fTXH0Euwlw9jIv3WEvG1d30tYquF1hzpu5i4KUXby05Txq23LJSTpMWyCN7kgKWZ4aOkJphKIuIsaJz16HAG2RPOakPM+45BoO+ydQHZhDWySXKNaXs40wdgkSNm4muHZQ6NpEkGQ2tn8UgHRHDQ4JkOZs5NzC1dQ2p9PSlUqep4p0s4/DZgFvd3ycaRMOck7GX2lssNEgc6iOLKKiJo9oVEhytDE5/wizZ3eTldJKRzidgKSRlmHD3rwTulvAmUSwK8z/vX0Otc1pTC70c+UFFdR0TiYrrROPvQMjdrqCLoKdYXzhCuzZk2DiYgh2QO1WaD1IRWgZtuRUivLqEX8NhAPg8IDDzbq3XGzclseE7BYuv6yVlIJJULcd2ushrQDSC8CbAaEuSM6xhtvrrMCzO8DmgM4m6G6FnBmQlA0mQrc/AEStwEsZBzYbREJWSIot9hDrAUQiUULdEat8sMNavmeAbtK7W6GrBewuSMoChwuiUQi0gTcdgGjUHD/UohFo3GP9CPCkDfnvPhqJcnhvK+NL0rD1NFkaYz1sQ2jC7G4DVzLY7HT5g7i8DuwObfpMNA2CE/jLhoPc+cQWvnRxCf+yfPpJL+fNmjfZ0bSDtmAbDnHQFmyjsrWSrY1bCUaC5Pvyyffls7FuIwBOm5O2YN/bOE9KnURpZileh5e3a98m1ZXKjMwZeBwenDYnBsOR7iNMy5jGDdNvINwqlLVu5OXaF5mUOolJ7sn417kI1AkpKUksuKSICVPT2F6xh3V/qsI2qR3XzDqMMwnbmnxat1hfFHankFEYpiDXQ854JymZSVTuDdPc0kBNRxXu+gn4W5MAmDojSlFxhB3v+LHZoxxuTCccGfiXf4q9gfZIDsmuVjqC1peNSzop9b5MsqOVOsfZVB0pImIcFLjepTo4lygOIIqdMD5nE+Oce6gKzCMQSabQvYnKwNlMcm+gKrAYp3Qx3llOfaiEbtPzhRkly3GAdMchOiPppDtqMDjZ2bUMgDR7DfOSnqMtksvOrotJtjfTFC6mwLuNw90l2AlxSdr/UOx+G7E7IRqiJTyOmuAsWiITyHIcoMj9Di7p5FBwNgeD80iytRI2LrqjPry2Via6t+EgyDNH/o1Q1MMM76tkuWvwuVpwhRvY1PFhwsbFWSl/piU8gW7jI8+5l9Vtt9EWyeNDWd8n17GLiHFQl3IFNe1F+LuSyM5oxxfeD50N+CO5pNrrKHC9S5NtFv6AD5vppjCvhQOBBTy//wbSHLUUe95hXso/cNm6qJMFVHExHlsb2cF3yDXvUhk8izrHuaRkuEhzNpISOQACu+qnUddRwNyiCnKyArS1OcjMirB6x1wqGyYyPqmKS6a+QvrkSYR2vEC0tQ53egbR9CI67AV0BFLImujF4XLQtLeaFEcjnmAt1G2lyz2JjZHb2HpoJuMyW7n2skrsDVuJdvtpj+bhmzINMRFMzbvsOZBFJGpjWt4+JNJF0JFNOHchW8tsdAdsLFxiJ83TCv7DYKLg9oHTawVO5mQoPAd846DtMDTvA6fHClF/LUFbKnaXE7sdcKfh77DT0hhmQkk6dpfTCne3DyJBaNxDQ6iYA4eSCDdWk55lI780m2R3NwTbrTI2B8G2FurrbEw8ay4S7oLaLbS7pxERN6n2OsRmswJc7LFAP2LNX7DEqu/hMgh2EAlHWbcpm9Q0G9PmOHFnZEJGMaRNPKnvJw2CIfjmE+/y5w3V3HvNTFacXzysy45EIxgMDpv1ZXmw7SC/2fobXHYXxWnFLMhdQFNXE+XN5ZQ3lVPeXE5bsI0l45bgD/qpaK0gGAkSilrNKamuVOo663DZXLgdbvxBP8nOZDpCHX3W6xAHc3LmcNB/MN6E1Z8z7CY9lMMRVz1he5BMTyZ5SXkAZHozefvw24SiIexi58Lsi5nhnENzSg0H2w9yoO0AhzsOkx0ez2UdHyOlwEZHTgN1B1rJDOaRm55NznQnb/xtJ1mHinDO6iRrhouK4A72HdlB1OYgO3kcS9LOJrgunWBFMqkzwkzId9HeGCSIh2CDg84aQ/60DMYvsbOu61lCT83B0ZHM/okbyLXlkdYxDkduF9Mn5ZGVls62mlo6D3QTbRHwhAi2JBMOwsKzDdlZITaUuWg+DGBwF3eREvYxoSiTC/5pNm31nbzwUBmNNQGcbsHtcxKNhOg8Yv2fiFg/fAGcnjChbgdg6LkHk90OkVifhXZ7FI87Sv6EAHv2JRGNHv11bneGsNmihAJ9m7jcrhAOe4RIxEZWRoDaxmQiEevXstsRIBAeoEnMFoHo0ZMdslOaaOlMJTUlQJInRHV9OjabwUQFgyBEMPQ9OcJhCxGO9m2ms0kUn7eD1k5fvxVGmZW9md1H5hCKuEiz1+CP5hE1drzObgJhJ1FjLd9rayXF1khDeAoOW5BJ6VWQlElVTRrhqI1Jvl1U+UspdL9Dnq+R3f4ltAYyKXavJ9+1hV2hK6jvnmQty9FBMOImYqz/IyGKTSIYA/nuraS6/fgjWWTYD+KlkYru8wlFHSTZWpng3I4/mkNLeCKzkl4kFPVQ3nUpjeEiXNJJkXsDtaHptEYmADDeWc785GeoC01jnLMcr62Nss5rqeg+v8+WECJM9qxjinsdPns9rZFxrPd/An80lyL3O+S73qUycBbVwXkAJNmaGe8qx0mA1kge+a6tiETZ030h6fZDlHjWMtWzGhF4vfVzbO+60vp7IUi+ewuzFnoovuWOY/8GhkCDYAhCkSj//NgmXtpRxzevnM4XLppySh9c3da4jef3P08gEmBG5gyunXItHaEOajpq8Af9tAXb2Na4jXdq36EwtZDFeYtZmLeQDHdG/FTYan81u4/sZl/rPrK92aS701l3eB3+oJ+IiVDfWc+srFncNOMm/r7v77xR/QaVbZX4XD4KfYUU+grJ9+VT31nPawdfoy3YhtfhZVLqJJq7m6nvtO4JnZ+Sz5LxS3hm7zOETZhxyeOYkjYFp91Jtb+avS17AUhyJNEZHvgCPYc4CJswNrExzcyhIDIFJvvj9QXIcGcwP3c+rx18re+8EReL05ZgfEGq/dUc8h8ip6OAoD1Aq7cem9jIT8knFA0RjAQJhyNMqpmHryMLTygFm7HRkHqASEErkh7mSFUXOUeKSOvOod5XhW16G4uzzga7YYd/G9urdzKjcQlTO+ZTN38LGXnJFKdMZmfNHvZUHsC026lK344Rw8ymc5CcACYphKMmjZ3JG0myJXPN3i/QFemk2reb+fOmMXN2MXu7dvHO3s2EOyDDlcG8ybN4Yd0qvPVZ2McHmVKcz/a9eyjduQxcUVJvaGZm/nSCTcK+dc0keT3k5qeRNc1FS2cb5bsqqdxdSzC7jfyZ6ZybdQFtTV0crmsgyZ5MykQH9hSDf5chGhDcmYK3OZNoZicH0srxdvtw7MsicsiJJ8dOss+Drc1DVaCCZnc9EzPzqNscwLTbcc/uZkKgmPbKKB2hDmRCN9OXZXHurEX88tHHcW8sxIaNQGYr02fnc/AtP5EQuDKEiRe5yEhL5ciWKKmZXlIyPESD3UhJiJpANf63wF9lJ9QuSEoY0+LERCB3kg9J6qCxroVIsw+ny+Dx2fE3Wd95zrwwuSUOpNVN3Z4g4/JdFE510W2PsPmFDqLhfv//zghZc9r4wHkZJE87j7r9tWxcvYvqrQ4igaNl03M9lCzIYvPL1UQiQmq2i8yp7aQm2+lqyqBmfyfRSBRfqoP6miAYmFCSRmv9ETrabDjHdeJJcuPfZ2fBJblMmelhzzv17N/ZzawlaSz88KKT+s7QIBiiQDjCN/78Ls9tOczVc8Zx34fmkJHsSsi6Tlfd4W48joEPqhtjMJh40PiDfqr91UxOn4zb7qaluwWHzUGKK6XPfHUddThsDjI8GZQ3ldPc3YzH4cHr8NIZ6qS6vZqD/oOkOFO4dsq15CTlxOcNRALUdtTSEergW6u/xf7W/Xxx/hdZmLeQmvYaJqZMZH3tetZUr8FmszEheQKlWaUsGbeEfF8+TV1NPLfvOar91TjtTlx2F06bE5fNRao7lXR3Ol6Hl/2t+9nXuo+2YBtT06eyIG8BLpuLnc07WX94PVsatiAiTEmfwuK8xYSiIXY17yIUDXGg7QD+kJ9sbzZLxi/hrLyzKPAV0BJooayhjMPthwlGg+R4c8hNyuVQ+yGe3/88U9KnkOnNZO2htfH3OyVtCtlJ2VS1VVHbUUuGO4Pb5tzGL8p+QSAS4PwJ55Nmz6DiSAXl/u0n/DznZs8lYiLsPrI7vsc5HHr2UFNdqRT6CtnZvJOwCQNgE1ufs+8iJsJ1kz6E3W7nHwf+Tle4C08oBWfEhd/THF9mz3w9n82ge7kRN0WuKfiyPJQ1lFnzhD2EbSGiEmVO9xKawo3UpOztczNdh82BMYaIiZDalU1qIIuOzEbOjlxMU0sL76auJmQP4HV4mZw2mf2t++kMd2KL2snunshsz3wkOUK1q4L67jo8gRSCoRBNztr4OnK9uTR2W/Uu8BUQabMRCofoTGrFH2hnRv0Szjp4NUF7NwcydrB7+mrsNjthEybNlcbHSm7g5jmfPKnPRIPgPTDG8OtV+3jghV1kJLv4zgdncs3c8af03oGydIW7qO+sZ1LqpBFfdyASwC72ePNfb1ETpbGrkRxvzpD/jqImiiCICJvrNxOMBJmUOolxyePi07c3bmd8yniyvdnUtNcgCONTxseX0dTVxL7WfURMhEm+STR1N9HU1YTBkOZOIz8lPx6q7cH2+DGporQi2oJthCIhbGJDEGxiIxAJUNlWSbIzmYW5CwlGgzR1NdESaMEudhq6GqhoqeDC/AuZmTWTg/6DTEiegNPuxB/089rB16jtqOWaydfgc/nYXL+ZtTVrWZS3iMsnXQ5AY1cjrx54FY/DQ6orlRRnCgZDbUctlW2V2MRGd7ibpq4m5ufOZ17OPAKRAG67mxRXCg5x8Eb1G7xV8xa1HbUsylvEh6d+mJ3NO+kId9Ad7mZrw1bykvO4qvgqGrsaqeuss/aiA23YxEZOUg453hzaQ+1sadjCuw3vkuRI4ptnfZOWQAtra9ay58geClMLOXvc2aS6Ullfu55NdZswxpDpySQ3KRcRwevwkuHJoMBXQF1HHVsbt1KYWogxhn2t+0h1peJ1eAlHw+T78ilJL2FS6iRqO2rZdWQXu4/sBqwQbA20cnHBxVwz5ZqT+hvVIDgJ2w61ctdft7C9po0Fhenc84GZLJqUkfD1KqVUIhwvCPScrUHMnpjGs1+6gPs/OpdDR7r4yK/e5OaH1/Parnqi0dMrPJVS6nh0j2AIOoNhHllbyaNvVtLgDzA5O5mPLMpn+axxlOSmnHgBSik1yrRpaJgEw1H+se0wv32zkk0HWgCYnJPM8lnjWD5rHHMnpulVqUqpU5IGQQIcbu3ipR11vLC9lnX7molEDeNSPVw0LYezizNZMjmT/Iyk0a6mUkoBGgQJ19IZ5NWd9by4vY639jXR2mWdhjcx3cuS4kzOjj2Ks5P17COl1KjQIBhB0ahhV52ft/c3s35/E2/vb6ax3brncY7Pzbz8NGZNSGP2xDRmT0xlXKpHw0EplXDHC4Ixec/iRLLZhNLxqZSOT+WW84owxlDR0MHb+5t5p7KZbYdaeXVnPT0nHqUnOZmW66MkL4WpuSlMzfUxNS+FXJ9bA0IpNSI0CBJMRCjJTaEkN4WPL7G6j+4Mhik/7GfboVZ21vrZW+/n71sP09J59MpOn8dBSW4KxdnJTMpMZlJWEoVZSRRlJZOR5NSQUEoNGw2CUZDkcrBoUkafC9SMMTR1BNlT187eej976tvZU9fOuoomntx0qM/8PreDgswk8jO85Gf0PHvj43yeoffxr5RSCQsCESkAfgfkYXXP+JAx5mf9ygjwM+BqoBNYYYzZlKg6ncpEhOwUN9kpbs6dktVnWncoQvWRTqqaeh4dVB/porKpgzV7G+kMRvqUT/U4yPG5yfG548u0hl3x19mx126H3j9ZqbEukXsEYeAbxphNIuIDNorIS8aYHb3KXAVMjT2WAL+KPatePE47Jbk+SnL7dwds7Ukc6QxRfaSTg81dVB/p5FBLFw3+AI3tAbbXtNHoD+APhAdcdqrHEQsFNzkpvcIiHiKueKD0v6+zUurMkLAgMMYcBg7Hhv0iUg5MBHoHwXXA74x16tI6EUkXkfGxedUQiAiZyS4yk13MzU8ftFx3KBIPh8b2oPXc63VDe4Dy2jYa/AH83QOHhs/tiO9JxPcsUtxk+6zXGUku0rxO0rxO0pOcGhxKnSZG5BiBiBQBC4D1/SZNBA72el0dG9cnCETkduB2gMLCwoTV80zmcdopyEyiIPPEF7l1hyI0dQR7BUUsLGKvG/wBdtf5ebPi6DUTA3E5bEeDIfac5nWSluTsExhpvad5rTBx6a0LlRoxCQ8CEUkB/gp81RjTdqLyAzHGPAQ8BNZ1BMNYPTUAj9POxHQvE9O9JywbDEdp6gjQ6A/S2hWipct6bu0K0doZOjrcFeJwazc7a/20dYUGbarq4XXa4+GQ4nHg8zhIcTvweZykxocdpHic+DwOfLFpvcvqHolSQ5PQIBARJ1YIPGaMeXKAIoeAgl6v82Pj1GnC5bAxPs3L+LQTh0Zv4UiUtu5wPCRaOq0AaYu/tp7bukO0B8I0dwSpaurE3x3G3x0iEI6euG52GymxUOh5eF12kt12klwOkl12ktzWc7LbQbLbCpQUjzWc7HKQ5LLjddlJctnxOOzal5Q6IyXyrCEBHgbKjTE/GaTYs8CXRORxrIPErXp8YGxw2G3xYxsnIxiO0h6wQsHfHaatO0RHIII/Fhz+7nB8entsuCMQoaUzyKGWCJ2BMB3BCB2BMOH30K2412mFQpLbTpLTYT27+gZLUqyMx2XH64w9XHY8vYa9ztjr+LBNg0aNmkTuEZwP3AxsFZGy2LhvA4UAxpgHgb9jnTq6F+v00VsTWB91BnE5bGQ6Tj5IeguEI3QGIrQHegIjjD8QpisWFF2hCJ3B2CMQpjMUOWZaU3tnrIwVOF2hyIlXPAC3wxYPh2PDomfYZr3uXy42zuOw4XbacTtsuB02PD3Dseee1w6b6IWJCkjsWUNr6HNH0AHLGOCLiaqDUkPhdthxO+zDen9qYwyBcJSuoBUKXbHwCIQjdAWj8XHd/aZ39xruCh193RkM09QRJBDqv7wTN5ENxiYcDQmHHXdsr8Tt7Bcgjr5B0recvV9Zq5xngODpPc1h15MBTiV6ZbFSCSAieGK/1BN5g9NI1MTC5WhwdIeiBMIRAqEogbA1HB8XjhIIRekORQafFpu3IxCmqb3XtPDR+YLvI4AA7DY5NiQcVhOZu1cYuXuFkcfZO5SODSO3w4bTYcNlt+Fy2HDabTjt1npcdntsnOByWNNddpvuEcVoECh1GrPbhCSXgyTXyP4rR6OGYCQaC5tIn5DoCaHuwcLoeNNiy2nvFULdvcoNRwj11hMarj4BIrgcVnC4B5jeEzJux9HyTnv/ZVjDVjDJAON6letZp70nvKzXIxlSGgRKqffMZhM8NnvsFN2R7duqdwgdDZRYSESihMJRQhFDMBIhGLbKBsM9j0hsWjQeKsFwNFa2Zzjaaz6rWa6lq/cyovFl9iwrkoD7mPcEjNthix8H+viSQj6zdPKwr0uDQCl1WukdQmkjHEKDiUQNocjRILKe+4ZRKDYt0LtMr0AJ9ZSJmNg4a1rPXlJXKEJ2ijsh9dcgUEqp98luE+zxPaTTjx66V0qpMU6DQCmlxjgNAqWUGuM0CJRSaozTIFBKqTFOg0AppcY4DQKllBrjNAiUUmqME6sD0NOHiDQAVSc5ezbQOIzVGU6nat20Xu/NqVovOHXrpvV6b062XpOMMTkDTTjtguD9EJENxpjFo12PgZyqddN6vTenar3g1K2b1uu9SUS9tGlIKaXGOA0CpZQa48ZaEDw02hU4jlO1blqv9+ZUrRecunXTer03w16vMXWMQCml1LHG2h6BUkqpfjQIlFJqjBszQSAiV4rILhHZKyJ3j2I9CkTkNRHZISLbReQrsfH3isghESmLPa4ehbpVisjW2Po3xMZlishLIrIn9pzIe7EPVq/pvbZLmYi0ichXR2Obicj/iki9iGzrNW7AbSSW/479zW0RkYUjXK/7RWRnbN1PiUh6bHyRiHT12m4PjnC9Bv3cRORbse21S0SWJ6pex6nbn3rVq1JEymLjR3KbDfYdkbi/M2PMGf8A7EAFMBlwAe8CM0epLuOBhbFhH7AbmAncC/zLKG+nSiC737gfAXfHhu8GfngKfJa1wKTR2GbAhcBCYNuJthFwNfAPQIBzgPUjXK8rAEds+Ie96lXUu9wobK8BP7fY/8G7gBsojv3P2keybv2m/xj47ihss8G+IxL2dzZW9gjOBvYaY/YZY4LA48B1o1ERY8xhY8ym2LAfKAcmjkZdhug64Lex4d8CHxq9qgBwKVBhjDnZq8vfF2PMKqC53+jBttF1wO+MZR2QLiLjR6pexpgXjTHh2Mt1QH4i1v1e63Uc1wGPG2MCxpj9wF6s/90Rr5uICHADsDJR6x/Mcb4jEvZ3NlaCYCJwsNfrak6BL18RKQIWAOtjo74U27X739FoggEM8KKIbBSR22Pj8owxh2PDtUDeKNSrt5vo+8852tsMBt9Gp9Lf3aexfjX2KBaRzSLyhogsHYX6DPS5nUrbaylQZ4zZ02vciG+zft8RCfs7GytBcMoRkRTgr8BXjTFtwK+AKcB84DDWbulIu8AYsxC4CviiiFzYe6Kx9kNH7XxjEXEB1wJ/iY06FbZZH6O9jQYiIv8KhIHHYqMOA4XGmAXA14E/ikjqCFbplPvcBvBP9P3BMeLbbIDviLjh/jsbK0FwCCjo9To/Nm5UiIgT6wN+zBjzJIAxps4YEzHGRIHfkMBd4sEYYw7FnuuBp2J1qOvZzYw91490vXq5CthkjKmDU2ObxQy2jUb9705EVgAfBD4R+/Ig1vTSFBveiNUWP22k6nScz23UtxeAiDiADwN/6hk30ttsoO8IEvh3NlaC4B1gqogUx35V3gQ8OxoVibU9PgyUG2N+0mt87za964Ft/edNcL2SRcTXM4x1oHEb1na6JVbsFuCZkaxXP31+pY32NutlsG30LPCp2Fkd5wCtvXbtE05ErgS+CVxrjOnsNT5HROyx4cnAVGDfCNZrsM/tWeAmEXGLSHGsXm+PVL16uQzYaYyp7hkxkttssO8IEvl3NhJHwU+FB9aR9d1YSf6vo1iPC7B26bYAZbHH1cDvga2x8c8C40e4XpOxzth4F9jes42ALOAVYA/wMpA5StstGWgC0nqNG/FthhVEh4EQVlvsbYNtI6yzOH4R+5vbCiwe4XrtxWo77vk7ezBW9iOxz7gM2ARcM8L1GvRzA/41tr12AVeN9GcZG/8o8Pl+ZUdymw32HZGwvzPtYkIppca4sdI0pJRSahAaBEopNcZpECil1BinQaCUUmOcBoFSSo1xGgRKxYhIRPr2cjpsvdTGeq8cresclDoux2hXQKlTSJcxZv5oV0KpkaZ7BEqdQKxf+h+Jda+Gt0WkJDa+SERejXWe9oqIFMbG54nV//+7scd5sUXZReQ3sT7mXxQRb6z8HbG+57eIyOOj9DbVGKZBoNRR3n5NQzf2mtZqjJkD/A/w09i4nwO/NcbMxerQ7b9j4/8beMMYMw+rv/vtsfFTgV8YY2YBLVhXq4LVt/yC2HI+n5i3ptTg9MpipWJEpN0YkzLA+ErgEmPMvlhnYLXGmCwRacTqHiEUG3/YGJMtIg1AvjEm0GsZRcBLxpipsdd3AU5jzA9E5HmgHXgaeNoY057gt6pUH7pHoNTQmEGG34tAr+EIR4/RfQCrr5iFwDux3i+VGjEaBEoNzY29nt+KDb+J1ZMtwCeA1bHhV4AvAIiIXUTSBluoiNiAAmPMa8BdQBpwzF6JUomkvzyUOsorsZuVxzxvjOk5hTRDRLZg/ar/p9i4LwOPiMidQANwa2z8V4CHROQ2rF/+X8Dq5XIgduAPsbAQ4L+NMS3D9H6UGhI9RqDUCcSOESw2xjSOdl2USgRtGlJKqTFO9wiUUmqM0z0CpZQa4zQIlFJqjNMgUEqpMU6DQCmlxjgNAqWUGuP+fwaHc3UDNh1JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot L2 train loss vs epochs\n",
    "\n",
    "\n",
    "plt.title(\"Training loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "\n",
    "plt.plot(range(epochs), adagrad_L2_train_loss, label=\"AdaGrad\")\n",
    "plt.plot(range(epochs), rmsprop_L2_train_loss, label=\"RMSProp\")\n",
    "plt.plot(range(epochs), nadam_L2_train_loss, label=\"Adam+Nesterov\")\n",
    "plt.plot(range(epochs), adadelta_L2_train_loss, label=\"AdaDelta\")\n",
    "plt.plot(range(epochs), adam_L2_train_loss, label=\"Adam\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "8m5WlIyAPciU",
    "outputId": "525926b4-bd55-4586-f2c8-1338aff9fdaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x148e00963550>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot L2 + Dropout train loss vs epochs\n",
    "\n",
    "\n",
    "plt.title(\"Training loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "\n",
    "plt.plot(range(epochs), adagrad_L2D_train_loss, label=\"AdaGrad\")\n",
    "plt.plot(range(epochs), rmsprop_L2D_train_loss, label=\"RMSProp\")\n",
    "plt.plot(range(epochs), nadam_L2D_train_loss, label=\"Adam+Nesterov\")\n",
    "plt.plot(range(epochs), adadelta_L2D_train_loss, label=\"AdaDelta\")\n",
    "plt.plot(range(epochs), adam_L2D_train_loss, label=\"Adam\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "TOTPnkd6PciV",
    "outputId": "adf1d97f-ce15-4fed-c97a-f79b0a2e98c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x148e009da730>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation - Plot L2 test accuracy vs epochs\n",
    "\n",
    "\n",
    "plt.title(\"Test Accuracy vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "\n",
    "plt.plot(range(epochs), adagrad_L2_validation_accuracy, label=\"AdaGrad\")\n",
    "plt.plot(range(epochs), rmsprop_L2_validation_accuracy, label=\"RMSProp\")\n",
    "plt.plot(range(epochs), nadam_L2_validation_accuracy, label=\"Adam+Nesterov\")\n",
    "plt.plot(range(epochs), adadelta_L2_validation_accuracy, label=\"AdaDelta\")\n",
    "plt.plot(range(epochs), adam_L2_validation_accuracy, label=\"Adam\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "9S8jqV-MPciV",
    "outputId": "33fc8b7c-bb76-4883-e9da-61a8a3e9b74d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x148e041cafd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation - Plot L2 + Dropout test accuracy vs epochs\n",
    "\n",
    "plt.title(\"Test Accuracy vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "\n",
    "plt.plot(range(epochs), adagrad_L2D_validation_accuracy, label=\"AdaGrad\")\n",
    "plt.plot(range(epochs), rmsprop_L2D_validation_accuracy, label=\"RMSProp\")\n",
    "plt.plot(range(epochs), nadam_L2D_validation_accuracy, label=\"Adam+Nesterov\")\n",
    "plt.plot(range(epochs), adadelta_L2D_validation_accuracy, label=\"AdaDelta\")\n",
    "plt.plot(range(epochs), adam_L2D_validation_accuracy, label=\"Adam\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMZIjoytPciV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw3_amw9425_P4.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "cd6d8db529fcb6d8412518a5eecbbc3302ab092981e5676bdd98593d89df19c6"
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
